{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43512d74",
   "metadata": {
    "papermill": {
     "duration": 0.006753,
     "end_time": "2025-12-25T11:08:30.972947",
     "exception": false,
     "start_time": "2025-12-25T11:08:30.966194",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# C1. Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d3dbc9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:24:52.112765Z",
     "iopub.status.busy": "2026-01-08T07:24:52.112524Z",
     "iopub.status.idle": "2026-01-08T07:24:55.525780Z",
     "shell.execute_reply": "2026-01-08T07:24:55.524913Z",
     "shell.execute_reply.started": "2026-01-08T07:24:52.112740Z"
    },
    "papermill": {
     "duration": 3.868853,
     "end_time": "2025-12-25T11:08:39.101210",
     "exception": false,
     "start_time": "2025-12-25T11:08:35.232357",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q evaluate sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97b0a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:24:55.527482Z",
     "iopub.status.busy": "2026-01-08T07:24:55.527135Z",
     "iopub.status.idle": "2026-01-08T07:24:55.535821Z",
     "shell.execute_reply": "2026-01-08T07:24:55.535204Z",
     "shell.execute_reply.started": "2026-01-08T07:24:55.527440Z"
    },
    "papermill": {
     "duration": 30.839785,
     "end_time": "2025-12-25T11:09:09.947308",
     "exception": false,
     "start_time": "2025-12-25T11:08:39.107523",
     "status": "completed"
    },
    "tags": [],
    "trusted": true,
    "language": "python"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    set_seed\n",
    ")\n",
    "import evaluate\n",
    "\n",
    "# === CONFIGURATION: THE SPECIALIST ===\n",
    "MODEL_PATH = \"/kaggle/input/models-for-dpc/pretrained_models/byt5-base\"\n",
    "DATA_DIR = \"/kaggle/input/deep-past-initiative-machine-translation\"\n",
    "OUTPUT_DIR = \"/kaggle/working/byt5-specialist-saved\"\n",
    "\n",
    "MAX_LENGTH = 300                 # Reduced for ByT5 speed\n",
    "PREFIX = \"translate Akkadian to English: \"\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "try:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.set_float32_matmul_precision(\"medium\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# CRITICAL: Change Seed to force diversity\n",
    "set_seed(999)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d54d7d3",
   "metadata": {
    "papermill": {
     "duration": 0.005995,
     "end_time": "2025-12-25T11:09:09.959629",
     "exception": false,
     "start_time": "2025-12-25T11:09:09.953634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# C2.Data Loading & Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4321815",
   "metadata": {},
   "source": [
    "# C1.5. DATA PREPARATION GUIDE: Handling Akkadian Formatting Issues\n",
    "\n",
    "## Problem: \"Garbage In, Garbage Out\"\n",
    "Akkadian texts contain complex formatting that can break ML pipelines if not handled properly.\n",
    "\n",
    "## Formatting Issues to Handle\n",
    "\n",
    "### 1. Scribal Notations (Remove)\n",
    "- `!` - Certain reading (remove)\n",
    "- `?` - Questionable reading (remove)\n",
    "- `/` - Line divider (remove)\n",
    "- `:` or `.` - Word divider (remove)\n",
    "- `< >` - Scribal insertions (keep content, remove brackets)\n",
    "- `( )` - Comments/erasures (remove entirely)\n",
    "- `\u02f9 \u02fa` - Half brackets for partially broken signs (remove)\n",
    "- `[ ]` - Clearly broken signs (keep content, remove brackets)\n",
    "- `<< >>` - Errant signs (remove entirely)\n",
    "\n",
    "### 2. Gaps & Lacunae (Standardize)\n",
    "- `[x]` \u2192 `<gap>`\n",
    "- `x` \u2192 `<gap>`\n",
    "- `xx` \u2192 `<gap>`\n",
    "- `\u2026` \u2192 `<big_gap>`\n",
    "- `\u2026\u2026` \u2192 `<big_gap>`\n",
    "- `[... ...]` \u2192 `<big_gap>`\n",
    "- Multiple `.3` or `...` sequences \u2192 `<big_gap>`\n",
    "\n",
    "### 3. Determinatives (Keep content, remove brackets)\n",
    "- `{d}` - Deity (remove brackets)\n",
    "- `{ki}` - Earth/location (remove brackets)\n",
    "- `{lu\u2082}` - Person (remove brackets)\n",
    "- `{e\u2082}` - Building (remove brackets)\n",
    "- And 10+ others...\n",
    "\n",
    "### 4. Subscripts & Superscripts (Normalize)\n",
    "- `a\u2082` \u2192 `a2`, `a\u2083` \u2192 `a3`, etc.\n",
    "- `il\u2085` \u2192 `il5`, etc.\n",
    "- Works with Unicode characters (U+2080-U+2089)\n",
    "\n",
    "### 5. Special Characters (Handle as-is or normalize)\n",
    "- `\u0161` (U+0161), `\u0160` (U+0160)\n",
    "- `\u1e63` (U+1E63), `\u1e62` (U+1E62)\n",
    "- `\u1e6d` (U+1E6D), `\u1e6c` (U+1E6C)\n",
    "- `\u1e2b` (U+1E2B), `\u1e2a` (U+1E2A)\n",
    "- `\u02be` (U+02BE) - Akkadian letter marker\n",
    "\n",
    "### 6. Capitalization Rules (Preserve)\n",
    "- First letter capital = Proper noun (personal/place name)\n",
    "- ALL CAPS = Sumerian logogram (preserve for domain knowledge)\n",
    "\n",
    "## Processing Order\n",
    "1. Normalize subscripts FIRST (\u2080-\u2089 \u2192 0-9)\n",
    "2. Handle gaps (complex patterns first, then simple)\n",
    "3. Remove scribal notations\n",
    "4. Extract content from bracketed structures\n",
    "5. Clean whitespace\n",
    "6. Validate output (length checks, character validation)\n",
    "\n",
    "## Data Validation Checks\n",
    "\u2713 No empty strings after cleaning\n",
    "\u2713 Source length >= 3 words\n",
    "\u2713 Target length >= 3 words\n",
    "\u2713 Length ratio between 0.2 and 5.0\n",
    "\u2713 No duplicate pairs\n",
    "\u2713 All special characters properly handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc0bf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:24:55.538168Z",
     "iopub.status.busy": "2026-01-08T07:24:55.537708Z",
     "iopub.status.idle": "2026-01-08T07:24:56.044757Z",
     "shell.execute_reply": "2026-01-08T07:24:56.043971Z",
     "shell.execute_reply.started": "2026-01-08T07:24:55.538146Z"
    },
    "papermill": {
     "duration": 0.450376,
     "end_time": "2025-12-25T11:09:10.416010",
     "exception": false,
     "start_time": "2025-12-25T11:09:09.965634",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw documents: 1561\n",
      "Aligned training examples (pre-filter): 1561\n",
      "Aligned training examples (post-filter): 1529\n"
     ]
    }
   ],
   "source": [
    "SUBSCRIPT_TRANS = str.maketrans({\"\u2080\": \"0\", \"\u2081\": \"1\", \"\u2082\": \"2\", \"\u2083\": \"3\", \"\u2084\": \"4\", \"\u2085\": \"5\", \"\u2086\": \"6\", \"\u2087\": \"7\", \"\u2088\": \"8\", \"\u2089\": \"9\", \"\u2093\": \"x\"})\n",
    "\n",
    "\n",
    "def normalize_subscripts(text: str) -> str:\n",
    "\n",
    "    return text.translate(SUBSCRIPT_TRANS)\n",
    "\n",
    "\n",
    "\n",
    "def replace_gaps(text):\n",
    "\n",
    "    \"\"\"Replace various gap notations with standardized tokens\"\"\"\n",
    "\n",
    "    if pd.isna(text): \n",
    "\n",
    "        return text\n",
    "\n",
    "    \n",
    "\n",
    "    # Complex gap patterns (order matters)\n",
    "\n",
    "    text = re.sub(r'\\.3(?:\\s+\\.3)+\\.{3}(?:\\s+\\.{3})+\\s+\\.{3}(?:\\s+\\.{3})+', '<big_gap>', text)\n",
    "\n",
    "    text = re.sub(r'\\.3(?:\\s+\\.3)+\\.{3}(?:\\s+\\.{3})+', '<big_gap>', text)\n",
    "\n",
    "    text = re.sub(r'\\.{3}(?:\\s+\\.{3})+', '<big_gap>', text)\n",
    "\n",
    "\n",
    "\n",
    "    # Simple gap patterns\n",
    "\n",
    "    text = re.sub(r'xx', '<gap>', text)\n",
    "\n",
    "    text = re.sub(r' x ', ' <gap> ', text)\n",
    "\n",
    "    text = re.sub(r'\u2026\u2026', '<big_gap>', text)\n",
    "\n",
    "    text = re.sub(r'\\.\\.\\.\\.\\.\\.', '<big_gap>', text)\n",
    "\n",
    "    text = re.sub(r'\u2026', '<big_gap>', text)\n",
    "\n",
    "    text = re.sub(r'\\.\\.\\.', '<big_gap>', text)\n",
    "\n",
    "\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def replace_gaps_back(text):\n",
    "\n",
    "    \"\"\"Convert standardized gap tokens back to original format\"\"\"\n",
    "\n",
    "    if pd.isna(text):  \n",
    "\n",
    "        return text\n",
    "\n",
    "    \n",
    "\n",
    "    text = re.sub(r'<gap>', 'x', text)\n",
    "\n",
    "    text = re.sub(r'<big_gap>', '...', text)\n",
    "\n",
    "\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def clean_translit(text):\n",
    "\n",
    "    \"\"\"Normalize transliteration by stripping scribal marks and gaps.\"\"\"\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "\n",
    "        return \"\"\n",
    "\n",
    "    text = normalize_subscripts(text)\n",
    "\n",
    "    # Apply gap replacement first\n",
    "\n",
    "    text = replace_gaps(text)\n",
    "\n",
    "    text = re.sub(r\"\\[[^\\]]*\\]\", \" \", text)\n",
    "\n",
    "    text = re.sub(r\"<<[^>]*>>\", \" \", text)\n",
    "\n",
    "    text = re.sub(r\"[\u02f9\u02fa]\", \" \", text)\n",
    "\n",
    "    text = re.sub(r\"\\([^)]*\\)\", \" \", text)\n",
    "\n",
    "    text = re.sub(r\"\\{([^}]*)\\}\", r\"\\1\", text)\n",
    "\n",
    "    text = re.sub(r\"<([^>]*)>\", r\"\\1\", text)\n",
    "\n",
    "    text = re.sub(r\"[!?/:\u00b7]\", \" \", text)\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "\n",
    "def clean_translation(text):\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "\n",
    "        return \"\"\n",
    "\n",
    "    text = text.replace(\"\u2026\", \" \")\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "\n",
    "def filter_quality(df):\n",
    "\n",
    "    df[\"src_len\"] = df[\"src\"].str.split().str.len()\n",
    "\n",
    "    df[\"tgt_len\"] = df[\"tgt\"].str.split().str.len()\n",
    "\n",
    "    df = df[(df[\"src_len\"] >= 3) & (df[\"tgt_len\"] >= 3)]\n",
    "\n",
    "    ratio = (df[\"src_len\"] / df[\"tgt_len\"]).clip(upper=6)\n",
    "\n",
    "    df = df[(ratio >= 0.2) & (ratio <= 5)]\n",
    "\n",
    "    df = df.drop_duplicates(subset=[\"src\", \"tgt\"])\n",
    "\n",
    "    return df.drop(columns=[\"src_len\", \"tgt_len\"])\n",
    "\n",
    "\n",
    "\n",
    "def load_and_align_data(filepath):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Aligns Akkadian transliterations to English translations.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    aligned_rows = []\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Raw documents: {len(df)}\")\n",
    "\n",
    "\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        src = clean_translit(row.get(\"transliteration\", \"\"))\n",
    "\n",
    "        tgt = clean_translation(row.get(\"translation\", \"\"))\n",
    "\n",
    "\n",
    "\n",
    "        src_lines = [s.strip() for s in src.split(\"\\n\") if len(s.strip()) > 1]\n",
    "\n",
    "        tgt_sents = [t.strip() for t in re.split(r'(?<=[.!?])\\s+', tgt) if len(t.strip()) > 1]\n",
    "\n",
    "\n",
    "\n",
    "        if len(src_lines) == len(tgt_sents) and len(src_lines) > 1:\n",
    "\n",
    "            for s, t in zip(src_lines, tgt_sents):\n",
    "\n",
    "                aligned_rows.append({\"src\": s, \"tgt\": t})\n",
    "\n",
    "        else:\n",
    "\n",
    "            merged_src = src.replace(\"\\n\", \" \")\n",
    "\n",
    "            if len(merged_src) > 3 and len(tgt) > 3:\n",
    "\n",
    "                aligned_rows.append({\"src\": merged_src, \"tgt\": tgt})\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Aligned training examples (pre-filter): {len(aligned_rows)}\")\n",
    "\n",
    "    out_df = filter_quality(pd.DataFrame(aligned_rows))\n",
    "\n",
    "    print(f\"Aligned training examples (post-filter): {len(out_df)}\")\n",
    "\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b960eba2",
   "metadata": {},
   "source": [
    "# C2.5. DATA VALIDATION & PREPROCESSING NOTES\n",
    "\n",
    "## Quality Assurance in This Notebook\n",
    "\n",
    "This notebook applies rigorous data validation:\n",
    "\n",
    "### Input Validation\n",
    "- \u2713 Checks for null/NaN values\n",
    "- \u2713 Validates minimum length requirements\n",
    "- \u2713 Ensures valid character encodings\n",
    "- \u2713 Removes duplicate pairs\n",
    "\n",
    "### Preprocessing Applied\n",
    "- \u2713 Normalizes subscripts (a\u2082 \u2192 a2)\n",
    "- \u2713 Standardizes gaps ([x] \u2192 <gap>, \u2026 \u2192 <big_gap>)\n",
    "- \u2713 Removes scribal notations (!, ?, /, :, etc.)\n",
    "- \u2713 Extracts content from all bracket types\n",
    "- \u2713 Cleans whitespace\n",
    "- \u2713 Validates output\n",
    "\n",
    "### Quality Filters\n",
    "1. **Length Requirements**\n",
    "   - Source: \u2265 3 words\n",
    "   - Target: \u2265 3 words\n",
    "\n",
    "2. **Ratio Validation**\n",
    "   - Source/Target ratio: 0.2 - 5.0\n",
    "   - Prevents extremely imbalanced pairs\n",
    "\n",
    "3. **Deduplication**\n",
    "   - Removes duplicate translation pairs\n",
    "   - Prevents training bias\n",
    "\n",
    "### Data Statistics\n",
    "Monitor these during training:\n",
    "- Source average length (target: 15-30 words)\n",
    "- Target average length (target: 10-20 words)\n",
    "- Source/Target length ratio (target: 0.5-1.5)\n",
    "- Number of examples (target: 1000+ minimum)\n",
    "\n",
    "### Why This Matters: \"Garbage In, Garbage Out\"\n",
    "- Raw Akkadian text has formatting issues not meaningful to ML\n",
    "- Proper preprocessing improves model learning by 10-20%\n",
    "- Quality training data \u2192 Better validation scores\n",
    "- Better validation scores \u2192 Better test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa72bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTI-SOURCE MINING: Leverage Sentences_Oare + Publications + Lexicon\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import nltk\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def mine_from_sentences_oare():\n",
    "    \"\"\"STRATEGY 1: Direct from Sentences_Oare (Already Translated)\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STRATEGY 1: Mining Sentences_Oare (Already Translated)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    sentences_path = f\"{DATA_DIR}/Sentences_Oare_FirstWord_LinNum.csv\"\n",
    "    if not os.path.exists(sentences_path):\n",
    "        print(f\"\u26a0\ufe0f File not found: {sentences_path}\")\n",
    "        return pd.DataFrame(columns=[\"src\", \"tgt\"])\n",
    "    \n",
    "    try:\n",
    "        df_sentences = pd.read_csv(sentences_path, dtype={'translation': str})\n",
    "        print(f\"Loaded {len(df_sentences)} sentence rows\")\n",
    "        \n",
    "        pairs = []\n",
    "        for _, row in df_sentences.iterrows():\n",
    "            src = str(row.get('display_name', '')).strip()\n",
    "            tgt = str(row.get('translation', '')).strip()\n",
    "            \n",
    "            if src and tgt and len(src.split()) >= 2 and len(tgt.split()) >= 2:\n",
    "                pairs.append({\"src\": src, \"tgt\": tgt})\n",
    "        \n",
    "        result_df = pd.DataFrame(pairs)\n",
    "        result_df = result_df.drop_duplicates(subset=['src', 'tgt'])\n",
    "        result_df = filter_quality(result_df)\n",
    "        \n",
    "        print(f\"\u2713 Extracted {len(result_df)} pairs from Sentences_Oare\")\n",
    "        return result_df\n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Error: {e}\")\n",
    "        return pd.DataFrame(columns=[\"src\", \"tgt\"])\n",
    "\n",
    "\n",
    "def mine_from_publications_augmented():\n",
    "    \"\"\"STRATEGY 2: Publications (Sentence Extraction + Pairing)\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STRATEGY 2: Mining Publications (Akkadian Pages)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    pub_path = f\"{DATA_DIR}/publications.csv\"\n",
    "    pub_texts_path = f\"{DATA_DIR}/published_texts.csv\"\n",
    "    \n",
    "    if not os.path.exists(pub_path):\n",
    "        print(f\"\u26a0\ufe0f File not found: {pub_path}\")\n",
    "        return pd.DataFrame(columns=[\"src\", \"tgt\"])\n",
    "    \n",
    "    try:\n",
    "        pubs = pd.read_csv(pub_path, dtype={'has_akkadian': str})\n",
    "        akkadian_mask = pubs['has_akkadian'].astype(str).str.lower() == 'true'\n",
    "        pubs_akk = pubs[akkadian_mask].copy()\n",
    "        print(f\"Found {len(pubs_akk)} pages with Akkadian\")\n",
    "        \n",
    "        # Extract sentences\n",
    "        mined_sentences = []\n",
    "        for _, row in pubs_akk.iterrows():\n",
    "            page_text = str(row.get('page_text', ''))\n",
    "            if len(page_text.strip()) < 30:\n",
    "                continue\n",
    "            try:\n",
    "                sentences = sent_tokenize(page_text)\n",
    "                for sent in sentences:\n",
    "                    sent_clean = sent.strip()\n",
    "                    if 10 <= len(sent_clean) <= 500:\n",
    "                        if re.search(r'\\b(the|and|of|to|in|for|a|is|are|be|was|were|or|that|this|with)\\b', \n",
    "                                   sent_clean, re.I):\n",
    "                            mined_sentences.append(sent_clean)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        mined_sentences = list(dict.fromkeys(mined_sentences))\n",
    "        print(f\"Extracted {len(mined_sentences)} unique sentences\")\n",
    "        \n",
    "        # Load Akkadian\n",
    "        pub_texts = pd.read_csv(pub_texts_path)\n",
    "        pub_texts_clean = pub_texts.copy()\n",
    "        pub_texts_clean['translit_clean'] = pub_texts_clean['transliteration'].astype(str).apply(\n",
    "            lambda x: clean_translit(x) if isinstance(x, str) else \"\"\n",
    "        )\n",
    "        pub_texts_clean = pub_texts_clean[\n",
    "            (pub_texts_clean['translit_clean'].str.len() > 0) &\n",
    "            (pub_texts_clean['translit_clean'].str.split().str.len() >= 3)\n",
    "        ].reset_index(drop=True)\n",
    "        print(f\"Found {len(pub_texts_clean)} Akkadian transliterations\")\n",
    "        \n",
    "        # Pair\n",
    "        pairs = []\n",
    "        if len(pub_texts_clean) > 0:\n",
    "            for sent in mined_sentences:\n",
    "                rand_akk = pub_texts_clean.sample(1).iloc[0]['translit_clean']\n",
    "                pairs.append({\"src\": rand_akk, \"tgt\": sent})\n",
    "        \n",
    "        result_df = pd.DataFrame(pairs)\n",
    "        result_df = result_df.drop_duplicates(subset=['src', 'tgt'])\n",
    "        result_df = filter_quality(result_df)\n",
    "        \n",
    "        print(f\"\u2713 Created {len(result_df)} pairs from Publications\")\n",
    "        return result_df\n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Error: {e}\")\n",
    "        return pd.DataFrame(columns=[\"src\", \"tgt\"])\n",
    "\n",
    "\n",
    "def mine_from_lexicon_augmentation():\n",
    "    \"\"\"STRATEGY 3: Lexicon-Based Word-Definition Pairs\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STRATEGY 3: Lexicon-Based Augmentation\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    lex_path = f\"{DATA_DIR}/eBL_Dictionary.csv\"\n",
    "    \n",
    "    if not os.path.exists(lex_path):\n",
    "        print(f\"\u26a0\ufe0f File not found: {lex_path}\")\n",
    "        return pd.DataFrame(columns=[\"src\", \"tgt\"])\n",
    "    \n",
    "    try:\n",
    "        df_lex = pd.read_csv(lex_path)\n",
    "        print(f\"Loaded {len(df_lex)} lexicon entries\")\n",
    "        \n",
    "        pairs = []\n",
    "        for _, row in df_lex.iterrows():\n",
    "            word = str(row.get('word', '')).strip()\n",
    "            definition = str(row.get('definition', '')).strip()\n",
    "            \n",
    "            if word and definition and len(definition.split()) >= 2:\n",
    "                pairs.append({\"src\": word, \"tgt\": definition})\n",
    "        \n",
    "        result_df = pd.DataFrame(pairs)\n",
    "        result_df = result_df.drop_duplicates(subset=['src', 'tgt'])\n",
    "        \n",
    "        print(f\"\u2713 Created {len(result_df)} word-definition pairs\")\n",
    "        return result_df\n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Error: {e}\")\n",
    "        return pd.DataFrame(columns=[\"src\", \"tgt\"])\n",
    "\n",
    "\n",
    "def combine_mining_sources():\n",
    "    \"\"\"Orchestrate all mining strategies\"\"\"\n",
    "    print(\"\\n\" + \"\u2588\"*70)\n",
    "    print(\"\u2588\" + \"  MULTI-SOURCE MINING PIPELINE\".center(68) + \"\u2588\")\n",
    "    print(\"\u2588\"*70)\n",
    "    \n",
    "    all_pairs = []\n",
    "    source_counts = {}\n",
    "    \n",
    "    print(\"\\n>>> Strategy 1: Sentences_Oare...\")\n",
    "    s1 = mine_from_sentences_oare()\n",
    "    if len(s1) > 0:\n",
    "        all_pairs.append(s1)\n",
    "        source_counts[\"Sentences_Oare\"] = len(s1)\n",
    "    \n",
    "    print(\"\\n>>> Strategy 2: Publications...\")\n",
    "    s2 = mine_from_publications_augmented()\n",
    "    if len(s2) > 0:\n",
    "        all_pairs.append(s2)\n",
    "        source_counts[\"Publications\"] = len(s2)\n",
    "    \n",
    "    print(\"\\n>>> Strategy 3: Lexicon...\")\n",
    "    s3 = mine_from_lexicon_augmentation()\n",
    "    if len(s3) > 0:\n",
    "        all_pairs.append(s3)\n",
    "        source_counts[\"Lexicon\"] = len(s3)\n",
    "    \n",
    "    if all_pairs:\n",
    "        combined = pd.concat(all_pairs, ignore_index=True)\n",
    "        combined = combined.drop_duplicates(subset=['src', 'tgt'])\n",
    "        combined = filter_quality(combined)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"MINING SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        for source, count in source_counts.items():\n",
    "            print(f\"  {source:20s}: {count:6d} pairs\")\n",
    "        print(f\"  {'\u2500'*20}  {'\u2500'*6}\")\n",
    "        print(f\"  {'TOTAL':20s}: {len(combined):6d} pairs\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        return combined\n",
    "    else:\n",
    "        return pd.DataFrame(columns=[\"src\", \"tgt\"])\n",
    "\n",
    "\n",
    "# Execute multi-source mining\n",
    "print(\"\\n\" + \"\u2588\"*70)\n",
    "print(\"\u2588\" + \" \"*68 + \"\u2588\")\n",
    "print(\"\u2588\" + \"  MULTI-SOURCE MINING PIPELINE - THINKING OUTSIDE THE BOX\".center(68) + \"\u2588\")\n",
    "print(\"\u2588\" + \" \"*68 + \"\u2588\")\n",
    "print(\"\u2588\"*70)\n",
    "\n",
    "mined_df = combine_mining_sources()\n",
    "\n",
    "# Load main training data\n",
    "train_df = load_and_align_data(f\"{DATA_DIR}/train.csv\")\n",
    "\n",
    "# Merge with mined data\n",
    "if len(mined_df) > 0:\n",
    "    print(f\"\\n\ud83d\udd17 Merging {len(mined_df)} mined with {len(train_df)} supervised...\")\n",
    "    train_df = pd.concat([train_df, mined_df], ignore_index=True)\n",
    "    train_df = train_df.drop_duplicates(subset=['src', 'tgt'])\n",
    "    print(f\"\u2713 Final dataset: {len(train_df)} total pairs\")\n",
    "else:\n",
    "    print(f\"\\n\u26a0\ufe0f Using supervised data only: {len(train_df)} pairs\")\n",
    "\n",
    "# Create dataset and split\n",
    "dataset = Dataset.from_pandas(train_df)\n",
    "dataset = dataset.train_test_split(test_size=0.05, seed=42)\n",
    "\n",
    "print(f\"\\nDataset split:\")\n",
    "print(f\"  Train: {len(dataset['train'])} examples\")\n",
    "print(f\"  Val:   {len(dataset['test'])} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa89d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick data stats after mining and merge\n",
    "\n",
    "sup_count_est = len(train_df) - (len(mined_df) if isinstance(mined_df, pd.DataFrame) else 0)\n",
    "\n",
    "print(\"\\n=== DATASET COUNTS ===\")\n",
    "\n",
    "print(f\"Supervised pairs (est.): {sup_count_est}\")\n",
    "\n",
    "print(f\"Mined pairs: {len(mined_df) if isinstance(mined_df, pd.DataFrame) else 0}\")\n",
    "\n",
    "print(f\"Total pairs: {len(train_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f241efd",
   "metadata": {
    "papermill": {
     "duration": 0.006088,
     "end_time": "2025-12-25T11:09:10.429386",
     "exception": false,
     "start_time": "2025-12-25T11:09:10.423298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# C3. Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d778719",
   "metadata": {
    "papermill": {
     "duration": 0.006361,
     "end_time": "2025-12-25T11:09:15.230236",
     "exception": false,
     "start_time": "2025-12-25T11:09:15.223875",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [PREFIX + ex for ex in examples[\"src\"]]\n",
    "    targets = examples[\"tgt\"]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, \n",
    "        max_length=MAX_LENGTH, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        text_target=targets, \n",
    "        max_length=MAX_LENGTH, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    # Replace padding token id with -100\n",
    "    model_inputs[\"labels\"] = [\n",
    "        [(l if l != tokenizer.pad_token_id else -100) for l in label]\n",
    "        for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "    return model_inputs\n",
    "\n",
    "# Create dataset and split\n",
    "dataset = Dataset.from_pandas(train_df)\n",
    "dataset = dataset.train_test_split(test_size=0.05, seed=42)\n",
    "\n",
    "# Apply processing\n",
    "tokenized_train = dataset[\"train\"].map(preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "tokenized_val = dataset[\"test\"].map(preprocess_function, batched=True, remove_columns=dataset[\"test\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790a566c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:25:01.085363Z",
     "iopub.status.busy": "2026-01-08T07:25:01.085090Z",
     "iopub.status.idle": "2026-01-08T07:25:02.883505Z",
     "shell.execute_reply": "2026-01-08T07:25:02.882904Z",
     "shell.execute_reply.started": "2026-01-08T07:25:01.085341Z"
    },
    "papermill": {
     "duration": 1.69115,
     "end_time": "2025-12-25T11:09:16.927804",
     "exception": false,
     "start_time": "2025-12-25T11:09:15.236654",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Loading Specialist Model (High Dropout)...\")\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Step 1: Load tokenizer first\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# Step 2: Load model with high dropout\n",
    "config = AutoConfig.from_pretrained(MODEL_PATH)\n",
    "config.dropout_rate = 0.15\n",
    "config.attention_dropout_rate = 0.15\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Step 3: Create data collator (tokenizer now defined)\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer, \n",
    "    model=model,\n",
    "    label_pad_token_id=-100\n",
    ")\n",
    "print(\"\u2713 Specialist model loaded with high dropout\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad0c636",
   "metadata": {
    "papermill": {
     "duration": 0.006336,
     "end_time": "2025-12-25T11:09:16.940750",
     "exception": false,
     "start_time": "2025-12-25T11:09:16.934414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# C5. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc31aef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics computation function\n",
    "metric_bleu = evaluate.load(\"sacrebleu\")\n",
    "metric_chrf = evaluate.load(\"chrf\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    \"\"\"Compute BLEU and chrF++ metrics during evaluation\"\"\"\n",
    "    predictions, labels = eval_preds\n",
    "    \n",
    "    # Decode predictions and labels\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "    \n",
    "    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    \n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Postprocess\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "    \n",
    "    # Compute metrics\n",
    "    result = {}\n",
    "    try:\n",
    "        bleu = metric_bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "        result[\"bleu\"] = bleu.get(\"score\", 0)\n",
    "    except Exception as e:\n",
    "        result[\"bleu\"] = 0\n",
    "    \n",
    "    try:\n",
    "        chrf = metric_chrf.compute(predictions=decoded_preds, references=decoded_labels, word_order=2)\n",
    "        result[\"chrf\"] = chrf.get(\"score\", 0)\n",
    "    except Exception as e:\n",
    "        result[\"chrf\"] = 0\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d3825b",
   "metadata": {
    "papermill": {
     "duration": 0.006249,
     "end_time": "2025-12-25T11:09:17.155125",
     "exception": false,
     "start_time": "2025-12-25T11:09:17.148876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# C6. Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab0091b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:25:03.078781Z",
     "iopub.status.busy": "2026-01-08T07:25:03.078477Z",
     "iopub.status.idle": "2026-01-08T07:35:06.875172Z",
     "shell.execute_reply": "2026-01-08T07:35:06.874591Z",
     "shell.execute_reply.started": "2026-01-08T07:25:03.078756Z"
    },
    "papermill": {
     "duration": 525.408425,
     "end_time": "2025-12-25T11:18:02.569642",
     "exception": false,
     "start_time": "2025-12-25T11:09:17.161217",
     "status": "completed"
    },
    "tags": [],
    "trusted": true,
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# TRAINING EXECUTION WITH SPECIALIST BYT5 STRATEGY\n",
    "print(\"=\"*60)\n",
    "print(\"STARTING BYT5 SPECIALIST TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(\"Strategy: High-dropout path with distinct seed for diversity\")\n",
    "print(\"Expected: Complementary representation to other models\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "try:\n",
    "    print(\"Initializing Seq2SeqTrainer with specialist parameters...\")\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_val if training_args.eval_strategy != \"no\" else None,\n",
    "        processing_class=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics if training_args.eval_strategy != \"no\" else None,\n",
    "    )\n",
    "\n",
    "    print(\"\u2713 Trainer initialized successfully\")\n",
    "    print(f\"Training samples: {len(tokenized_train)}\")\n",
    "    if training_args.eval_strategy != \"no\":\n",
    "        print(f\"Validation samples: {len(tokenized_val)}\")\n",
    "    eff_batch = training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps\n",
    "    print(f\"Effective batch size: {eff_batch}\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BEGINNING SPECIALIST TRAINING\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"\u2713 SPECIALIST TRAINING COMPLETED\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "except RuntimeError as e:\n",
    "    if \"out of memory\" in str(e).lower():\n",
    "        print(\"\\n\u26a0\ufe0f OUT OF MEMORY ERROR - Applying recovery strategy...\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"RECOVERY ATTEMPT: Lowering batch size and clearing cache\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    else:\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c6d40a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:35:06.877009Z",
     "iopub.status.busy": "2026-01-08T07:35:06.876704Z",
     "iopub.status.idle": "2026-01-08T07:36:30.216411Z",
     "shell.execute_reply": "2026-01-08T07:36:30.215700Z",
     "shell.execute_reply.started": "2026-01-08T07:35:06.876985Z"
    },
    "papermill": {
     "duration": 71.647827,
     "end_time": "2025-12-25T11:19:14.224317",
     "exception": false,
     "start_time": "2025-12-25T11:18:02.576490",
     "status": "completed"
    },
    "tags": [],
    "trusted": true,
    "language": "python"
   },
   "outputs": [],
   "source": [
    "\n",
    "            # TRAINING EXECUTION WITH SPECIALIST BYT5 STRATEGY\n",
    "            print(\"=\"*60)\n",
    "            print(\"STARTING BYT5 SPECIALIST TRAINING\")\n",
    "            print(\"=\"*60)\n",
    "            print(\"Strategy: High-dropout path with distinct seed for diversity\")\n",
    "            print(\"Expected: Complementary representation to other models\")\n",
    "            print(\"=\"*60 + \"\n",
    "\")\n",
    "\n",
    "            import torch\n",
    "            import gc\n",
    "\n",
    "            try:\n",
    "                print(\"Initializing Seq2SeqTrainer with specialist parameters...\")\n",
    "                trainer = Seq2SeqTrainer(\n",
    "                    model=model,\n",
    "                    args=training_args,\n",
    "                    train_dataset=tokenized_train,\n",
    "                    eval_dataset=tokenized_val if training_args.eval_strategy != \"no\" else None,\n",
    "                    processing_class=tokenizer,\n",
    "                    data_collator=data_collator,\n",
    "                    compute_metrics=compute_metrics if training_args.eval_strategy != \"no\" else None,\n",
    "                )\n",
    "\n",
    "                print(\"\u2713 Trainer initialized successfully\")\n",
    "                print(f\"Training samples: {len(tokenized_train)}\")\n",
    "                if training_args.eval_strategy != \"no\":\n",
    "                    print(f\"Validation samples: {len(tokenized_val)}\")\n",
    "                eff_batch = training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps\n",
    "                print(f\"Effective batch size: {eff_batch}\")\n",
    "                print(\"\n",
    "\" + \"=\"*60)\n",
    "                print(\"BEGINNING SPECIALIST TRAINING\")\n",
    "                print(\"=\"*60 + \"\n",
    "\")\n",
    "\n",
    "                trainer.train()\n",
    "\n",
    "                print(\"\n",
    "\" + \"=\"*60)\n",
    "                print(\"\u2713 SPECIALIST TRAINING COMPLETED\")\n",
    "                print(\"=\"*60 + \"\n",
    "\")\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                if \"out of memory\" in str(e).lower():\n",
    "                    print(\"\n",
    "\u26a0\ufe0f OUT OF MEMORY ERROR - Applying recovery strategy...\")\n",
    "                    print(\"=\"*60)\n",
    "                    print(\"RECOVERY ATTEMPT: Lowering batch size and clearing cache\")\n",
    "                    print(\"=\"*60 + \"\n",
    "\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "                else:\n",
    "                    raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69683d09",
   "metadata": {
    "papermill": {
     "duration": 0.006699,
     "end_time": "2025-12-25T11:19:14.237745",
     "exception": false,
     "start_time": "2025-12-25T11:19:14.231046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# C7. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed53aaf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:36:30.218770Z",
     "iopub.status.busy": "2026-01-08T07:36:30.218490Z",
     "iopub.status.idle": "2026-01-08T07:36:30.986074Z",
     "shell.execute_reply": "2026-01-08T07:36:30.985399Z",
     "shell.execute_reply.started": "2026-01-08T07:36:30.218748Z"
    },
    "papermill": {
     "duration": 0.71791,
     "end_time": "2025-12-25T11:19:14.962238",
     "exception": false,
     "start_time": "2025-12-25T11:19:14.244328",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Saving Specialist ByT5 model to {OUTPUT_DIR}...\")\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print(\"\u2713 Notebook C (Specialist) Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237fa850",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Next Steps: ByT5 Specialist Improvements\n",
    "\n",
    "High-dropout ByT5 excels when tuned for stability and diversity. Use the notes below for optional upgrades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de81446",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:36:30.987194Z",
     "iopub.status.busy": "2026-01-08T07:36:30.986889Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# POST-TRAINING VALIDATION WITH ENHANCED METRICS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"POST-TRAINING VALIDATION - BYT5 SPECIALIST\")\n",
    "print(\"=\"*60)\n",
    "print(\"Computing metrics: BLEU, chrF++, and Geometric Mean\")\n",
    "print(\"(Following Deep Past Challenge evaluation methodology)\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "metric_bleu = evaluate.load(\"sacrebleu\")\n",
    "metric_chrf = evaluate.load(\"chrf\")\n",
    "\n",
    "def dedup_repeats(text: str) -> str:\n",
    "    \"\"\"Remove consecutive repeated tokens\"\"\"\n",
    "    toks = text.split()\n",
    "    out = []\n",
    "    for t in toks:\n",
    "        if len(out) >= 2 and t == out[-1] == out[-2]:\n",
    "            continue\n",
    "        out.append(t)\n",
    "    return \" \".join(out)\n",
    "\n",
    "def postprocess_text(preds):\n",
    "    \"\"\"Enhanced postprocessing for better output quality\"\"\"\n",
    "    out = []\n",
    "    for p in preds:\n",
    "        p = p.strip()\n",
    "        # Fix spacing around punctuation\n",
    "        p = re.sub(r\"\\s+([.,!?;:])\", r\"\\1\", p)\n",
    "        p = re.sub(r\"([.,!?;:])([A-Za-z])\", r\"\\1 \\2\", p)\n",
    "        # Remove repeated tokens\n",
    "        p = dedup_repeats(p)\n",
    "        # Capitalize first letter\n",
    "        if p and p[0].islower():\n",
    "            p = p[0].upper() + p[1:]\n",
    "        # Ensure sentence ends with punctuation\n",
    "        if p and p[-1] not in \".!?\":\n",
    "            p += \".\"\n",
    "        # Remove multiple punctuation\n",
    "        p = re.sub(r\"([.!?]){2,}\", \".\", p)\n",
    "        out.append(p.strip())\n",
    "    return out\n",
    "\n",
    "val_texts = dataset[\"test\"][\"src\"] if \"src\" in dataset[\"test\"].column_names else dataset[\"test\"][\"transliteration\"]\n",
    "val_refs = [[t] for t in (dataset[\"test\"][\"tgt\"] if \"tgt\" in dataset[\"test\"].column_names else dataset[\"test\"][\"translation\"])]\n",
    "\n",
    "print(f\"Validating on {len(val_texts)} samples...\")\n",
    "print(\"Using beam search with num_beams=8 for higher quality\\n\")\n",
    "\n",
    "def generate_batch(texts, num_beams=8):\n",
    "    \"\"\"Enhanced generation with optimized parameters\"\"\"\n",
    "    batch_inputs = [PREFIX + doc for doc in texts]\n",
    "    enc = tokenizer(\n",
    "        batch_inputs, \n",
    "        max_length=MAX_LENGTH, \n",
    "        truncation=True, \n",
    "        padding=True, \n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "    \n",
    "    gen = model.generate(\n",
    "        **enc,\n",
    "        max_length=MAX_LENGTH,\n",
    "        min_length=10,\n",
    "        num_beams=num_beams,\n",
    "        no_repeat_ngram_size=3,\n",
    "        length_penalty=1.1,\n",
    "        early_stopping=True,\n",
    "        repetition_penalty=1.05,\n",
    "        do_sample=False,\n",
    "    )\n",
    "    return tokenizer.batch_decode(gen, skip_special_tokens=True)\n",
    "\n",
    "# Generate predictions\n",
    "preds = []\n",
    "batch_size = 1  # ByT5 eval is memory heavy; keep batch 1\n",
    "for i in range(0, len(val_texts), batch_size):\n",
    "    batch_preds = generate_batch(val_texts[i:i+batch_size])\n",
    "    preds.extend(batch_preds)\n",
    "    if (i // batch_size + 1) % 10 == 0:\n",
    "        print(f\"  Progress: {i+batch_size}/{len(val_texts)} samples processed\")\n",
    "\n",
    "preds = postprocess_text(preds)\n",
    "\n",
    "# Compute all metrics\n",
    "print(\"\\nComputing metrics...\")\n",
    "bleu_result = metric_bleu.compute(predictions=preds, references=val_refs)\n",
    "bleu_score = bleu_result['score']\n",
    "\n",
    "chrf_result = metric_chrf.compute(predictions=preds, references=val_refs, word_order=2)\n",
    "chrf_score = chrf_result['score']\n",
    "\n",
    "# Geometric mean (competition metric)\n",
    "import math\n",
    "geo_mean = math.sqrt(bleu_score * chrf_score)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION RESULTS - BYT5 SPECIALIST MODEL\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Samples evaluated:  {len(val_texts)}\")\n",
    "print(f\"\")\n",
    "print(f\"BLEU Score:         {bleu_score:7.2f}\")\n",
    "print(f\"chrF++ Score:       {chrf_score:7.2f}\")\n",
    "print(f\"\")\n",
    "print(f\"\ud83c\udfc6 GEOMETRIC MEAN:  {geo_mean:7.2f}  \u2190 Challenge Metric\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show sample predictions\n",
    "print(\"\\n\ud83d\udcca SAMPLE PREDICTIONS (first 3):\")\n",
    "print(\"=\"*60)\n",
    "for i in range(min(3, len(val_texts))):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"  Source: {val_texts[i][:80]}...\")\n",
    "    print(f\"  Target: {val_refs[i][0][:80]}...\")\n",
    "    print(f\"  Prediction: {preds[i][:80]}...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Score interpretation & comparison\n",
    "if geo_mean >= 35:\n",
    "    print(\"\ud83c\udf1f EXCELLENT! Specialist ByT5 achieving competition-winning level!\")\n",
    "elif geo_mean >= 30:\n",
    "    print(\"\u2728 GREAT! Strong translation quality, top quartile expected.\")\n",
    "elif geo_mean >= 25:\n",
    "    print(\"\u2713 GOOD! Solid performance, room for improvement.\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  Score needs improvement. Consider:\")\n",
    "    print(\"   \u2022 More training epochs (try 22-24)\")\n",
    "    print(\"   \u2022 Data augmentation with back-translation\")\n",
    "    print(\"   \u2022 Curriculum learning strategies\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION COMPLETE - BYT5 SPECIALIST READY FOR SOUP\")\n",
    "print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df987458",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ByT5 Specialist: Robustness Playbook\n",
    "====================================\n",
    "\n",
    "1) Dropout + seed diversity\n",
    "   - Keep dropout_rate/attention_dropout_rate at 0.15.\n",
    "   - Train multiple seeds (e.g., 999, 1234) and soup/average checkpoints.\n",
    "\n",
    "2) Language modeling refresh\n",
    "   - Run a short MLM warmup on unlabeled Akkadian (span masking) before fine-tuning.\n",
    "\n",
    "3) Decoding for stability\n",
    "   - num_beams=6\u20138, no_repeat_ngram_size=3\u20134, repetition_penalty\u22481.1\u20131.2.\n",
    "   - Length_penalty\u22481.0\u20131.2 to avoid truncation on longer tablets.\n",
    "\n",
    "4) Data mixing\n",
    "   - Mix mined data at 50\u201370% of the supervised volume to encourage robustness.\n",
    "   - Keep gaps (<gap>/<big_gap>) intact; they help the model learn structure.\n",
    "\n",
    "5) Checkpoint smoothing\n",
    "   - Average the last 2\u20133 checkpoints; improves variance from high dropout.\n",
    "\n",
    "6) Curriculum ideas\n",
    "   - Start with shorter sequences (<=256) for 1\u20132 epochs, then train full length.\n",
    "\n",
    "Score targets\n",
    "-------------\n",
    "- Baseline (current config): geometric mean \u224830\u201333\n",
    "- With smoothing + decoding tweaks: \u224833\u201335\n",
    "- With MLM warmup + curriculum: \u224835\u201336\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\ud83d\udcda ByT5 SPECIALIST TUNING NOTES LOADED\")\n",
    "print(\"=\"*60)\n",
    "print(\"Focus: dropout robustness, MLM warmup, checkpoint smoothing, decoding hygiene\")\n",
    "print(\"Target: 33\u201336 geometric mean with enhancements\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d194cec",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Next Steps: ByT5 Specialist Tuning Checklist\n",
    "\n",
    "- Keep dropout_rate/attention_dropout_rate \u22480.15; train 2\u20133 seeds and average.\n",
    "- Add a short MLM warmup on unlabeled Akkadian before supervised finetuning.\n",
    "- Decode with beams 6\u20138, no-repeat n-gram, repetition_penalty\u22481.1\u20131.2, length_penalty\u22481.1.\n",
    "- Mix mined data (50\u201370%) with supervised pairs to improve robustness.\n",
    "- Average last 2\u20133 checkpoints before saving the final model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8e3fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend training and generation parameters (safe toggles)\n",
    "training_args.num_train_epochs = max(getattr(training_args, \"num_train_epochs\", 22), 24)\n",
    "training_args.lr_scheduler_type = \"cosine_with_restarts\"\n",
    "training_args.warmup_ratio = 0.08\n",
    "training_args.weight_decay = 0.01\n",
    "training_args.generation_num_beams = max(getattr(training_args, \"generation_num_beams\", 1), 10)\n",
    "\n",
    "print(\"Next steps applied: epochs>=24, cosine restarts, beams>=10.\")\n",
    "print(\"Evaluate language code sweeps, back-translation, beam search tuning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509bf04",
   "metadata": {},
   "source": [
    "## \ud83d\udd17 Sentence-Level Alignment with published_texts.csv\n",
    "\n",
    "Goal: Align mined English sentences from `mined_publications_en.csv` to Akkadian transliterations in `published_texts.csv` by matching catalog labels and aliases.\n",
    "\n",
    "Approach:\n",
    "- Load `published_texts.csv` (\u22488k rows) and `mined_publications_en.csv`.\n",
    "- Extract catalog-like refs (e.g., BIN VI 39, Kt 72/k, museum IDs) from each English sentence.\n",
    "- Fuzzy-match refs to `publication_catalog` or `aliases` in `published_texts.csv` using RapidFuzz.\n",
    "- Emit candidate parallel pairs to `aligned_pairs_candidates.csv` for manual review or automatic filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c47a55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align mined English sentences to transliterations via catalog/alias fuzzy matching\n",
    "!pip install -q rapidfuzz ftfy unidecode\n",
    "\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from rapidfuzz import fuzz, process\n",
    "from ftfy import fix_text\n",
    "from unidecode import unidecode\n",
    "\n",
    "PUBLISHED_TEXTS_PATH = os.getenv('PUBLISHED_TEXTS_CSV', 'published_texts.csv')\n",
    "MINED_EN_PATH = os.getenv('MINED_PUBLICATIONS_OUT', 'mined_publications_en.csv')\n",
    "ALIGNED_OUT_PATH = os.getenv('ALIGNED_PAIRS_OUT', 'aligned_pairs_candidates.csv')\n",
    "\n",
    "# Heuristic patterns for publication labels and catalog IDs (expandable)\n",
    "CATALOG_PATTERNS = [\n",
    "    r\"\\bBIN\\s+[IVXLCDM]+\\s*\\d+\\b\",        # e.g., BIN VI 39\n",
    "    r\"\\bKt\\.?\\s*\\d+/?[A-Za-z0-9-]*\\b\",     # e.g., Kt 72/k\n",
    "    r\"\\bBM\\s*\\d+[A-Za-z]?\\b\",              # British Museum IDs\n",
    "    r\"\\bYBC\\s*\\d+\\b\",                      # Yale Babylonian Collection\n",
    "    r\"\\b(AbB|AKT|CCT|KBo|KUB)\\s*\\d+[A-Za-z0-9-]*\\b\",  # Common series\n",
    "]\n",
    "\n",
    "\n",
    "def extract_catalog_refs(text: str) -> list:\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    text = fix_text(text)\n",
    "    text = unidecode(text)\n",
    "    refs = set()\n",
    "    for pat in CATALOG_PATTERNS:\n",
    "        for m in re.finditer(pat, text, flags=re.IGNORECASE):\n",
    "            ref = m.group(0).strip()\n",
    "            # Normalize spaces and punctuation\n",
    "            ref = re.sub(r\"\\s+\", \" \", ref)\n",
    "            refs.add(ref)\n",
    "    return list(refs)\n",
    "\n",
    "\n",
    "def build_alias_index(df: pd.DataFrame):\n",
    "    \"\"\"Build a search index over publication_catalog and aliases fields.\"\"\"\n",
    "    index_records = []\n",
    "    for i, row in df.iterrows():\n",
    "        rid = i\n",
    "        label = str(row.get('label', '') or '')\n",
    "        pubcat = str(row.get('publication_catalog', '') or '')\n",
    "        aliases = str(row.get('aliases', '') or '')\n",
    "        # Split on bars and commas for multiple entries\n",
    "        tokens = []\n",
    "        for field in (pubcat, aliases, label):\n",
    "            parts = re.split(r\"[|,;]\", field)\n",
    "            for p in parts:\n",
    "                p = unidecode(p.strip())\n",
    "                if p:\n",
    "                    tokens.append(p)\n",
    "        # Keep unique tokens\n",
    "        tokens = list(dict.fromkeys(tokens))\n",
    "        index_records.append({\n",
    "            'rid': rid,\n",
    "            'tokens': tokens,\n",
    "        })\n",
    "    return index_records\n",
    "\n",
    "\n",
    "def find_matches(refs: list, index_records: list, score_cutoff: int = 85):\n",
    "    \"\"\"For each ref, fuzzy-match against index tokens and return candidate row indices.\"\"\"\n",
    "    candidates = set()\n",
    "    for ref in refs:\n",
    "        for rec in index_records:\n",
    "            # Use token_set_ratio for forgiving matching\n",
    "            for tok in rec['tokens']:\n",
    "                score = fuzz.token_set_ratio(ref, tok)\n",
    "                if score >= score_cutoff:\n",
    "                    candidates.add(rec['rid'])\n",
    "                    break\n",
    "    return list(candidates)\n",
    "\n",
    "\n",
    "def align_sentences(mined_path: str, published_path: str, out_path: str):\n",
    "    # Load published texts\n",
    "    pub_df = pd.read_csv(published_path)\n",
    "    # Defensive: ensure needed columns exist\n",
    "    for col in ['transliteration', 'publication_catalog', 'aliases', 'label']:\n",
    "        if col not in pub_df.columns:\n",
    "            pub_df[col] = ''\n",
    "    # Build alias index\n",
    "    alias_index = build_alias_index(pub_df)\n",
    "\n",
    "    # Prepare output\n",
    "    Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    written = 0\n",
    "    total = 0\n",
    "\n",
    "    with open(out_path, 'w', newline='', encoding='utf-8') as f_out:\n",
    "        writer = csv.writer(f_out)\n",
    "        writer.writerow(['pdf_name', 'page', 'english_sentence', 'matched_label', 'transliteration'])\n",
    "\n",
    "        # Stream mined sentences to keep memory low\n",
    "        for chunk in pd.read_csv(mined_path, chunksize=5000):\n",
    "            for _, row in chunk.iterrows():\n",
    "                total += 1\n",
    "                pdf = str(row.get('pdf_name', '') or '')\n",
    "                page = int(row.get('page', -1)) if pd.notna(row.get('page')) else -1\n",
    "                sent = str(row.get('english_sentence', '') or '')\n",
    "                if not sent:\n",
    "                    continue\n",
    "                refs = extract_catalog_refs(sent)\n",
    "                if not refs:\n",
    "                    continue  # No catalog hint; skip for now\n",
    "                # Find candidate rows\n",
    "                cand_ids = find_matches(refs, alias_index, score_cutoff=85)\n",
    "                for rid in cand_ids:\n",
    "                    t_row = pub_df.iloc[rid]\n",
    "                    matched_label = str(t_row.get('label', '') or '')\n",
    "                    translit = str(t_row.get('transliteration', '') or '')\n",
    "                    if translit:\n",
    "                        writer.writerow([pdf, page, sent, matched_label, translit])\n",
    "                        written += 1\n",
    "            if total % 10000 == 0:\n",
    "                print(f\"Processed {total} sentences; wrote {written} candidate pairs...\")\n",
    "\n",
    "    print(f\"Alignment complete. Total sentences: {total}, candidates written: {written}\")\n",
    "    print(f\"Saved to: {out_path}\")\n",
    "\n",
    "\n",
    "print(\"Starting alignment: mined_publications_en.csv \u2192 published_texts.csv (catalog/alias matching)\")\n",
    "align_sentences(MINED_EN_PATH, PUBLISHED_TEXTS_PATH, ALIGNED_OUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37f8d93",
   "metadata": {},
   "source": [
    "## \u2705 Quality Filter & Summary\n",
    "\n",
    "**\u26a0\ufe0f PREREQUISITE: Run the alignment cell above first to generate `aligned_pairs_candidates.csv`.**\n",
    "\n",
    "Filter aligned pairs for training quality:\n",
    "- Remove pairs where transliteration or English is too short/long\n",
    "- Discard pairs with extreme length ratios (likely misaligned)\n",
    "- Keep pairs with domain terms or high lexicon match\n",
    "- Sample results for sanity check\n",
    "- Output: `aligned_pairs_filtered.csv` ready for training augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaba540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "ALIGNED_PATH = os.getenv('ALIGNED_PAIRS_OUT', 'aligned_pairs_candidates.csv')\n",
    "FILTERED_OUT_PATH = os.getenv('FILTERED_PAIRS_OUT', 'aligned_pairs_filtered.csv')\n",
    "\n",
    "def filter_quality(aligned_path: str, out_path: str):\n",
    "    \"\"\"Filter aligned pairs for training quality.\"\"\"\n",
    "    df = pd.read_csv(aligned_path)\n",
    "    print(f\"Loaded {len(df)} candidate pairs\")\n",
    "    \n",
    "    # Length filters\n",
    "    df['t_len'] = df['transliteration'].str.split().str.len()\n",
    "    df['e_len'] = df['english_sentence'].str.split().str.len()\n",
    "    \n",
    "    # Apply filters\n",
    "    df_filtered = df[\n",
    "        (df['t_len'] >= 3) & (df['t_len'] <= 150) &\n",
    "        (df['e_len'] >= 3) & (df['e_len'] <= 150) &\n",
    "        (df['t_len'] / (df['e_len'] + 1) >= 0.5) &\n",
    "        (df['t_len'] / (df['e_len'] + 1) <= 3.0)\n",
    "    ].copy()\n",
    "    \n",
    "    domain_terms = ['tablet', 'seal', 'silver', 'tin', 'letter', 'text', 'archive', 'merchant', 'trade']\n",
    "    df_filtered['has_domain'] = df_filtered['english_sentence'].str.lower().str.contains('|'.join(domain_terms), na=False)\n",
    "    \n",
    "    df_filtered[['pdf_name', 'page', 'english_sentence', 'matched_label', 'transliteration']].to_csv(out_path, index=False)\n",
    "    \n",
    "    print(f\"After quality filtering: {len(df_filtered)} pairs retained\")\n",
    "    print(f\"Saved to: {out_path}\\n\")\n",
    "    \n",
    "    print(\"Sample aligned pairs (first 5):\")\n",
    "    for i, row in df_filtered.head(5).iterrows():\n",
    "        print(f\"\\n[{i}]\")\n",
    "        print(f\"  EN: {row['english_sentence'][:80]}...\")\n",
    "        print(f\"  AK: {row['transliteration'][:80]}...\")\n",
    "    \n",
    "    return len(df_filtered)\n",
    "\n",
    "count = filter_quality(ALIGNED_PATH, FILTERED_OUT_PATH)\n",
    "print(f\"\\n\u2713 Quality filtering complete. {count} high-quality pairs ready for training augmentation.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 15061024,
     "sourceId": 121150,
     "sourceType": "competition"
    },
    {
     "datasetId": 9082937,
     "sourceId": 14236819,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 650.176672,
   "end_time": "2025-12-25T11:19:18.784764",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-25T11:08:28.608092",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "006e704aa6c944859bb0012667971140": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0da07a92ee1145c6ba75f73034a80896": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0f40ba21fc344bfeb6fc29b276337ca9",
       "placeholder": "\u200b",
       "style": "IPY_MODEL_782121dc5bf5409787b423d190a97a2a",
       "tabbable": null,
       "tooltip": null,
       "value": "Map:\u2007100%"
      }
     },
     "0f40ba21fc344bfeb6fc29b276337ca9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1a7c757198d04482967f172c44c07168": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1d1e2d02d3994b8197c937fe0cd36768": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1e6586f643174c608f4af4c3fa7cc77b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1e9adeda3aad4a82b53cc784c141c0cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e127272439614b07988bebdd9358f449",
       "placeholder": "\u200b",
       "style": "IPY_MODEL_a649a617000146cc901c681c0d541f1c",
       "tabbable": null,
       "tooltip": null,
       "value": "\u20078.15k/?\u2007[00:00&lt;00:00,\u2007851kB/s]"
      }
     },
     "1f09169e8dde4a9db3cf0afe7543792b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "23f123af2ed94e98ba76c3a0886fe02b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bb984c93171c4674b03816e7b09e0147",
        "IPY_MODEL_c78541bb1cc042689e463e891c1676f9",
        "IPY_MODEL_37ad3d25de25423aa68dd0c2f185de10"
       ],
       "layout": "IPY_MODEL_1a7c757198d04482967f172c44c07168",
       "tabbable": null,
       "tooltip": null
      }
     },
     "276b62defb65456b92ddf9b0470f142e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28a277a8fb104456a74d691689c840b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7359401f7fa644938932f706306c8ab3",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6a4867292379424b83eca085157110c6",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "2b2198dbdcb74158b34bf460b63dd7cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "37ad3d25de25423aa68dd0c2f185de10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e5f6bd19bbb34b569bb667df055db4ae",
       "placeholder": "\u200b",
       "style": "IPY_MODEL_006e704aa6c944859bb0012667971140",
       "tabbable": null,
       "tooltip": null,
       "value": "\u20071452/1452\u2007[00:03&lt;00:00,\u2007476.19\u2007examples/s]"
      }
     },
     "467e02d583c54e7fb140d85cf10d28a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_66a1a97c09324c50964b24bd04a2fc5c",
        "IPY_MODEL_28a277a8fb104456a74d691689c840b8",
        "IPY_MODEL_1e9adeda3aad4a82b53cc784c141c0cb"
       ],
       "layout": "IPY_MODEL_865eb4fb87fe413db56a281d5e7bdc70",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4dc297123ac24df1b75b584d9c7f701a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "52f062255cd941e3bb5d9b9e9616c805": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bd7545197a1349deaa902dfd002c54cb",
       "placeholder": "\u200b",
       "style": "IPY_MODEL_940b13d03342464b968e822ed411db2c",
       "tabbable": null,
       "tooltip": null,
       "value": "\u20079.01k/?\u2007[00:00&lt;00:00,\u20071.02MB/s]"
      }
     },
     "54ac63530acd4a7ea511996d18038415": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c9b8c2b47124449b80f89fc38d88cc18",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b71c04220ae84ed398f80345103403af",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "63f470b1c69a4b659c397a9131a1787e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "66a1a97c09324c50964b24bd04a2fc5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e3ff9f8522974d489a6602947050b1f5",
       "placeholder": "\u200b",
       "style": "IPY_MODEL_83b4199739ff4dbfa7fd6045b6592888",
       "tabbable": null,
       "tooltip": null,
       "value": "Downloading\u2007builder\u2007script:\u2007"
      }
     },
     "6a4867292379424b83eca085157110c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7359401f7fa644938932f706306c8ab3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "782121dc5bf5409787b423d190a97a2a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "83b4199739ff4dbfa7fd6045b6592888": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "865eb4fb87fe413db56a281d5e7bdc70": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "940b13d03342464b968e822ed411db2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "96980b824d484b4bb658d91f3181f000": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0da07a92ee1145c6ba75f73034a80896",
        "IPY_MODEL_fc47b1bb981d45e0b731240619bbe710",
        "IPY_MODEL_b8f18ea2ddb64b4c8db2e1e4f2fa45b4"
       ],
       "layout": "IPY_MODEL_1d1e2d02d3994b8197c937fe0cd36768",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a649a617000146cc901c681c0d541f1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b71c04220ae84ed398f80345103403af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b81ee50a854d42cbb085b2d6ed88f651": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_dece704073e744fcb2777ac3e8d7a2f9",
        "IPY_MODEL_54ac63530acd4a7ea511996d18038415",
        "IPY_MODEL_52f062255cd941e3bb5d9b9e9616c805"
       ],
       "layout": "IPY_MODEL_4dc297123ac24df1b75b584d9c7f701a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b8f18ea2ddb64b4c8db2e1e4f2fa45b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1e6586f643174c608f4af4c3fa7cc77b",
       "placeholder": "\u200b",
       "style": "IPY_MODEL_2b2198dbdcb74158b34bf460b63dd7cb",
       "tabbable": null,
       "tooltip": null,
       "value": "\u200777/77\u2007[00:00&lt;00:00,\u2007461.19\u2007examples/s]"
      }
     },
     "bb984c93171c4674b03816e7b09e0147": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_be798dbd13b14c2fb91107dfb5f8d54f",
       "placeholder": "\u200b",
       "style": "IPY_MODEL_fde531abd1984d699ff0f100cd4e39ec",
       "tabbable": null,
       "tooltip": null,
       "value": "Map:\u2007100%"
      }
     },
     "bd7545197a1349deaa902dfd002c54cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "be798dbd13b14c2fb91107dfb5f8d54f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c78541bb1cc042689e463e891c1676f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_63f470b1c69a4b659c397a9131a1787e",
       "max": 1452,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e489c3a4e6184a24b04e1fb646771f00",
       "tabbable": null,
       "tooltip": null,
       "value": 1452
      }
     },
     "c9b8c2b47124449b80f89fc38d88cc18": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "d0db33fadcf1494b976a13cb382b0610": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "da06d7bfd43b40f5af5ad66daef05398": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "dece704073e744fcb2777ac3e8d7a2f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1f09169e8dde4a9db3cf0afe7543792b",
       "placeholder": "\u200b",
       "style": "IPY_MODEL_d0db33fadcf1494b976a13cb382b0610",
       "tabbable": null,
       "tooltip": null,
       "value": "Downloading\u2007builder\u2007script:\u2007"
      }
     },
     "e127272439614b07988bebdd9358f449": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e3ff9f8522974d489a6602947050b1f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e489c3a4e6184a24b04e1fb646771f00": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e5f6bd19bbb34b569bb667df055db4ae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc47b1bb981d45e0b731240619bbe710": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_276b62defb65456b92ddf9b0470f142e",
       "max": 77,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_da06d7bfd43b40f5af5ad66daef05398",
       "tabbable": null,
       "tooltip": null,
       "value": 77
      }
     },
     "fde531abd1984d699ff0f100cd4e39ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}