{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":121150,"databundleVersionId":14976537,"sourceType":"competition"},{"sourceId":14236819,"sourceType":"datasetVersion","datasetId":9082937}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T17:13:42.877253Z","iopub.execute_input":"2025-12-20T17:13:42.877535Z","iopub.status.idle":"2025-12-20T17:13:43.042772Z","shell.execute_reply.started":"2025-12-20T17:13:42.877504Z","shell.execute_reply":"2025-12-20T17:13:43.041941Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q evaluate sacrebleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T17:13:43.045096Z","iopub.execute_input":"2025-12-20T17:13:43.045555Z","iopub.status.idle":"2025-12-20T17:13:48.057972Z","shell.execute_reply.started":"2025-12-20T17:13:43.045506Z","shell.execute_reply":"2025-12-20T17:13:48.057158Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# B1. Imports & Configuration","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport gc\nimport pandas as pd\nimport torch\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer, \n    AutoModelForSeq2SeqLM, \n    DataCollatorForSeq2Seq, \n    Seq2SeqTrainer, \n    Seq2SeqTrainingArguments\n)\n\n# --- Configuration ---\n# Path provided by you for Notebook B\nMODEL_PATH = \"/kaggle/input/models-for-dpc/pretrained_models/t5-base\"\nDATA_DIR = \"/kaggle/input/deep-past-initiative-machine-translation\"\nOUTPUT_DIR = \"./t5-base-fine-tuned\"\n\n# T5 uses subwords, so sequences are shorter than ByT5. \n# 256 is usually sufficient for sentence-level Akkadian.\nMAX_LENGTH = 266 \n\n# T5 is a multi-task model, so we must provide a task prefix.\nPREFIX = \"translate Akkadian to English: \"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T17:13:48.059313Z","iopub.execute_input":"2025-12-20T17:13:48.059638Z","iopub.status.idle":"2025-12-20T17:14:16.286938Z","shell.execute_reply.started":"2025-12-20T17:13:48.059601Z","shell.execute_reply":"2025-12-20T17:14:16.286147Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# B2. Data Loading & Alignment","metadata":{}},{"cell_type":"code","source":"def load_and_align_data(filepath):\n    \"\"\"\n    Aligns Akkadian transliterations to English translations.\n    Tries to split by line/sentence; falls back to document-level if counts mismatch.\n    \"\"\"\n    df = pd.read_csv(filepath)\n    aligned_rows = []\n\n    print(f\"Raw documents: {len(df)}\")\n\n    for _, row in df.iterrows():\n        src = str(row[\"transliteration\"]).strip()\n        tgt = str(row[\"translation\"]).strip()\n\n        # Split source by newlines (standard cuneiform formatting)\n        src_lines = [s.strip() for s in src.split(\"\\n\") if len(s.strip()) > 1]\n        \n        # Split target by sentence punctuation (. ! ?)\n        tgt_sents = [t.strip() for t in re.split(r'(?<=[.!?])\\s+', tgt) if len(t.strip()) > 1]\n\n        # Heuristic: If line counts match, assume 1:1 alignment\n        if len(src_lines) == len(tgt_sents) and len(src_lines) > 1:\n            for s, t in zip(src_lines, tgt_sents):\n                aligned_rows.append({\"src\": s, \"tgt\": t})\n        else:\n            # Fallback: Use the whole document to avoid data loss\n            aligned_rows.append({\"src\": src.replace(\"\\n\", \" \"), \"tgt\": tgt})\n\n    print(f\"Aligned training examples: {len(aligned_rows)}\")\n    return pd.DataFrame(aligned_rows)\n\n# Load and Split Data\ndf = load_and_align_data(f\"{DATA_DIR}/train.csv\")\ndataset = Dataset.from_pandas(df)\n\n# 95% Train / 5% Validation\ndataset = dataset.train_test_split(test_size=0.05, seed=42)\nprint(\"Data loaded successfully.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-20T17:14:16.287892Z","iopub.execute_input":"2025-12-20T17:14:16.288551Z","iopub.status.idle":"2025-12-20T17:14:16.489976Z","shell.execute_reply.started":"2025-12-20T17:14:16.288524Z","shell.execute_reply":"2025-12-20T17:14:16.489349Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# B3. Tokenization","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n\ndef preprocess_function(examples):\n    # Add prefix to inputs\n    inputs = [PREFIX + doc for doc in examples[\"src\"]]\n    targets = examples[\"tgt\"]\n\n    model_inputs = tokenizer(\n        inputs, \n        max_length=MAX_LENGTH, \n        truncation=True, \n        padding=\"max_length\"\n    )\n\n    labels = tokenizer(\n        targets, \n        max_length=MAX_LENGTH, \n        truncation=True, \n        padding=\"max_length\"\n    )\n\n    # Replace padding token id with -100 to ignore in loss calculation\n    labels[\"input_ids\"] = [\n        [(l if l != tokenizer.pad_token_id else -100) for l in label]\n        for label in labels[\"input_ids\"]\n    ]\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\n# Apply processing\ntokenized_train = dataset[\"train\"].map(preprocess_function, batched=True)\ntokenized_val = dataset[\"test\"].map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T17:14:16.490763Z","iopub.execute_input":"2025-12-20T17:14:16.491041Z","iopub.status.idle":"2025-12-20T17:14:19.118204Z","shell.execute_reply.started":"2025-12-20T17:14:16.490999Z","shell.execute_reply":"2025-12-20T17:14:19.117631Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# B4. Model Setup","metadata":{}},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH)\n\ndata_collator = DataCollatorForSeq2Seq(\n    tokenizer=tokenizer, \n    model=model,\n    label_pad_token_id=-100\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T17:14:19.119090Z","iopub.execute_input":"2025-12-20T17:14:19.119385Z","iopub.status.idle":"2025-12-20T17:14:20.599655Z","shell.execute_reply.started":"2025-12-20T17:14:19.119358Z","shell.execute_reply":"2025-12-20T17:14:20.599055Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# B5 . Training Configuration","metadata":{}},{"cell_type":"code","source":"# --- CORRECTED B5. Training Configuration (Disk Space Safe) ---\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=OUTPUT_DIR,\n    \n    # --- DISK SPACE FIXES ---\n    save_strategy=\"no\",           # Do NOT save checkpoints during training\n    eval_strategy=\"epoch\",        # Evaluate every epoch\n    load_best_model_at_end=False, # Must be False if we aren't saving checkpoints\n    # ------------------------\n    \n    learning_rate=2e-4, \n    \n    per_device_train_batch_size=4, \n    per_device_eval_batch_size=4,\n    gradient_accumulation_steps=4,\n    \n    num_train_epochs=7,\n    weight_decay=0.01,\n    predict_with_generate=True,\n    \n    fp16=True, # T5 is safe with fp16\n    report_to=\"none\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T17:14:20.601269Z","iopub.execute_input":"2025-12-20T17:14:20.601591Z","iopub.status.idle":"2025-12-20T17:14:20.754682Z","shell.execute_reply.started":"2025-12-20T17:14:20.601567Z","shell.execute_reply":"2025-12-20T17:14:20.754061Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# B6. Execution","metadata":{}},{"cell_type":"code","source":"# Clear cache before training\ntorch.cuda.empty_cache()\ngc.collect()\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)\n\nprint(\"Starting T5-Base Training...\")\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T17:14:20.755560Z","iopub.execute_input":"2025-12-20T17:14:20.755863Z","execution_failed":"2025-12-20T17:14:51.455Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# B7. Save Model","metadata":{}},{"cell_type":"code","source":"print(f\"Saving model to {OUTPUT_DIR}...\")\ntrainer.save_model(OUTPUT_DIR)\ntokenizer.save_pretrained(OUTPUT_DIR)\nprint(\"Notebook B (T5) Complete.\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-20T17:14:51.456Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}