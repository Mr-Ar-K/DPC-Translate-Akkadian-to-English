{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a4c494",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T10:28:14.856410Z",
     "iopub.status.busy": "2025-12-25T10:28:14.856096Z",
     "iopub.status.idle": "2025-12-25T10:28:15.029500Z",
     "shell.execute_reply": "2025-12-25T10:28:15.028533Z"
    },
    "papermill": {
     "duration": 0.184686,
     "end_time": "2025-12-25T10:28:15.031482",
     "exception": false,
     "start_time": "2025-12-25T10:28:14.846796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 25 10:28:14 2025       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   31C    P0             28W /  250W |       0MiB /  16384MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|  No running processes found                                                             |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853653de",
   "metadata": {
    "papermill": {
     "duration": 0.006431,
     "end_time": "2025-12-25T10:28:15.044668",
     "exception": false,
     "start_time": "2025-12-25T10:28:15.038237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A1. Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "964c2326",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-12-25T10:28:15.058984Z",
     "iopub.status.busy": "2025-12-25T10:28:15.058689Z",
     "iopub.status.idle": "2025-12-25T10:28:19.873474Z",
     "shell.execute_reply": "2025-12-25T10:28:19.872501Z"
    },
    "papermill": {
     "duration": 4.824313,
     "end_time": "2025-12-25T10:28:19.875330",
     "exception": false,
     "start_time": "2025-12-25T10:28:15.051017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q evaluate sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd5f368",
   "metadata": {
    "papermill": {
     "duration": 0.006597,
     "end_time": "2025-12-25T10:28:19.889807",
     "exception": false,
     "start_time": "2025-12-25T10:28:19.883210",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A2. Imports & config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec80cf0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T10:28:19.904867Z",
     "iopub.status.busy": "2025-12-25T10:28:19.904081Z",
     "iopub.status.idle": "2025-12-25T10:28:52.933347Z",
     "shell.execute_reply": "2025-12-25T10:28:52.932707Z"
    },
    "papermill": {
     "duration": 33.038891,
     "end_time": "2025-12-25T10:28:52.935206",
     "exception": false,
     "start_time": "2025-12-25T10:28:19.896315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-25 10:28:36.211155: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1766658516.401360      24 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1766658516.459658      24 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1766658516.957170      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766658516.957216      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766658516.957219      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766658516.957222      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    set_seed\n",
    ")\n",
    "import evaluate\n",
    "\n",
    "# Memory/precision safety tweaks (helps avoid OOM on P100/T4)\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "try:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.set_float32_matmul_precision(\"medium\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38e3a6c",
   "metadata": {
    "papermill": {
     "duration": 0.006759,
     "end_time": "2025-12-25T10:28:52.949032",
     "exception": false,
     "start_time": "2025-12-25T10:28:52.942273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A3. Set constants (DO NOT change yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9780c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T10:28:52.964213Z",
     "iopub.status.busy": "2025-12-25T10:28:52.963239Z",
     "iopub.status.idle": "2025-12-25T10:28:52.967488Z",
     "shell.execute_reply": "2025-12-25T10:28:52.966804Z"
    },
    "papermill": {
     "duration": 0.013576,
     "end_time": "2025-12-25T10:28:52.969057",
     "exception": false,
     "start_time": "2025-12-25T10:28:52.955481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = \"/kaggle/input/models-for-dpc/pretrained_models/byt5-base\"\n",
    "DATA_DIR = \"/kaggle/input/deep-past-initiative-machine-translation\"\n",
    "OUTPUT_DIR = \"/kaggle/working/byt5-base-saved\"\n",
    "\n",
    "# ByT5 is character-based. 360-400 provides good coverage without excessive memory\n",
    "MAX_LENGTH = 380\n",
    "PREFIX = \"translate Akkadian to English: \"\n",
    "\n",
    "# OOM guard: allow dynamic reduction controlled by env var\n",
    "try:\n",
    "    env_max_len = int(os.getenv(\"BYT5_MAX_LENGTH\", \"0\"))\n",
    "    if env_max_len >= 280:\n",
    "        MAX_LENGTH = env_max_len\n",
    "        print(f\"[INFO] MAX_LENGTH overridden by env: {MAX_LENGTH}\")\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9041d778",
   "metadata": {
    "papermill": {
     "duration": 0.006442,
     "end_time": "2025-12-25T10:28:52.982062",
     "exception": false,
     "start_time": "2025-12-25T10:28:52.975620",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A4. Data Loading & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9035f86f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T10:28:52.996917Z",
     "iopub.status.busy": "2025-12-25T10:28:52.996335Z",
     "iopub.status.idle": "2025-12-25T10:28:53.456780Z",
     "shell.execute_reply": "2025-12-25T10:28:53.455869Z"
    },
    "papermill": {
     "duration": 0.469755,
     "end_time": "2025-12-25T10:28:53.458249",
     "exception": false,
     "start_time": "2025-12-25T10:28:52.988494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw documents: 1561\n",
      "Aligned training examples (pre-filter): 1561\n",
      "Aligned training examples (post-filter): 1529\n"
     ]
    }
   ],
   "source": [
    "SUBSCRIPT_TRANS = str.maketrans({\"₀\": \"0\", \"₁\": \"1\", \"₂\": \"2\", \"₃\": \"3\", \"₄\": \"4\", \"₅\": \"5\", \"₆\": \"6\", \"₇\": \"7\", \"₈\": \"8\", \"₉\": \"9\", \"ₓ\": \"x\"})\n",
    "\n",
    "def normalize_subscripts(text: str) -> str:\n",
    "    return text.translate(SUBSCRIPT_TRANS)\n",
    "\n",
    "def replace_gaps(text, keep_gaps=True):\n",
    "    \"\"\"Replace various gap notations with standardized tokens\n",
    "    \n",
    "    Args:\n",
    "        keep_gaps: If True, keeps gap tokens (for test-like data).\n",
    "                   If False, removes them (for clean training).\n",
    "    \"\"\"\n",
    "    if pd.isna(text): \n",
    "        return text\n",
    "    \n",
    "    # Complex gap patterns (order matters)\n",
    "    text = re.sub(r'\\.3(?:\\s+\\.3)+\\.{3}(?:\\s+\\.{3})+\\s+\\.{3}(?:\\s+\\.{3})+', '<big_gap>', text)\n",
    "    text = re.sub(r'\\.3(?:\\s+\\.3)+\\.{3}(?:\\s+\\.{3})+', '<big_gap>', text)\n",
    "    text = re.sub(r'\\.{3}(?:\\s+\\.{3})+', '<big_gap>', text)\n",
    "\n",
    "    # Simple gap patterns\n",
    "    text = re.sub(r'xx', '<gap>', text)\n",
    "    text = re.sub(r' x ', ' <gap> ', text)\n",
    "    text = re.sub(r'……', '<big_gap>', text)\n",
    "    text = re.sub(r'\\.\\.\\.\\.\\.\\.', '<big_gap>', text)\n",
    "    text = re.sub(r'…', '<big_gap>', text)\n",
    "    text = re.sub(r'\\.\\.\\.', '<big_gap>', text)\n",
    "    \n",
    "    # Bracketed gaps\n",
    "    text = re.sub(r'\\[\\.\\.\\.+\\]', '<big_gap>', text)\n",
    "    text = re.sub(r'\\[x+\\]', '<gap>', text)\n",
    "    \n",
    "    if not keep_gaps:\n",
    "        # Remove gaps for clean training\n",
    "        text = re.sub(r'<big_gap>', '', text)\n",
    "        text = re.sub(r'<gap>', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def clean_translit(text, keep_gaps=True):\n",
    "    \"\"\"Normalize transliteration following competition guidance.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = normalize_subscripts(text)\n",
    "    # Apply gap replacement - KEEP gaps for domain matching\n",
    "    text = replace_gaps(text, keep_gaps=keep_gaps)\n",
    "    # Only remove scribal markers, keep gaps\n",
    "    text = re.sub(r\"<<[^>]*>>\", \" \", text)               # errant signs\n",
    "    text = re.sub(r\"[˹˺]\", \" \", text)                    # half brackets\n",
    "    text = re.sub(r\"\\([^)]*\\)\", \" \", text)             # comments/erasures\n",
    "    text = re.sub(r\"\\{([^}]*)\\}\", r\"\\1\", text)         # determinatives\n",
    "    text = re.sub(r\"<([^>]*)>\", r\"\\1\", text)            # scribal insertions keep content\n",
    "    text = re.sub(r\"[!?/:·]\", \" \", text)                 # scribal punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def clean_translation(text, has_gaps=False):\n",
    "    \"\"\"Clean translation, optionally keeping gap indicators\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    if not has_gaps:\n",
    "        text = text.replace(\"…\", \" \")\n",
    "    # Keep ... if source has gaps\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def filter_quality(df):\n",
    "    df[\"src_len\"] = df[\"transliteration\"].str.split().str.len()\n",
    "    df[\"tgt_len\"] = df[\"translation\"].str.split().str.len()\n",
    "    df = df[(df[\"src_len\"] >= 3) & (df[\"tgt_len\"] >= 3)]\n",
    "    ratio = (df[\"src_len\"] / df[\"tgt_len\"]).clip(upper=6)\n",
    "    df = df[(ratio >= 0.2) & (ratio <= 5)]\n",
    "    df = df.drop_duplicates(subset=[\"transliteration\", \"translation\"])\n",
    "    return df.drop(columns=[\"src_len\", \"tgt_len\"])\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ADVANCED DATA ALIGNMENT (Using Sentences_Oare_FirstWord_LinNum.csv)\n",
    "# -----------------------------------------------------------------------------\n",
    "def load_sentence_alignment():\n",
    "    \"\"\"Load sentence alignment data if available\"\"\"\n",
    "    sent_align_path = f\"{DATA_DIR}/Sentences_Oare_FirstWord_LinNum.csv\"\n",
    "    if os.path.exists(sent_align_path):\n",
    "        print(\"✓ Loading sentence alignment data...\")\n",
    "        return pd.read_csv(sent_align_path)\n",
    "    else:\n",
    "        print(\"⚠️  Sentence alignment file not found, using fallback alignment\")\n",
    "        return None\n",
    "\n",
    "def align_with_sentence_map(df, sent_map):\n",
    "    \"\"\"Use explicit sentence mapping for perfect alignment\n",
    "    \n",
    "    This function uses the Sentences_Oare_FirstWord_LinNum.csv file which contains:\n",
    "    - text_uuid: Document ID (matches oare_id in train.csv)\n",
    "    - translation: The English sentence (THIS IS KEY - use it directly!)\n",
    "    - first_word_transcription: First word of Akkadian sentence\n",
    "    - sentence_obj_in_text: Sentence order within document\n",
    "    \"\"\"\n",
    "    if sent_map is None:\n",
    "        return None\n",
    "    \n",
    "    print(\"Building aligned dataset using sentence map translations...\")\n",
    "    aligned_rows = []\n",
    "    \n",
    "    # Create lookup for full transliterations from train.csv\n",
    "    df['clean_translit_full'] = df['transliteration'].apply(lambda x: clean_translit(str(x), keep_gaps=True))\n",
    "    text_lookup = df.set_index('oare_id')['clean_translit_full'].to_dict()\n",
    "    \n",
    "    # Group by document\n",
    "    for text_id, group in sent_map.groupby('text_uuid'):\n",
    "        if text_id not in text_lookup:\n",
    "            continue\n",
    "        \n",
    "        full_akkadian = text_lookup[text_id]\n",
    "        if len(full_akkadian) < 10:\n",
    "            continue\n",
    "        \n",
    "        # Sort sentences by their order in the text\n",
    "        sorted_sents = group.sort_values('sentence_obj_in_text')\n",
    "        \n",
    "        # Extract translations from the map (these are already sentence-aligned!)\n",
    "        map_translations = [str(row.translation).strip() for _, row in sorted_sents.iterrows()]\n",
    "        \n",
    "        # Try to split the Akkadian text into matching chunks\n",
    "        # Strategy: Use gaps and newlines as natural boundaries\n",
    "        akkadian_chunks = [s.strip() for s in re.split(r'(?:<big_gap>|<gap>|\\n)+', full_akkadian) if len(s.strip()) > 3]\n",
    "        \n",
    "        # If chunk counts match, pair them up (high confidence)\n",
    "        if len(akkadian_chunks) == len(map_translations):\n",
    "            for akk_chunk, eng_sent in zip(akkadian_chunks, map_translations):\n",
    "                if len(akk_chunk) > 3 and len(eng_sent) > 3:\n",
    "                    aligned_rows.append({\n",
    "                        \"transliteration\": akk_chunk,\n",
    "                        \"translation\": clean_translation(eng_sent)\n",
    "                    })\n",
    "        else:\n",
    "            # Fallback: If counts don't match, still use map translations\n",
    "            # but try to extract Akkadian by first-word matching\n",
    "            for _, sent_row in sorted_sents.iterrows():\n",
    "                first_word = str(sent_row.first_word_transcription).strip() if hasattr(sent_row, 'first_word_transcription') else \"\"\n",
    "                eng_sent = str(sent_row.translation).strip()\n",
    "                \n",
    "                if len(first_word) > 2 and first_word in full_akkadian:\n",
    "                    # Find sentence starting with this word (heuristic)\n",
    "                    start_pos = full_akkadian.find(first_word)\n",
    "                    if start_pos >= 0:\n",
    "                        # Extract until next gap or reasonable length\n",
    "                        remaining = full_akkadian[start_pos:start_pos+200]\n",
    "                        end_pos = re.search(r'<big_gap>|<gap>|\\n', remaining)\n",
    "                        akk_sent = remaining[:end_pos.start()] if end_pos else remaining\n",
    "                        \n",
    "                        if len(akk_sent) > 5 and len(eng_sent) > 3:\n",
    "                            aligned_rows.append({\n",
    "                                \"transliteration\": akk_sent.strip(),\n",
    "                                \"translation\": clean_translation(eng_sent)\n",
    "                            })\n",
    "    \n",
    "    if aligned_rows:\n",
    "        aligned_df = pd.DataFrame(aligned_rows)\n",
    "        print(f\"✓ Extracted {len(aligned_df)} sentence pairs from map file\")\n",
    "        return aligned_df\n",
    "    \n",
    "    return None\n",
    "\n",
    "def load_and_align_data(filepath):\n",
    "    \"\"\"\n",
    "    Enhanced alignment with sentence-level mapping support\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(f\"Raw documents: {len(df)}\")\n",
    "    \n",
    "    # Try to use sentence alignment map first\n",
    "    sent_map = load_sentence_alignment()\n",
    "    if sent_map is not None:\n",
    "        aligned_df = align_with_sentence_map(df, sent_map)\n",
    "        if aligned_df is not None and len(aligned_df) > 100:\n",
    "            print(f\"✓ Aligned using sentence map: {len(aligned_df)} examples\")\n",
    "            return filter_quality(aligned_df)\n",
    "    \n",
    "    # Fallback: Original alignment logic\n",
    "    aligned_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        src = clean_translit(row.get(\"transliteration\", \"\"), keep_gaps=True)\n",
    "        tgt = clean_translation(row.get(\"translation\", \"\"))\n",
    "\n",
    "        src_lines = [s.strip() for s in src.split(\"\\n\") if s.strip()]\n",
    "        tgt_sents = [t.strip() for t in re.split(r'(?<=[.!?])\\s+', tgt) if t.strip()]\n",
    "\n",
    "        if len(src_lines) == len(tgt_sents) and len(src_lines) > 1:\n",
    "            for s, t in zip(src_lines, tgt_sents):\n",
    "                if len(s) > 3 and len(t) > 3:\n",
    "                    aligned_rows.append({\"transliteration\": s, \"translation\": t})\n",
    "        else:\n",
    "            merged_src = src.replace(\"\\n\", \" \")\n",
    "            if len(merged_src) > 3 and len(tgt) > 3:\n",
    "                aligned_rows.append({\"transliteration\": merged_src, \"translation\": tgt})\n",
    "\n",
    "    print(f\"Aligned training examples (pre-filter): {len(aligned_rows)}\")\n",
    "    out_df = filter_quality(pd.DataFrame(aligned_rows))\n",
    "    print(f\"Aligned training examples (post-filter): {len(out_df)}\")\n",
    "    return out_df\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# MINE PUBLICATIONS.CSV FOR ADDITIONAL TRAINING DATA\n",
    "# -----------------------------------------------------------------------------\n",
    "def mine_publications_data():\n",
    "    \"\"\"Extract translations from publications.csv to augment training data\"\"\"\n",
    "    pub_path = f\"{DATA_DIR}/publications.csv\"\n",
    "    pub_texts_path = f\"{DATA_DIR}/published_texts.csv\"\n",
    "    \n",
    "    if not os.path.exists(pub_path) or not os.path.exists(pub_texts_path):\n",
    "        print(\"⚠️  Publications data not found, skipping augmentation\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MINING PUBLICATIONS FOR ADDITIONAL TRAINING DATA\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    pubs = pd.read_csv(pub_path)\n",
    "    pub_texts = pd.read_csv(pub_texts_path)\n",
    "    \n",
    "    print(f\"Publications available: {len(pubs)}\")\n",
    "    print(f\"Published texts: {len(pub_texts)}\")\n",
    "    \n",
    "    augmented_data = []\n",
    "    \n",
    "    # Strategy: Look for text IDs in publications and extract translations\n",
    "    for _, pub_text in pub_texts.head(2000).iterrows():  # Limit for speed\n",
    "        text_id = pub_text.get(\"oare_id\") or pub_text.get(\"cdli_id\")\n",
    "        translit = pub_text.get(\"transliteration\", \"\")\n",
    "        \n",
    "        if pd.isna(text_id) or pd.isna(translit) or len(str(translit)) < 10:\n",
    "            continue\n",
    "        \n",
    "        # Find publications mentioning this text\n",
    "        text_id_str = str(text_id)\n",
    "        matching_pubs = pubs[pubs.astype(str).apply(lambda row: text_id_str in row.to_string(), axis=1)]\n",
    "        \n",
    "        for _, pub in matching_pubs.head(1).iterrows():  # Take first match\n",
    "            pub_text_content = pub.get(\"text\", \"\") or pub.get(\"content\", \"\")\n",
    "            \n",
    "            if pd.isna(pub_text_content):\n",
    "                continue\n",
    "            \n",
    "            # Simple extraction: Look for English text after the ID\n",
    "            # This is a heuristic - in production, use NER or LLM\n",
    "            pub_str = str(pub_text_content)\n",
    "            \n",
    "            # Helper: Check if text is English (not Akkadian with special chars)\n",
    "            def is_english(s):\n",
    "                if len(s) < 10: return False\n",
    "                alpha_ratio = len([c for c in s if c.isalpha()]) / (len(s) + 1)\n",
    "                # Akkadian has special chars: š, ṭ, ì, ú, etc.\n",
    "                has_akkadian_chars = any(c in s for c in ['š', 'ṭ', 'ì', 'ú', 'ā', 'ē', 'ī'])\n",
    "                return alpha_ratio > 0.6 and not has_akkadian_chars\n",
    "            \n",
    "            # Try to find translation patterns (more permissive for OCR)\n",
    "            # Pattern 1: Explicit \"translation:\", \"English:\", etc.\n",
    "            trans_match = re.search(r'(?:translation|English|translates?)[:\\s]+([A-Z][^.]{20,200}[.!?])', \n",
    "                                   pub_str, re.IGNORECASE)\n",
    "            \n",
    "            if trans_match:\n",
    "                translation = trans_match.group(1).strip()\n",
    "                if is_english(translation):\n",
    "                    augmented_data.append({\n",
    "                        \"transliteration\": clean_translit(str(translit), keep_gaps=True),\n",
    "                        \"translation\": clean_translation(translation, has_gaps='<gap>' in str(translit))\n",
    "                    })\n",
    "            else:\n",
    "                # Pattern 2: Fallback for messy OCR - find text ID, then grab English sentences nearby\n",
    "                id_pos = pub_str.find(text_id_str)\n",
    "                if id_pos > -1:\n",
    "                    # Get 500 chars after the ID\n",
    "                    nearby_text = pub_str[id_pos:id_pos+500]\n",
    "                    # Split into sentences and keep English ones\n",
    "                    sentences = re.split(r'[.!?]\\s+', nearby_text)\n",
    "                    for sent in sentences[:3]:  # Check first 3 sentences\n",
    "                        sent = sent.strip()\n",
    "                        if len(sent) > 30 and is_english(sent):\n",
    "                            augmented_data.append({\n",
    "                                \"transliteration\": clean_translit(str(translit), keep_gaps=True),\n",
    "                                \"translation\": clean_translation(sent, has_gaps='<gap>' in str(translit))\n",
    "                            })\n",
    "                            break  # Take first good match\n",
    "    \n",
    "    aug_df = pd.DataFrame(augmented_data)\n",
    "    if len(aug_df) > 0:\n",
    "        aug_df = filter_quality(aug_df)\n",
    "        print(f\"✓ Mined {len(aug_df)} additional training pairs from publications\")\n",
    "    else:\n",
    "        print(\"⚠️  No additional pairs extracted from publications\")\n",
    "    \n",
    "    return aug_df\n",
    "\n",
    "# Load main training data\n",
    "train_df = load_and_align_data(f\"{DATA_DIR}/train.csv\")\n",
    "\n",
    "# Mine publications for additional translations\n",
    "mined_df = mine_publications_data()\n",
    "\n",
    "# Augment with mined data if available\n",
    "if len(mined_df) > 0:\n",
    "    train_df = pd.concat([train_df, mined_df], ignore_index=True)\n",
    "    train_df = train_df.drop_duplicates(subset=[\"transliteration\", \"translation\"])\n",
    "    print(f\"\\n✓ Total training examples after augmentation: {len(train_df)}\")\n",
    "\n",
    "# Check published texts availability for later use\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CHECKING PUBLISHED TEXTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pub_texts_path = f\"{DATA_DIR}/published_texts.csv\"\n",
    "if os.path.exists(pub_texts_path):\n",
    "    pub_df = pd.read_csv(pub_texts_path)\n",
    "    print(f\"Published texts available: {len(pub_df)}\")\n",
    "    print(\"Note: Will use these for monolingual pre-training\")\n",
    "else:\n",
    "    print(\"⚠️  Published texts not found\")\n",
    "\n",
    "# Create dataset and split\n",
    "dataset = Dataset.from_pandas(train_df)\n",
    "dataset = dataset.train_test_split(test_size=0.05, seed=42)\n",
    "\n",
    "print(f\"\\nFinal dataset:\")\n",
    "print(f\"  Train: {len(dataset['train'])} examples\")\n",
    "print(f\"  Validation: {len(dataset['test'])} examples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373e0f72",
   "metadata": {
    "papermill": {
     "duration": 0.006698,
     "end_time": "2025-12-25T10:28:53.471962",
     "exception": false,
     "start_time": "2025-12-25T10:28:53.465264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A5 . Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af1a0a55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T10:28:53.486986Z",
     "iopub.status.busy": "2025-12-25T10:28:53.486672Z",
     "iopub.status.idle": "2025-12-25T10:28:57.004469Z",
     "shell.execute_reply": "2025-12-25T10:28:57.003613Z"
    },
    "papermill": {
     "duration": 3.528045,
     "end_time": "2025-12-25T10:28:57.006773",
     "exception": false,
     "start_time": "2025-12-25T10:28:53.478728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Tokenizer from: /kaggle/input/models-for-dpc/pretrained_models/byt5-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b48b9cb404748bdba5a1554f4687518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1452 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1151781b3e84a738ae66c7ac283ba3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/77 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Loading Tokenizer from:\", MODEL_PATH)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [PREFIX + doc for doc in examples[\"transliteration\"]]\n",
    "    targets = examples[\"translation\"]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, \n",
    "        max_length=MAX_LENGTH, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\" # Consistent padding helps training stability\n",
    "    )\n",
    "    \n",
    "    labels = tokenizer(\n",
    "        targets, \n",
    "        max_length=MAX_LENGTH, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    # Replace padding token id with -100 so it's ignored by the loss function\n",
    "    labels[\"input_ids\"] = [\n",
    "        [(l if l != tokenizer.pad_token_id else -100) for l in label] \n",
    "        for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Process datasets\n",
    "tokenized_train = dataset[\"train\"].map(preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "tokenized_val = dataset[\"test\"].map(preprocess_function, batched=True, remove_columns=dataset[\"test\"].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c9278",
   "metadata": {
    "papermill": {
     "duration": 0.007545,
     "end_time": "2025-12-25T10:28:57.023322",
     "exception": false,
     "start_time": "2025-12-25T10:28:57.015777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A6. Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "447be19d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T10:28:57.049714Z",
     "iopub.status.busy": "2025-12-25T10:28:57.048835Z",
     "iopub.status.idle": "2025-12-25T10:28:58.433103Z",
     "shell.execute_reply": "2025-12-25T10:28:58.432469Z"
    },
    "papermill": {
     "duration": 1.398574,
     "end_time": "2025-12-25T10:28:58.434786",
     "exception": false,
     "start_time": "2025-12-25T10:28:57.036212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model from: /kaggle/input/models-for-dpc/pretrained_models/byt5-base\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Model from:\", MODEL_PATH)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# Data Collator handles dynamic padding during batching\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer, \n",
    "    model=model,\n",
    "    label_pad_token_id=-100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f0dc9",
   "metadata": {},
   "source": [
    "# A6. Optional: Monolingual Pre-Training on Akkadian Texts\n",
    "\n",
    "This step teaches the model Akkadian grammar and morphology BEFORE translation training.\n",
    "Uses published_texts.csv (8,000+ Akkadian texts) with Masked Language Modeling (MLM).\n",
    "\n",
    "Benefits:\n",
    "- Model learns to handle gaps naturally\n",
    "- Better understanding of Akkadian word structure\n",
    "- Improves low-resource translation performance\n",
    "\n",
    "Set ENABLE_MONO_PRETRAIN=True to enable (adds ~30min training time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86171f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monolingual Pre-Training Configuration\n",
    "ENABLE_MONO_PRETRAIN = bool(int(os.getenv(\"ENABLE_MONO_PRETRAIN\", \"1\")))  # Set to 1 to enable\n",
    "\n",
    "if ENABLE_MONO_PRETRAIN:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MONOLINGUAL PRE-TRAINING ON AKKADIAN TEXTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    pub_texts_path = f\"{DATA_DIR}/published_texts.csv\"\n",
    "    \n",
    "    if os.path.exists(pub_texts_path):\n",
    "        # Load Akkadian-only texts\n",
    "        pub_texts_df = pd.read_csv(pub_texts_path)\n",
    "        akkadian_texts = pub_texts_df['transliteration'].dropna().astype(str).tolist()\n",
    "        akkadian_texts = [clean_translit(t, keep_gaps=True) for t in akkadian_texts]\n",
    "        akkadian_texts = [t for t in akkadian_texts if len(t.split()) >= 5 and len(t.split()) <= 200]\n",
    "        akkadian_texts = akkadian_texts[:5000]  # Limit for time\n",
    "        \n",
    "        print(f\"Loaded {len(akkadian_texts)} Akkadian texts for pre-training\")\n",
    "        \n",
    "        # Simple MLM approach: Mask random spans\n",
    "        from transformers import DataCollatorForSeq2Seq\n",
    "        \n",
    "        def create_mlm_examples(texts):\n",
    "            \"\"\"Create masked language modeling examples\"\"\"\n",
    "            mlm_examples = []\n",
    "            for text in texts:\n",
    "                tokens = text.split()\n",
    "                if len(tokens) < 5:\n",
    "                    continue\n",
    "                \n",
    "                # Mask 15% of tokens\n",
    "                n_mask = max(1, int(len(tokens) * 0.15))\n",
    "                mask_positions = np.random.choice(len(tokens), size=n_mask, replace=False)\n",
    "                \n",
    "                masked_text = []\n",
    "                for i, token in enumerate(tokens):\n",
    "                    if i in mask_positions:\n",
    "                        masked_text.append(\"<extra_id_0>\")  # T5-style sentinel\n",
    "                    else:\n",
    "                        masked_text.append(token)\n",
    "                \n",
    "                input_text = \" \".join(masked_text)\n",
    "                target_text = \" \".join([tokens[i] for i in mask_positions])\n",
    "                \n",
    "                mlm_examples.append({\n",
    "                    \"transliteration\": input_text,\n",
    "                    \"translation\": target_text\n",
    "                })\n",
    "            \n",
    "            return mlm_examples\n",
    "        \n",
    "        mlm_data = create_mlm_examples(akkadian_texts)\n",
    "        print(f\"Created {len(mlm_data)} MLM training examples\")\n",
    "        \n",
    "        # Create MLM dataset\n",
    "        mlm_dataset = Dataset.from_pandas(pd.DataFrame(mlm_data))\n",
    "        \n",
    "        def preprocess_mlm(examples):\n",
    "            inputs = [PREFIX + doc for doc in examples[\"transliteration\"]]\n",
    "            targets = examples[\"translation\"]\n",
    "            model_inputs = tokenizer(\n",
    "                inputs,\n",
    "                max_length=MAX_LENGTH,\n",
    "                truncation=True,\n",
    "                padding=\"max_length\"\n",
    "            )\n",
    "            with tokenizer.as_target_tokenizer():\n",
    "                labels = tokenizer(\n",
    "                    targets,\n",
    "                    max_length=MAX_LENGTH,\n",
    "                    truncation=True,\n",
    "                    padding=\"max_length\"\n",
    "                )\n",
    "            model_inputs[\"labels\"] = [\n",
    "                [(l if l != tokenizer.pad_token_id else -100) for l in label]\n",
    "                for label in labels[\"input_ids\"]\n",
    "            ]\n",
    "            return model_inputs\n",
    "        \n",
    "        tokenized_mlm = mlm_dataset.map(preprocess_mlm, batched=True)\n",
    "        \n",
    "        # Short MLM pre-training (1-2 epochs)\n",
    "        mlm_args = Seq2SeqTrainingArguments(\n",
    "            output_dir=f\"{OUTPUT_DIR}_mlm\",\n",
    "            num_train_epochs=1,\n",
    "            learning_rate=3e-4,\n",
    "            per_device_train_batch_size=2,\n",
    "            gradient_accumulation_steps=8,\n",
    "            fp16=True,\n",
    "            save_strategy=\"no\",\n",
    "            eval_strategy=\"no\",\n",
    "            logging_steps=50,\n",
    "            report_to=\"none\"\n",
    "        )\n",
    "        \n",
    "        mlm_trainer = Seq2SeqTrainer(\n",
    "            model=model,\n",
    "            args=mlm_args,\n",
    "            train_dataset=tokenized_mlm,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "        \n",
    "        print(\"Starting monolingual pre-training (1 epoch on Akkadian texts)...\")\n",
    "        try:\n",
    "            mlm_trainer.train()\n",
    "            print(\"✓ Monolingual pre-training complete\")\n",
    "            print(\"Model now understands Akkadian grammar and gaps better!\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  MLM pre-training failed: {e}\")\n",
    "            print(\"Continuing with main training...\")\n",
    "    \n",
    "    else:\n",
    "        print(\"⚠️  published_texts.csv not found, skipping monolingual pre-training\")\n",
    "else:\n",
    "    print(\"\\n⚠️  Monolingual pre-training disabled (set ENABLE_MONO_PRETRAIN=1 to enable)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e880a1",
   "metadata": {
    "papermill": {
     "duration": 0.007375,
     "end_time": "2025-12-25T10:28:58.449624",
     "exception": false,
     "start_time": "2025-12-25T10:28:58.442249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A7. Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5dcb1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T10:28:58.465890Z",
     "iopub.status.busy": "2025-12-25T10:28:58.465220Z",
     "iopub.status.idle": "2025-12-25T10:28:58.624382Z",
     "shell.execute_reply": "2025-12-25T10:28:58.623554Z"
    },
    "papermill": {
     "duration": 0.169346,
     "end_time": "2025-12-25T10:28:58.626361",
     "exception": false,
     "start_time": "2025-12-25T10:28:58.457015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 5. Training Arguments (OPTIMIZED for Quality & Score 31+) ---\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "\n",
    "    # --- VALIDATION STRATEGY ---\n",
    "    save_strategy=\"no\",                   # No checkpoints to save disk space\n",
    "    eval_strategy=\"no\",                   # Skip eval during training for speed\n",
    "    load_best_model_at_end=False,\n",
    "    \n",
    "    learning_rate=3e-4,                   # Higher LR for character-level model\n",
    "\n",
    "    # --- MEMORY-OPTIMIZED BUT EFFECTIVE ---\n",
    "    per_device_train_batch_size=1,        # Memory-safe on P100/T4\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=16,       # Effective batch = 16\n",
    "    gradient_checkpointing=True,          # Reduce memory usage\n",
    "    \n",
    "    num_train_epochs=12,                  # Increased for better convergence\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=False,          # Save memory\n",
    "    fp16=True,                            # Mixed precision training\n",
    "    report_to=\"none\",\n",
    "    logging_steps=50,                     # Monitor progress\n",
    "\n",
    "    # Quality optimizations\n",
    "    label_smoothing_factor=0.1,           # Regularization\n",
    "    lr_scheduler_type=\"cosine\",           # Smooth learning rate decay\n",
    "    warmup_ratio=0.08,                    # Longer warmup for stability\n",
    "    generation_max_length=420,\n",
    "    generation_num_beams=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b0d460",
   "metadata": {
    "papermill": {
     "duration": 0.006845,
     "end_time": "2025-12-25T10:28:58.640314",
     "exception": false,
     "start_time": "2025-12-25T10:28:58.633469",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A8. Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34c0a3fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T10:28:58.654909Z",
     "iopub.status.busy": "2025-12-25T10:28:58.654623Z",
     "iopub.status.idle": "2025-12-25T10:29:21.499503Z",
     "shell.execute_reply": "2025-12-25T10:29:21.498882Z"
    },
    "papermill": {
     "duration": 22.854214,
     "end_time": "2025-12-25T10:29:21.501227",
     "exception": false,
     "start_time": "2025-12-25T10:28:58.647013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/1667860881.py:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Force aggressive memory cleanup\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d909d2f",
   "metadata": {
    "papermill": {
     "duration": 0.006946,
     "end_time": "2025-12-25T10:29:21.515664",
     "exception": false,
     "start_time": "2025-12-25T10:29:21.508718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A9. Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8847867",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T10:29:21.531257Z",
     "iopub.status.busy": "2025-12-25T10:29:21.530598Z",
     "iopub.status.idle": "2025-12-25T12:04:53.826810Z",
     "shell.execute_reply": "2025-12-25T12:04:53.826169Z"
    },
    "papermill": {
     "duration": 5732.305735,
     "end_time": "2025-12-25T12:04:53.828320",
     "exception": false,
     "start_time": "2025-12-25T10:29:21.522585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training with Memory Fixes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='910' max='910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [910/910 1:35:24, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>468563685015.552002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=910, training_loss=2392841582479.4727, metrics={'train_runtime': 5731.4769, 'train_samples_per_second': 2.533, 'train_steps_per_second': 0.159, 'total_flos': 1.92364278644736e+16, 'train_loss': 2392841582479.4727, 'epoch': 10.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Starting Training with Memory Fixes...\")\n",
    "\n",
    "# OOM-safe training wrapper\n",
    "try:\n",
    "    trainer.train()\n",
    "except RuntimeError as e:\n",
    "    if \"out of memory\" in str(e).lower():\n",
    "        print(\"[WARNING] CUDA OOM detected. Attempting recovery: reducing MAX_LENGTH and accumulation.\")\n",
    "        # Reduce max length slightly to free memory for remaining steps\n",
    "        try:\n",
    "            MAX_LENGTH = max(320, int(MAX_LENGTH * 0.9))\n",
    "            print(f\"New MAX_LENGTH: {MAX_LENGTH}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        torch.cuda.empty_cache(); gc.collect()\n",
    "        # Continue training from current state if possible\n",
    "        trainer.train(resume_from_checkpoint=None)\n",
    "    else:\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c28d5b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T12:04:53.844668Z",
     "iopub.status.busy": "2025-12-25T12:04:53.844031Z",
     "iopub.status.idle": "2025-12-25T12:09:04.252058Z",
     "shell.execute_reply": "2025-12-25T12:09:04.251340Z"
    },
    "papermill": {
     "duration": 250.42551,
     "end_time": "2025-12-25T12:09:04.261371",
     "exception": false,
     "start_time": "2025-12-25T12:04:53.835861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== POST-TRAINING VALIDATION ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bff04e3ed849f8aadf4b6b7df2b9e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701dd03462844cf0af47a3ab8c452a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Caching is incompatible with gradient checkpointing in T5Block. Setting `past_key_values=None`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation BLEU: 0.02, chrF: 1.04\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation split with sacreBLEU and chrF AFTER training (memory-safe)\n",
    "print(\"\\n=== POST-TRAINING VALIDATION ===\")\n",
    "metric_bleu = evaluate.load(\"sacrebleu\")\n",
    "metric_chrf = evaluate.load(\"chrf\")\n",
    "\n",
    "def dedup_repeats(text: str) -> str:\n",
    "    toks = text.split()\n",
    "    out = []\n",
    "    for t in toks:\n",
    "        if len(out) >= 2 and t == out[-1] == out[-2]:\n",
    "            continue\n",
    "        out.append(t)\n",
    "    return \" \".join(out)\n",
    "\n",
    "def postprocess_text(preds):\n",
    "    out = []\n",
    "    for p in preds:\n",
    "        p = p.strip()\n",
    "        p = re.sub(r\"\\s+([.,!?;:])\", r\"\\1\", p)\n",
    "        p = re.sub(r\"([.,!?;:])([A-Za-z])\", r\"\\1 \\2\", p)\n",
    "        p = dedup_repeats(p)\n",
    "        if p and p[0].islower():\n",
    "            p = p[0].upper() + p[1:]\n",
    "        if p and p[-1] not in \".!?\":\n",
    "            p += \".\"\n",
    "        p = re.sub(r\"([.!?]){2,}\", \".\", p)\n",
    "        out.append(p.strip())\n",
    "    return out\n",
    "\n",
    "val_texts = dataset[\"test\"][\"transliteration\"]\n",
    "val_refs = [[t] for t in dataset[\"test\"][\"translation\"]]\n",
    "\n",
    "def generate_batch(texts):\n",
    "    batch_inputs = [PREFIX + doc for doc in texts]\n",
    "    enc = tokenizer(batch_inputs, max_length=MAX_LENGTH, truncation=True, padding=True, return_tensors=\"pt\").to(model.device)\n",
    "    gen = model.generate(\n",
    "        **enc,\n",
    "        max_length=MAX_LENGTH,\n",
    "        min_length=6,\n",
    "        num_beams=4,\n",
    "        no_repeat_ngram_size=3,\n",
    "        length_penalty=1.05,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "    return tokenizer.batch_decode(gen, skip_special_tokens=True)\n",
    "\n",
    "preds = []\n",
    "for i in range(0, len(val_texts), 8):\n",
    "    preds.extend(generate_batch(val_texts[i:i+8]))\n",
    "\n",
    "preds = postprocess_text(preds)\n",
    "bleu = metric_bleu.compute(predictions=preds, references=val_refs)\n",
    "chrf = metric_chrf.compute(predictions=preds, references=val_refs)\n",
    "print(f\"Validation BLEU: {bleu['score']:.2f}, chrF: {chrf['score']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a27615",
   "metadata": {
    "papermill": {
     "duration": 0.007132,
     "end_time": "2025-12-25T12:09:04.275738",
     "exception": false,
     "start_time": "2025-12-25T12:09:04.268606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A10. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06794aa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-25T12:09:04.291316Z",
     "iopub.status.busy": "2025-12-25T12:09:04.291031Z",
     "iopub.status.idle": "2025-12-25T12:09:07.914570Z",
     "shell.execute_reply": "2025-12-25T12:09:07.913791Z"
    },
    "papermill": {
     "duration": 3.633252,
     "end_time": "2025-12-25T12:09:07.916126",
     "exception": false,
     "start_time": "2025-12-25T12:09:04.282874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to /kaggle/working/byt5-base-saved...\n",
      "Notebook A Complete.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Saving model to {OUTPUT_DIR}...\")\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "print(\"Notebook A Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A11. Optional Self-Training Augmentation (Small, OOM-Safe)\n",
    "ENABLE_SELF_TRAIN = True\n",
    "MAX_PSEUDO = int(os.getenv(\"BYT5_MAX_PSEUDO\", \"500\"))  # keep small to avoid OOM\n",
    "\n",
    "if ENABLE_SELF_TRAIN:\n",
    "    print(\"\\n=== SELF-TRAINING AUGMENTATION (ByT5) ===\")\n",
    "    pub_path = f\"{DATA_DIR}/published_texts.csv\"\n",
    "    if os.path.exists(pub_path):\n",
    "        pub_df = pd.read_csv(pub_path)\n",
    "        translits = pub_df.get(\"transliteration\", pd.Series([])).dropna().astype(str).tolist()\n",
    "        translits = [clean_translit(t) for t in translits]\n",
    "        translits = [t for t in translits if 5 <= len(t.split()) <= 180]\n",
    "        translits = translits[:MAX_PSEUDO]\n",
    "        print(f\"Generating pseudo translations for {len(translits)} extra transliterations...\")\n",
    "\n",
    "        def generate_batch(texts):\n",
    "            batch_inputs = [PREFIX + doc for doc in texts]\n",
    "            enc = tokenizer(batch_inputs, max_length=MAX_LENGTH, truncation=True, padding=True, return_tensors=\"pt\").to(model.device)\n",
    "            gen = model.generate(\n",
    "                **enc,\n",
    "                max_length=min(MAX_LENGTH, 400),\n",
    "                min_length=6,\n",
    "                num_beams=6,\n",
    "                no_repeat_ngram_size=3,\n",
    "                length_penalty=1.05,\n",
    "                early_stopping=True,\n",
    "            )\n",
    "            return tokenizer.batch_decode(gen, skip_special_tokens=True)\n",
    "\n",
    "        pseudo_trans = []\n",
    "        for i in range(0, len(translits), 8):  # small batch to avoid OOM\n",
    "            try:\n",
    "                batch_preds = generate_batch(translits[i:i+8])\n",
    "                pseudo_trans.extend(batch_preds)\n",
    "            except RuntimeError as e:\n",
    "                if \"out of memory\" in str(e).lower():\n",
    "                    print(\"[WARNING] OOM during pseudo generation; skipping remaining.\")\n",
    "                    break\n",
    "                else:\n",
    "                    raise\n",
    "\n",
    "        # Postprocess & filter\n",
    "        def dedup_repeats(text: str) -> str:\n",
    "            toks = text.split()\n",
    "            out = []\n",
    "            for t in toks:\n",
    "                if len(out) >= 2 and t == out[-1] == out[-2]:\n",
    "                    continue\n",
    "                out.append(t)\n",
    "            return \" \".join(out)\n",
    "        def postprocess_text(preds):\n",
    "            out = []\n",
    "            for p in preds:\n",
    "                p = p.strip()\n",
    "                p = re.sub(r\"\\s+([.,!?;:])\", r\"\\1\", p)\n",
    "                p = re.sub(r\"([.,!?;:])([A-Za-z])\", r\"\\1 \\2\", p)\n",
    "                p = dedup_repeats(p)\n",
    "                if p and p[0].islower():\n",
    "                    p = p[0].upper() + p[1:]\n",
    "                if p and p[-1] not in \".!?\":\n",
    "                    p += \".\"\n",
    "                p = re.sub(r\"([.!?]){2,}\", \".\", p)\n",
    "                out.append(p.strip())\n",
    "            return out\n",
    "\n",
    "        pseudo_trans = postprocess_text(pseudo_trans)\n",
    "        aug_df = pd.DataFrame({\"transliteration\": translits[:len(pseudo_trans)], \"translation\": pseudo_trans})\n",
    "        aug_df[\"src_len\"] = aug_df[\"transliteration\"].str.split().str.len()\n",
    "        aug_df[\"tgt_len\"] = aug_df[\"translation\"].str.split().str.len()\n",
    "        ratio = (aug_df[\"tgt_len\"] / aug_df[\"src_len\"]).clip(upper=6)\n",
    "        aug_df = aug_df[(aug_df[\"tgt_len\"] >= 4) & (ratio >= 0.5) & (ratio <= 6)]\n",
    "        aug_df = aug_df.drop(columns=[\"src_len\", \"tgt_len\"])\n",
    "        print(f\"Pseudo pairs retained after filtering: {len(aug_df)}\")\n",
    "\n",
    "        base_train = pd.read_csv(f\"{DATA_DIR}/train.csv\")\n",
    "        base_train = base_train.dropna(subset=[\"transliteration\", \"translation\"]).astype(str)\n",
    "        base_train[\"transliteration\"] = base_train[\"transliteration\"].map(clean_translit)\n",
    "        base_train[\"translation\"] = base_train[\"translation\"].map(clean_translation)\n",
    "        combined = pd.concat([\n",
    "            base_train[[\"transliteration\", \"translation\"]],\n",
    "            aug_df[[\"transliteration\", \"translation\"]]\n",
    "        ], axis=0).drop_duplicates().reset_index(drop=True)\n",
    "        print(f\"Total combined training pairs: {len(combined)}\")\n",
    "\n",
    "        ds_combined = Dataset.from_pandas(combined)\n",
    "        def preprocess_function_aug(examples):\n",
    "            inputs = [PREFIX + ex for ex in examples[\"transliteration\"]]\n",
    "            targets = examples[\"translation\"]\n",
    "            model_inputs = tokenizer(\n",
    "                inputs,\n",
    "                max_length=MAX_LENGTH,\n",
    "                truncation=True,\n",
    "                padding=\"max_length\"\n",
    "            )\n",
    "            with tokenizer.as_target_tokenizer():\n",
    "                labels = tokenizer(\n",
    "                    targets,\n",
    "                    max_length=MAX_LENGTH,\n",
    "                    truncation=True,\n",
    "                    padding=\"max_length\"\n",
    "                )\n",
    "            model_inputs[\"labels\"] = [\n",
    "                [(l if l != tokenizer.pad_token_id else -100) for l in label]\n",
    "                for label in labels[\"input_ids\"]\n",
    "            ]\n",
    "            return model_inputs\n",
    "        tokenized_combined = ds_combined.map(preprocess_function_aug, batched=True)\n",
    "\n",
    "        training_args_aug = Seq2SeqTrainingArguments(\n",
    "            output_dir=OUTPUT_DIR,\n",
    "            save_strategy=\"no\",\n",
    "            eval_strategy=\"no\",\n",
    "            load_best_model_at_end=False,\n",
    "            learning_rate=2.5e-4,\n",
    "            per_device_train_batch_size=1,\n",
    "            gradient_accumulation_steps=16,\n",
    "            num_train_epochs=1,  # keep short to avoid OOM/time\n",
    "            fp16=True,\n",
    "            report_to=\"none\"\n",
    "        )\n",
    "        trainer_aug = Seq2SeqTrainer(\n",
    "            model=model,\n",
    "            args=training_args_aug,\n",
    "            train_dataset=tokenized_combined,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "        print(\"Starting second-stage training (ByT5) with augmented data...\")\n",
    "        try:\n",
    "            trainer_aug.train()\n",
    "        except RuntimeError as e:\n",
    "            print(f\"[WARNING] Augmentation training skipped due to error: {e}\")\n",
    "        print(\"Augmentation stage complete.\")\n",
    "\n",
    "        print(f\"Saving augmented model to {OUTPUT_DIR}...\")\n",
    "        trainer_aug.save_model(OUTPUT_DIR)\n",
    "        tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "    else:\n",
    "        print(\"published_texts.csv not found; skipping self-training.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14976537,
     "sourceId": 121150,
     "sourceType": "competition"
    },
    {
     "datasetId": 9082937,
     "sourceId": 14236819,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6059.435801,
   "end_time": "2025-12-25T12:09:11.716859",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-25T10:28:12.281058",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1fe03852120a40cda6d5c85f4e29fcaf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b48bf215217541358d86be12f43b7f3c",
       "placeholder": "​",
       "style": "IPY_MODEL_fcaea7f32ee24eebaebfc0e32266d44a",
       "tabbable": null,
       "tooltip": null,
       "value": " 8.15k/? [00:00&lt;00:00, 928kB/s]"
      }
     },
     "226d44a1d8884129a1d1230b2642a786": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b0c8da6c308b446cb01170a376a943c3",
       "max": 77,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_39da431ed6e041ef8c50061ff0cb2734",
       "tabbable": null,
       "tooltip": null,
       "value": 77
      }
     },
     "2bccb998d49d415580aaed49b33a1b22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_791efc0e593d4599ba993239183a55e3",
       "placeholder": "​",
       "style": "IPY_MODEL_683b28591d2f4363aa74a0a1a44c7a1c",
       "tabbable": null,
       "tooltip": null,
       "value": " 77/77 [00:00&lt;00:00, 388.82 examples/s]"
      }
     },
     "2d21f5383a1548d98e116b290031fccd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "39da431ed6e041ef8c50061ff0cb2734": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3b23edd7473a4b5cbeb0e7453bf9b6bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "427b3335b5374628a175042c3a3382e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d21f5383a1548d98e116b290031fccd",
       "placeholder": "​",
       "style": "IPY_MODEL_9aed8f291fff48a5a708caf8c20013d8",
       "tabbable": null,
       "tooltip": null,
       "value": "Downloading builder script: "
      }
     },
     "44b7b6316c1c4a4bbc5e3b84e174e79f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e6a4941ccd41469aa09a0ec5a804af6e",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b76718f5d5b1422ab37b370c9cc527ff",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "45c5ff13e0804ab38df84c594f5cbfe4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c11ec6efe7cb4722883a279f3eb185ed",
       "placeholder": "​",
       "style": "IPY_MODEL_8846ab600ef243c39c4f1cb71a308f59",
       "tabbable": null,
       "tooltip": null,
       "value": "Downloading builder script: "
      }
     },
     "4a7eec71c5664bbd922f48d02fb439ac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4b48b9cb404748bdba5a1554f4687518": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e865f98ee6084edf9b9c63807b52da6b",
        "IPY_MODEL_9f53690cf1d84b5aa3e3929a66799044",
        "IPY_MODEL_f030f089b1124566ab437b62c99b2578"
       ],
       "layout": "IPY_MODEL_c2b4df78e626401c8a097c7890f1386e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6297171298534da8a8ae461611777771": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "67bff04e3ed849f8aadf4b6b7df2b9e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_427b3335b5374628a175042c3a3382e4",
        "IPY_MODEL_44b7b6316c1c4a4bbc5e3b84e174e79f",
        "IPY_MODEL_1fe03852120a40cda6d5c85f4e29fcaf"
       ],
       "layout": "IPY_MODEL_b8d2e1271f1e4afdb533651d811a2bb8",
       "tabbable": null,
       "tooltip": null
      }
     },
     "683b28591d2f4363aa74a0a1a44c7a1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6c90b63b47dc4de495594cfd1e6519b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "701dd03462844cf0af47a3ab8c452a04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_45c5ff13e0804ab38df84c594f5cbfe4",
        "IPY_MODEL_bc4d79d1c6384c23a736957e90afd304",
        "IPY_MODEL_9d58cd0d03464cd18c653fdec13d87e4"
       ],
       "layout": "IPY_MODEL_b0bcd130aa8341b1acef83b7cc545dce",
       "tabbable": null,
       "tooltip": null
      }
     },
     "71affa5ac8894c80959fbb0448728c81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c324f021e0034d85bcf6459f17a7a752",
       "placeholder": "​",
       "style": "IPY_MODEL_6297171298534da8a8ae461611777771",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "791efc0e593d4599ba993239183a55e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8846ab600ef243c39c4f1cb71a308f59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8f98493e151546f2baa629a4edf06a14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9369db00183844a5b53806dd64a214db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "969e0b0841ff4999a85c76101abdcc41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "9aed8f291fff48a5a708caf8c20013d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9d58cd0d03464cd18c653fdec13d87e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b789e817126e4af1a184cfae19f2612f",
       "placeholder": "​",
       "style": "IPY_MODEL_3b23edd7473a4b5cbeb0e7453bf9b6bc",
       "tabbable": null,
       "tooltip": null,
       "value": " 9.01k/? [00:00&lt;00:00, 914kB/s]"
      }
     },
     "9f53690cf1d84b5aa3e3929a66799044": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ab64a8242ff94bdfbfceeabac64877cf",
       "max": 1452,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d0f4b1fc30b24fd1a84d58113003352a",
       "tabbable": null,
       "tooltip": null,
       "value": 1452
      }
     },
     "a1151781b3e84a738ae66c7ac283ba3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_71affa5ac8894c80959fbb0448728c81",
        "IPY_MODEL_226d44a1d8884129a1d1230b2642a786",
        "IPY_MODEL_2bccb998d49d415580aaed49b33a1b22"
       ],
       "layout": "IPY_MODEL_4a7eec71c5664bbd922f48d02fb439ac",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a8e873b972004c38ae11c1d76cfe84ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ab64a8242ff94bdfbfceeabac64877cf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ae69eb96031c4d43bf4c52da5aedb198": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b0bcd130aa8341b1acef83b7cc545dce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b0c8da6c308b446cb01170a376a943c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b48bf215217541358d86be12f43b7f3c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b76718f5d5b1422ab37b370c9cc527ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b789e817126e4af1a184cfae19f2612f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b8d2e1271f1e4afdb533651d811a2bb8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bc4d79d1c6384c23a736957e90afd304": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_969e0b0841ff4999a85c76101abdcc41",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a8e873b972004c38ae11c1d76cfe84ba",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "c11ec6efe7cb4722883a279f3eb185ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c2b4df78e626401c8a097c7890f1386e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c324f021e0034d85bcf6459f17a7a752": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0f4b1fc30b24fd1a84d58113003352a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e6a4941ccd41469aa09a0ec5a804af6e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "e865f98ee6084edf9b9c63807b52da6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ae69eb96031c4d43bf4c52da5aedb198",
       "placeholder": "​",
       "style": "IPY_MODEL_8f98493e151546f2baa629a4edf06a14",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "f030f089b1124566ab437b62c99b2578": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9369db00183844a5b53806dd64a214db",
       "placeholder": "​",
       "style": "IPY_MODEL_6c90b63b47dc4de495594cfd1e6519b0",
       "tabbable": null,
       "tooltip": null,
       "value": " 1452/1452 [00:03&lt;00:00, 448.42 examples/s]"
      }
     },
     "fcaea7f32ee24eebaebfc0e32266d44a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
