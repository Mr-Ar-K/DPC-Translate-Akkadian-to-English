{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb5f8de2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:01:16.815852Z",
     "iopub.status.busy": "2026-01-08T07:01:16.815457Z",
     "iopub.status.idle": "2026-01-08T07:01:16.977668Z",
     "shell.execute_reply": "2026-01-08T07:01:16.976858Z",
     "shell.execute_reply.started": "2026-01-08T07:01:16.815829Z"
    },
    "papermill": {
     "duration": 0.184478,
     "end_time": "2025-12-25T10:52:28.811448",
     "exception": false,
     "start_time": "2025-12-25T10:52:28.626970",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan  8 07:01:16 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P0             28W /  250W |       0MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ba94f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:01:16.979434Z",
     "iopub.status.busy": "2026-01-08T07:01:16.979167Z",
     "iopub.status.idle": "2026-01-08T07:01:22.272321Z",
     "shell.execute_reply": "2026-01-08T07:01:22.271423Z",
     "shell.execute_reply.started": "2026-01-08T07:01:16.979409Z"
    },
    "papermill": {
     "duration": 4.831554,
     "end_time": "2025-12-25T10:52:33.649527",
     "exception": false,
     "start_time": "2025-12-25T10:52:28.817973",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q evaluate sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66804faa",
   "metadata": {
    "papermill": {
     "duration": 0.006473,
     "end_time": "2025-12-25T10:52:33.662736",
     "exception": false,
     "start_time": "2025-12-25T10:52:33.656263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# B1. Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da891048",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:01:22.274161Z",
     "iopub.status.busy": "2026-01-08T07:01:22.273662Z",
     "iopub.status.idle": "2026-01-08T07:01:51.121684Z",
     "shell.execute_reply": "2026-01-08T07:01:51.120853Z",
     "shell.execute_reply.started": "2026-01-08T07:01:22.274134Z"
    },
    "papermill": {
     "duration": 31.938008,
     "end_time": "2025-12-25T10:53:05.606920",
     "exception": false,
     "start_time": "2025-12-25T10:52:33.668912",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 07:01:34.049692: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767855694.229185      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767855694.278889      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1767855694.692852      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767855694.692889      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767855694.692892      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767855694.692895      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import pandas as pd\n",
    "import torch\n",
    "import evaluate\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSeq2SeqLM, \n",
    "    DataCollatorForSeq2Seq, \n",
    "    Seq2SeqTrainer, \n",
    "    Seq2SeqTrainingArguments,\n",
    "    set_seed,\n",
    " )\n",
    "\n",
    "# Memory safety tweaks\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "try:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.set_float32_matmul_precision(\"medium\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# --- Configuration ---\n",
    "MODEL_PATH = \"/kaggle/input/models-for-dpc/pretrained_models/t5-base\"\n",
    "DATA_DIR = \"/kaggle/input/deep-past-initiative-machine-translation\"\n",
    "OUTPUT_DIR = \"/kaggle/working/t5-base-fine-tuned\"\n",
    "\n",
    "MAX_LENGTH = 266 \n",
    "PREFIX = \"translate Akkadian to English: \"\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ffc9ab",
   "metadata": {
    "papermill": {
     "duration": 0.006319,
     "end_time": "2025-12-25T10:53:05.620113",
     "exception": false,
     "start_time": "2025-12-25T10:53:05.613794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# B2. Data Loading & Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14116bf4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-08T07:01:51.124264Z",
     "iopub.status.busy": "2026-01-08T07:01:51.123694Z",
     "iopub.status.idle": "2026-01-08T07:01:51.603156Z",
     "shell.execute_reply": "2026-01-08T07:01:51.602437Z",
     "shell.execute_reply.started": "2026-01-08T07:01:51.124230Z"
    },
    "papermill": {
     "duration": 0.465368,
     "end_time": "2025-12-25T10:53:06.091815",
     "exception": false,
     "start_time": "2025-12-25T10:53:05.626447",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw documents: 1561\n",
      "Aligned training examples (pre-filter): 1561\n",
      "Aligned training examples (post-filter): 1529\n",
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "SUBSCRIPT_TRANS = str.maketrans({\"₀\": \"0\", \"₁\": \"1\", \"₂\": \"2\", \"₃\": \"3\", \"₄\": \"4\", \"₅\": \"5\", \"₆\": \"6\", \"₇\": \"7\", \"₈\": \"8\", \"₉\": \"9\", \"ₓ\": \"x\"})\n",
    "\n",
    "def normalize_subscripts(text: str) -> str:\n",
    "    return text.translate(SUBSCRIPT_TRANS)\n",
    "\n",
    "def replace_gaps(text):\n",
    "    \"\"\"Replace various gap notations with standardized tokens\"\"\"\n",
    "    if pd.isna(text): \n",
    "        return text\n",
    "    \n",
    "    # Complex gap patterns (order matters)\n",
    "    text = re.sub(r'\\.3(?:\\s+\\.3)+\\.{3}(?:\\s+\\.{3})+\\s+\\.{3}(?:\\s+\\.{3})+', '<big_gap>', text)\n",
    "    text = re.sub(r'\\.3(?:\\s+\\.3)+\\.{3}(?:\\s+\\.{3})+', '<big_gap>', text)\n",
    "    text = re.sub(r'\\.{3}(?:\\s+\\.{3})+', '<big_gap>', text)\n",
    "\n",
    "    # Simple gap patterns\n",
    "    text = re.sub(r'xx', '<gap>', text)\n",
    "    text = re.sub(r' x ', ' <gap> ', text)\n",
    "    text = re.sub(r'……', '<big_gap>', text)\n",
    "    text = re.sub(r'\\.\\.\\.\\.\\.\\.', '<big_gap>', text)\n",
    "    text = re.sub(r'…', '<big_gap>', text)\n",
    "    text = re.sub(r'\\.\\.\\.', '<big_gap>', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def replace_gaps_back(text):\n",
    "    \"\"\"Convert standardized gap tokens back to original format\"\"\"\n",
    "    if pd.isna(text):  \n",
    "        return text\n",
    "    \n",
    "    text = re.sub(r'<gap>', 'x', text)\n",
    "    text = re.sub(r'<big_gap>', '...', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def clean_translit(text):\n",
    "    \"\"\"Normalize transliteration by stripping scribal marks and gaps.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = normalize_subscripts(text)\n",
    "    # Apply gap replacement first\n",
    "    text = replace_gaps(text)\n",
    "    text = re.sub(r\"\\[[^\\]]*\\]\", \" \", text)\n",
    "    text = re.sub(r\"<<[^>]*>>\", \" \", text)\n",
    "    text = re.sub(r\"[˹˺]\", \" \", text)\n",
    "    text = re.sub(r\"\\([^)]*\\)\", \" \", text)\n",
    "    text = re.sub(r\"\\{([^}]*)\\}\", r\"\\1\", text)\n",
    "    text = re.sub(r\"<([^>]*)>\", r\"\\1\", text)\n",
    "    text = re.sub(r\"[!?/:·]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def clean_translation(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.replace(\"…\", \" \")\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def filter_quality(df):\n",
    "    df[\"src_len\"] = df[\"src\"].str.split().str.len()\n",
    "    df[\"tgt_len\"] = df[\"tgt\"].str.split().str.len()\n",
    "    df = df[(df[\"src_len\"] >= 3) & (df[\"tgt_len\"] >= 3)]\n",
    "    ratio = (df[\"src_len\"] / df[\"tgt_len\"]).clip(upper=6)\n",
    "    df = df[(ratio >= 0.2) & (ratio <= 5)]\n",
    "    df = df.drop_duplicates(subset=[\"src\", \"tgt\"])\n",
    "    return df.drop(columns=[\"src_len\", \"tgt_len\"])\n",
    "\n",
    "def load_and_align_data(filepath):\n",
    "    \"\"\"\n",
    "    Aligns Akkadian transliterations to English translations.\n",
    "    Tries to split by line/sentence; falls back to document-level if counts mismatch.\n",
    "    Filters low-quality pairs.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    aligned_rows = []\n",
    "\n",
    "    print(f\"Raw documents: {len(df)}\")\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        src = clean_translit(row.get(\"transliteration\", \"\"))\n",
    "        tgt = clean_translation(row.get(\"translation\", \"\"))\n",
    "\n",
    "        src_lines = [s.strip() for s in src.split(\"\\n\") if len(s.strip()) > 1]\n",
    "        tgt_sents = [t.strip() for t in re.split(r'(?<=[.!?])\\s+', tgt) if len(t.strip()) > 1]\n",
    "\n",
    "        if len(src_lines) == len(tgt_sents) and len(src_lines) > 1:\n",
    "            for s, t in zip(src_lines, tgt_sents):\n",
    "                aligned_rows.append({\"src\": s, \"tgt\": t})\n",
    "        else:\n",
    "            merged_src = src.replace(\"\\n\", \" \")\n",
    "            if len(merged_src) > 3 and len(tgt) > 3:\n",
    "                aligned_rows.append({\"src\": merged_src, \"tgt\": tgt})\n",
    "\n",
    "    print(f\"Aligned training examples (pre-filter): {len(aligned_rows)}\")\n",
    "    out_df = filter_quality(pd.DataFrame(aligned_rows))\n",
    "    print(f\"Aligned training examples (post-filter): {len(out_df)}\")\n",
    "    return out_df\n",
    "\n",
    "df = load_and_align_data(f\"{DATA_DIR}/train.csv\")\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.train_test_split(test_size=0.05, seed=42)\n",
    "print(\"Data loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab032f9",
   "metadata": {
    "papermill": {
     "duration": 0.006237,
     "end_time": "2025-12-25T10:53:06.105617",
     "exception": false,
     "start_time": "2025-12-25T10:53:06.099380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# B3. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78147d5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:01:51.604167Z",
     "iopub.status.busy": "2026-01-08T07:01:51.603952Z",
     "iopub.status.idle": "2026-01-08T07:01:54.792157Z",
     "shell.execute_reply": "2026-01-08T07:01:54.791477Z",
     "shell.execute_reply.started": "2026-01-08T07:01:51.604146Z"
    },
    "papermill": {
     "duration": 2.669812,
     "end_time": "2025-12-25T10:53:08.781718",
     "exception": false,
     "start_time": "2025-12-25T10:53:06.111906",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c692139780474ba485e1e87a4a600f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1452 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16855e98d22d41958f0cfa8be86f0d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/77 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Add prefix to inputs\n",
    "    inputs = [PREFIX + doc for doc in examples[\"src\"]]\n",
    "    targets = examples[\"tgt\"]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, \n",
    "        max_length=MAX_LENGTH, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        targets, \n",
    "        max_length=MAX_LENGTH, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    # Replace padding token id with -100 to ignore in loss calculation\n",
    "    labels[\"input_ids\"] = [\n",
    "        [(l if l != tokenizer.pad_token_id else -100) for l in label]\n",
    "        for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Apply processing\n",
    "tokenized_train = dataset[\"train\"].map(preprocess_function, batched=True)\n",
    "tokenized_val = dataset[\"test\"].map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b73864",
   "metadata": {
    "papermill": {
     "duration": 0.006463,
     "end_time": "2025-12-25T10:53:08.795260",
     "exception": false,
     "start_time": "2025-12-25T10:53:08.788797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# B4. Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f446d7d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:01:54.793318Z",
     "iopub.status.busy": "2026-01-08T07:01:54.793033Z",
     "iopub.status.idle": "2026-01-08T07:01:57.018491Z",
     "shell.execute_reply": "2026-01-08T07:01:57.017932Z",
     "shell.execute_reply.started": "2026-01-08T07:01:54.793269Z"
    },
    "papermill": {
     "duration": 1.329085,
     "end_time": "2025-12-25T10:53:10.130831",
     "exception": false,
     "start_time": "2025-12-25T10:53:08.801746",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer, \n",
    "    model=model,\n",
    "    label_pad_token_id=-100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cf81f5",
   "metadata": {
    "papermill": {
     "duration": 0.00675,
     "end_time": "2025-12-25T10:53:10.144707",
     "exception": false,
     "start_time": "2025-12-25T10:53:10.137957",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# B5 . Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "448ff551",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:01:57.019634Z",
     "iopub.status.busy": "2026-01-08T07:01:57.019341Z",
     "iopub.status.idle": "2026-01-08T07:01:57.183154Z",
     "shell.execute_reply": "2026-01-08T07:01:57.182575Z",
     "shell.execute_reply.started": "2026-01-08T07:01:57.019609Z"
    },
    "papermill": {
     "duration": 0.173301,
     "end_time": "2025-12-25T10:53:10.324393",
     "exception": false,
     "start_time": "2025-12-25T10:53:10.151092",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- B5. Training Configuration (Optimized for 31+ Score) ---\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    \n",
    "    # --- DISK SPACE & SPEED ---\n",
    "    save_strategy=\"no\",           # No checkpoints to save disk space\n",
    "    eval_strategy=\"no\",           # Skip eval for faster training\n",
    "    load_best_model_at_end=False,\n",
    "    \n",
    "    learning_rate=2.5e-4,         # Slightly higher for faster convergence\n",
    "    \n",
    "    per_device_train_batch_size=4, \n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,  # Effective batch = 16\n",
    "    gradient_checkpointing=False,    # T5 handles memory well\n",
    "    \n",
    "    num_train_epochs=6,             # Increased for better quality\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=False,    # Faster training\n",
    "    \n",
    "    fp16=True,                      # Mixed precision\n",
    "    report_to=\"none\",\n",
    "    logging_steps=50,\n",
    "    \n",
    "    # Quality optimizations\n",
    "    label_smoothing_factor=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,              # Balanced warmup\n",
    "    generation_max_length=280,\n",
    "    generation_num_beams=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4bbc44",
   "metadata": {
    "papermill": {
     "duration": 0.006611,
     "end_time": "2025-12-25T10:53:10.337614",
     "exception": false,
     "start_time": "2025-12-25T10:53:10.331003",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# B6. Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65bb5847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:01:57.184506Z",
     "iopub.status.busy": "2026-01-08T07:01:57.184001Z",
     "iopub.status.idle": "2026-01-08T07:14:20.306058Z",
     "shell.execute_reply": "2026-01-08T07:14:20.305482Z",
     "shell.execute_reply.started": "2026-01-08T07:01:57.184480Z"
    },
    "papermill": {
     "duration": 630.345373,
     "end_time": "2025-12-25T11:03:40.689517",
     "exception": false,
     "start_time": "2025-12-25T10:53:10.344144",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/3452224907.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting T5-Base Training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='546' max='546' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [546/546 12:07, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.914400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.829900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.409400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.253800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.161900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.066700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.007700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=546, training_loss=3.4920040312267484, metrics={'train_runtime': 729.9203, 'train_samples_per_second': 11.936, 'train_steps_per_second': 0.748, 'total_flos': 2756238562344960.0, 'train_loss': 3.4920040312267484, 'epoch': 6.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear cache before training\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(\"Starting T5-Base Training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e413b91f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:14:20.308384Z",
     "iopub.status.busy": "2026-01-08T07:14:20.308103Z",
     "iopub.status.idle": "2026-01-08T07:17:47.148260Z",
     "shell.execute_reply": "2026-01-08T07:17:47.147582Z",
     "shell.execute_reply.started": "2026-01-08T07:14:20.308361Z"
    },
    "papermill": {
     "duration": 187.754923,
     "end_time": "2025-12-25T11:06:48.451525",
     "exception": false,
     "start_time": "2025-12-25T11:03:40.696602",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== POST-TRAINING VALIDATION ===\n",
      "Validating on 200 samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f200d4eb3654c00830fa720f40ec3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113e99b826d54c7d984b1dfc1fd0c613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation BLEU: 4.88, chrF: 23.80\n"
     ]
    }
   ],
   "source": [
    "# POST-TRAINING VALIDATION - Load fresh data and evaluate\n",
    "print(\"\\n=== POST-TRAINING VALIDATION ===\")\n",
    "\n",
    "# Reload validation data fresh\n",
    "val_df = pd.read_csv(f\"{DATA_DIR}/train.csv\")\n",
    "val_texts = []\n",
    "val_refs_list = []\n",
    "\n",
    "for _, row in val_df.iterrows():\n",
    "    src = clean_translit(row.get(\"transliteration\", \"\"))\n",
    "    tgt = clean_translation(row.get(\"translation\", \"\"))\n",
    "    if len(src) > 5 and len(tgt) > 5:\n",
    "        val_texts.append(src)\n",
    "        val_refs_list.append(tgt)\n",
    "\n",
    "# Use ~200 samples for quick validation\n",
    "val_texts = val_texts[:200]\n",
    "val_refs_list = val_refs_list[:200]\n",
    "val_refs = [[t] for t in val_refs_list]\n",
    "\n",
    "print(f\"Validating on {len(val_texts)} samples...\")\n",
    "\n",
    "metric_bleu = evaluate.load(\"sacrebleu\")\n",
    "metric_chrf = evaluate.load(\"chrf\")\n",
    "\n",
    "def dedup_repeats(text: str) -> str:\n",
    "    toks = text.split()\n",
    "    out = []\n",
    "    for t in toks:\n",
    "        if len(out) >= 2 and t == out[-1] == out[-2]:\n",
    "            continue\n",
    "        out.append(t)\n",
    "    return \" \".join(out)\n",
    "\n",
    "def postprocess_text(preds):\n",
    "    out = []\n",
    "    for p in preds:\n",
    "        p = p.strip()\n",
    "        p = re.sub(r\"\\s+([.,!?;:])\", r\"\\1\", p)\n",
    "        p = re.sub(r\"([.,!?;:])([A-Za-z])\", r\"\\1 \\2\", p)\n",
    "        p = dedup_repeats(p)\n",
    "        if p and p[0].islower():\n",
    "            p = p[0].upper() + p[1:]\n",
    "        if p and p[-1] not in \".!?\":\n",
    "            p += \".\"\n",
    "        p = re.sub(r\"([.!?]){2,}\", \".\", p)\n",
    "        out.append(p.strip())\n",
    "    return out\n",
    "\n",
    "def generate_batch(texts):\n",
    "    batch_inputs = [\"translate Akkadian to English: \" + doc for doc in texts]\n",
    "    enc = tokenizer(batch_inputs, max_length=266, truncation=True, padding=True, return_tensors=\"pt\").to(model.device)\n",
    "    gen = model.generate(\n",
    "        **enc,\n",
    "        max_length=280,\n",
    "        min_length=6,\n",
    "        num_beams=6,\n",
    "        no_repeat_ngram_size=3,\n",
    "        length_penalty=1.05,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "    return tokenizer.batch_decode(gen, skip_special_tokens=True)\n",
    "\n",
    "preds = []\n",
    "for i in range(0, len(val_texts), 8):\n",
    "    preds.extend(generate_batch(val_texts[i:i+8]))\n",
    "\n",
    "preds = postprocess_text(preds)\n",
    "bleu = metric_bleu.compute(predictions=preds, references=val_refs)\n",
    "chrf = metric_chrf.compute(predictions=preds, references=val_refs)\n",
    "print(f\"Validation BLEU: {bleu['score']:.2f}, chrF: {chrf['score']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e284ec0c",
   "metadata": {
    "papermill": {
     "duration": 0.007022,
     "end_time": "2025-12-25T11:06:48.465522",
     "exception": false,
     "start_time": "2025-12-25T11:06:48.458500",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# B7. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b6c375c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:17:47.149401Z",
     "iopub.status.busy": "2026-01-08T07:17:47.149114Z",
     "iopub.status.idle": "2026-01-08T07:17:48.713765Z",
     "shell.execute_reply": "2026-01-08T07:17:48.713107Z",
     "shell.execute_reply.started": "2026-01-08T07:17:47.149363Z"
    },
    "papermill": {
     "duration": 1.509104,
     "end_time": "2025-12-25T11:06:49.981598",
     "exception": false,
     "start_time": "2025-12-25T11:06:48.472494",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to /kaggle/working/t5-base-fine-tuned...\n",
      "Notebook B (T5) Complete.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Saving model to {OUTPUT_DIR}...\")\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print(\"Notebook B (T5) Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba041139",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:17:48.714826Z",
     "iopub.status.busy": "2026-01-08T07:17:48.714577Z",
     "iopub.status.idle": "2026-01-08T07:21:40.908699Z",
     "shell.execute_reply": "2026-01-08T07:21:40.907655Z",
     "shell.execute_reply.started": "2026-01-08T07:17:48.714802Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SELF-TRAINING AUGMENTATION (T5) ===\n",
      "Generating pseudo translations for 1200 extra transliterations...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_55/819406812.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mpseudo_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mbatch_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mpseudo_trans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_55/819406812.py\u001b[0m in \u001b[0;36mgenerate_batch\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mbatch_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mPREFIX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             gen = model.generate(\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m280\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m         \u001b[0;31m# 9. Call generation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2564\u001b[0;31m         result = decoding_method(\n\u001b[0m\u001b[1;32m   2565\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3280\u001b[0m             \u001b[0;31m# `temperature`, ...), and add new logprobs to existing running logprobs scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3282\u001b[0;31m             \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_running_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3284\u001b[0m             \u001b[0;31m# Store logits, attentions and hidden_states when required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/logits_process.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/logits_process.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0mcur_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0mscores_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m         \u001b[0mbanned_batch_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_calc_banned_ngram_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngram_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batch_hypotheses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbanned_tokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbanned_batch_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0mscores_processed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbanned_tokens\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/logits_process.py\u001b[0m in \u001b[0;36m_calc_banned_ngram_tokens\u001b[0;34m(ngram_size, prev_input_ids, num_hypos, cur_len)\u001b[0m\n\u001b[1;32m    959\u001b[0m         \u001b[0;31m# return no banned tokens if we haven't generated no_repeat_ngram_size tokens yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_hypos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mgenerated_ngrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hypos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     banned_tokens = [\n\u001b[1;32m    963\u001b[0m         \u001b[0m_get_generated_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_ngrams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhypo_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_input_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhypo_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/logits_process.py\u001b[0m in \u001b[0;36m_get_ngrams\u001b[0;34m(ngram_size, prev_input_ids, num_hypos)\u001b[0m\n\u001b[1;32m    924\u001b[0m         \u001b[0;31m# Loop through each n-gram of size ngram_size in the list of tokens (gen_tokens)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgen_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m             \u001b[0mprev_ngram_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m             \u001b[0mgenerated_ngram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev_ngram_tuple\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_ngram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_ngram_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgenerated_ngrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# B8. Optional Self-Training Augmentation (Fast, Quality-Filtered)\n",
    "ENABLE_SELF_TRAIN = False\n",
    "MAX_PSEUDO = int(os.getenv(\"T5_MAX_PSEUDO\", \"1200\"))\n",
    "\n",
    "if ENABLE_SELF_TRAIN:\n",
    "    print(\"\\n=== SELF-TRAINING AUGMENTATION (T5) ===\")\n",
    "    pub_path = f\"{DATA_DIR}/published_texts.csv\"\n",
    "    if os.path.exists(pub_path):\n",
    "        pub_df = pd.read_csv(pub_path)\n",
    "        # Use only clean transliterations (no provided translations)\n",
    "        translits = pub_df.get(\"transliteration\", pd.Series([])).dropna().astype(str).tolist()\n",
    "        translits = [clean_translit(t) for t in translits]\n",
    "        # Filter reasonable lengths\n",
    "        translits = [t for t in translits if 5 <= len(t.split()) <= 140]\n",
    "        translits = translits[:MAX_PSEUDO]\n",
    "        print(f\"Generating pseudo translations for {len(translits)} extra transliterations...\")\n",
    "\n",
    "        def generate_batch(texts):\n",
    "            batch_inputs = [PREFIX + doc for doc in texts]\n",
    "            enc = tokenizer(batch_inputs, max_length=MAX_LENGTH, truncation=True, padding=True, return_tensors=\"pt\").to(model.device)\n",
    "            gen = model.generate(\n",
    "                **enc,\n",
    "                max_length=280,\n",
    "                min_length=6,\n",
    "                num_beams=6,\n",
    "                no_repeat_ngram_size=3,\n",
    "                length_penalty=1.05,\n",
    "                early_stopping=True,\n",
    "            )\n",
    "            return tokenizer.batch_decode(gen, skip_special_tokens=True)\n",
    "\n",
    "        pseudo_trans = []\n",
    "        for i in range(0, len(translits), 16):\n",
    "            batch_preds = generate_batch(translits[i:i+16])\n",
    "            pseudo_trans.extend(batch_preds)\n",
    "\n",
    "        # Postprocess & quality filter\n",
    "        def dedup_repeats(text: str) -> str:\n",
    "            toks = text.split()\n",
    "            out = []\n",
    "            for t in toks:\n",
    "                if len(out) >= 2 and t == out[-1] == out[-2]:\n",
    "                    continue\n",
    "                out.append(t)\n",
    "            return \" \".join(out)\n",
    "        def postprocess_text(preds):\n",
    "            out = []\n",
    "            for p in preds:\n",
    "                p = p.strip()\n",
    "                p = re.sub(r\"\\s+([.,!?;:])\", r\"\\1\", p)\n",
    "                p = re.sub(r\"([.,!?;:])([A-Za-z])\", r\"\\1 \\2\", p)\n",
    "                p = dedup_repeats(p)\n",
    "                if p and p[0].islower():\n",
    "                    p = p[0].upper() + p[1:]\n",
    "                if p and p[-1] not in \".!?\":\n",
    "                    p += \".\"\n",
    "                p = re.sub(r\"([.!?]){2,}\", \".\", p)\n",
    "                out.append(p.strip())\n",
    "            return out\n",
    "\n",
    "        pseudo_trans = postprocess_text(pseudo_trans)\n",
    "        aug_df = pd.DataFrame({\"transliteration\": translits, \"translation\": pseudo_trans})\n",
    "        # Quality filter\n",
    "        aug_df[\"src_len\"] = aug_df[\"transliteration\"].str.split().str.len()\n",
    "        aug_df[\"tgt_len\"] = aug_df[\"translation\"].str.split().str.len()\n",
    "        ratio = (aug_df[\"tgt_len\"] / aug_df[\"src_len\"]).clip(upper=6)\n",
    "        aug_df = aug_df[(aug_df[\"tgt_len\"] >= 4) & (ratio >= 0.5) & (ratio <= 6)]\n",
    "        aug_df = aug_df.drop(columns=[\"src_len\", \"tgt_len\"])\n",
    "        print(f\"Pseudo pairs retained after filtering: {len(aug_df)}\")\n",
    "\n",
    "        # Combine with original training data\n",
    "        base_train = pd.read_csv(f\"{DATA_DIR}/train.csv\")\n",
    "        base_train = base_train.dropna(subset=[\"transliteration\", \"translation\"]).astype(str)\n",
    "        base_train[\"transliteration\"] = base_train[\"transliteration\"].map(clean_translit)\n",
    "        base_train[\"translation\"] = base_train[\"translation\"].map(clean_translation)\n",
    "        combined = pd.concat([\n",
    "            base_train[[\"transliteration\", \"translation\"]],\n",
    "            aug_df[[\"transliteration\", \"translation\"]]\n",
    "        ], axis=0).drop_duplicates().reset_index(drop=True)\n",
    "        print(f\"Total combined training pairs: {len(combined)}\")\n",
    "\n",
    "        # Tokenize combined\n",
    "        def preprocess_function_aug(examples):\n",
    "            inputs = [PREFIX + ex for ex in examples[\"transliteration\"]]\n",
    "            targets = examples[\"translation\"]\n",
    "            model_inputs = tokenizer(\n",
    "                inputs,\n",
    "                max_length=MAX_LENGTH,\n",
    "                truncation=True,\n",
    "                padding=\"max_length\"\n",
    "            )\n",
    "            with tokenizer.as_target_tokenizer():\n",
    "                labels = tokenizer(\n",
    "                    targets,\n",
    "                    max_length=MAX_LENGTH,\n",
    "                    truncation=True,\n",
    "                    padding=\"max_length\"\n",
    "                )\n",
    "            model_inputs[\"labels\"] = [\n",
    "                [(l if l != tokenizer.pad_token_id else -100) for l in label]\n",
    "                for label in labels[\"input_ids\"]\n",
    "            ]\n",
    "            return model_inputs\n",
    "\n",
    "        ds_combined = Dataset.from_pandas(combined)\n",
    "        tokenized_combined = ds_combined.map(preprocess_function_aug, batched=True)\n",
    "\n",
    "        # Short second-stage training\n",
    "        training_args_aug = Seq2SeqTrainingArguments(\n",
    "            output_dir=OUTPUT_DIR,\n",
    "            save_strategy=\"no\",\n",
    "            eval_strategy=\"no\",\n",
    "            load_best_model_at_end=False,\n",
    "            learning_rate=2e-4,\n",
    "            per_device_train_batch_size=4,\n",
    "            gradient_accumulation_steps=4,\n",
    "            num_train_epochs=2,\n",
    "            fp16=True,\n",
    "            report_to=\"none\"\n",
    "        )\n",
    "        trainer_aug = Seq2SeqTrainer(\n",
    "            model=model,\n",
    "            args=training_args_aug,\n",
    "            train_dataset=tokenized_combined,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "        print(\"Starting second-stage training with augmented data...\")\n",
    "        trainer_aug.train()\n",
    "        print(\"Augmentation stage complete.\")\n",
    "        \n",
    "        # Save again\n",
    "        print(f\"Saving augmented model to {OUTPUT_DIR}...\")\n",
    "        trainer_aug.save_model(OUTPUT_DIR)\n",
    "        tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "    else:\n",
    "        print(\"published_texts.csv not found; skipping self-training.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 15061024,
     "sourceId": 121150,
     "sourceType": "competition"
    },
    {
     "datasetId": 9082937,
     "sourceId": 14236819,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 867.451795,
   "end_time": "2025-12-25T11:06:53.451666",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-25T10:52:25.999871",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "077ae2461fb6489b97106a1caaafb370": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_eb6470d874c040e698b88b4827bb0052",
        "IPY_MODEL_772639f9a8104921b6f3b1caca957605",
        "IPY_MODEL_c0e6baa9bf9a411b844486a5ac4eb0f2"
       ],
       "layout": "IPY_MODEL_bd2909e5aebc4611a9e453f84a7e8035",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0adb4c94b7b74e03b9969a916a78f816": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2a1fc3087f004cdcbe55deb12e9b9d55": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2adf7045efe64b7cb4c5556604eb75e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2d2eba874f204b159a6a962c13f13b19": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2d432c967de54ce58ca8f97185c3edd5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_907a9c57f14d46909be51efea7772bfe",
       "max": 1452,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dfea59b2310d4bf7a765969e33c563e4",
       "tabbable": null,
       "tooltip": null,
       "value": 1452
      }
     },
     "310b3b3d8e6e4913bf9b553d7df21e92": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4948d8ef30b94d23ab5670946a3aea08": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4ecbe0b10d9f4af2862caa0ea4819ad3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "62b2c58f9ef642879c9120277b64490f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ab9961958af74ef6b85fd74f35f7ab79",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a2e79e4817c1410fad2a93325460dab6",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "6bfa7186924b4ef1b09723815e8039e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e0dd8d999ad42c98136d00236800e95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e3c59e812f44e02bbde7360657be1e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7212b9bcee854738bc028dc516c6d9e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6bfa7186924b4ef1b09723815e8039e7",
       "placeholder": "​",
       "style": "IPY_MODEL_9c4f0d0224314af5a5348f524290228d",
       "tabbable": null,
       "tooltip": null,
       "value": "Downloading builder script: "
      }
     },
     "757491e8dcfb4e53bbde385ec37d11c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "76050bf59c0b404eb86de944a9d2f440": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "772639f9a8104921b6f3b1caca957605": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cbcf3f903c0142bb919b4c6c873027b8",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4ecbe0b10d9f4af2862caa0ea4819ad3",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "8ae65202365844b3823b46cc09af0d8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7212b9bcee854738bc028dc516c6d9e0",
        "IPY_MODEL_62b2c58f9ef642879c9120277b64490f",
        "IPY_MODEL_d254aa49e2c748839b11c3ae30b3ed4b"
       ],
       "layout": "IPY_MODEL_0adb4c94b7b74e03b9969a916a78f816",
       "tabbable": null,
       "tooltip": null
      }
     },
     "907a9c57f14d46909be51efea7772bfe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "939f39d353254f2188c3154b27045a38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6e0dd8d999ad42c98136d00236800e95",
       "placeholder": "​",
       "style": "IPY_MODEL_4948d8ef30b94d23ab5670946a3aea08",
       "tabbable": null,
       "tooltip": null,
       "value": " 1452/1452 [00:02&lt;00:00, 685.40 examples/s]"
      }
     },
     "9c4f0d0224314af5a5348f524290228d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a12b2c8b8d9045ad9880827234dd0592": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a151a03ca0304312ade7c4c2a3fca88b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a2e79e4817c1410fad2a93325460dab6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ab9961958af74ef6b85fd74f35f7ab79": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "ac4c4df806d943919a176f5abba4439e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d2eba874f204b159a6a962c13f13b19",
       "placeholder": "​",
       "style": "IPY_MODEL_ea4d9cb6237b410fa26d0ef017695535",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "b584c545f2a04b22a8684541f3716bb8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f29b32d0d9ff4816ae71db8424c042ee",
        "IPY_MODEL_2d432c967de54ce58ca8f97185c3edd5",
        "IPY_MODEL_939f39d353254f2188c3154b27045a38"
       ],
       "layout": "IPY_MODEL_ed16ef8fdffb4b9b8536b8c6e9d727bf",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b999aa2ad3044b9cb4a67d342fc9aabc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ac4c4df806d943919a176f5abba4439e",
        "IPY_MODEL_d6dab87b9b4b4b0fa1f6ca17928ae214",
        "IPY_MODEL_f4856502a22146fb8fde2d23cb451348"
       ],
       "layout": "IPY_MODEL_6e3c59e812f44e02bbde7360657be1e9",
       "tabbable": null,
       "tooltip": null
      }
     },
     "bd2909e5aebc4611a9e453f84a7e8035": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c0e6baa9bf9a411b844486a5ac4eb0f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_310b3b3d8e6e4913bf9b553d7df21e92",
       "placeholder": "​",
       "style": "IPY_MODEL_d3822816c9214e8296dbc9d8f6a53130",
       "tabbable": null,
       "tooltip": null,
       "value": " 9.01k/? [00:00&lt;00:00, 925kB/s]"
      }
     },
     "ca6c0b7ac45e453daf901dbe2533d931": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cbcf3f903c0142bb919b4c6c873027b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "d254aa49e2c748839b11c3ae30b3ed4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a12b2c8b8d9045ad9880827234dd0592",
       "placeholder": "​",
       "style": "IPY_MODEL_2adf7045efe64b7cb4c5556604eb75e9",
       "tabbable": null,
       "tooltip": null,
       "value": " 8.15k/? [00:00&lt;00:00, 832kB/s]"
      }
     },
     "d29e22650257471d8935422c67a4c6b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d3822816c9214e8296dbc9d8f6a53130": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d6dab87b9b4b4b0fa1f6ca17928ae214": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2a1fc3087f004cdcbe55deb12e9b9d55",
       "max": 77,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_757491e8dcfb4e53bbde385ec37d11c7",
       "tabbable": null,
       "tooltip": null,
       "value": 77
      }
     },
     "da9bc0ca3f1e42268d44dd4984814919": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dfea59b2310d4bf7a765969e33c563e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ea4d9cb6237b410fa26d0ef017695535": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "eb6470d874c040e698b88b4827bb0052": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ca6c0b7ac45e453daf901dbe2533d931",
       "placeholder": "​",
       "style": "IPY_MODEL_f1f41397162d4f36aba6f0441042960e",
       "tabbable": null,
       "tooltip": null,
       "value": "Downloading builder script: "
      }
     },
     "ed16ef8fdffb4b9b8536b8c6e9d727bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f1f41397162d4f36aba6f0441042960e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f29b32d0d9ff4816ae71db8424c042ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_76050bf59c0b404eb86de944a9d2f440",
       "placeholder": "​",
       "style": "IPY_MODEL_d29e22650257471d8935422c67a4c6b3",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "f4856502a22146fb8fde2d23cb451348": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_da9bc0ca3f1e42268d44dd4984814919",
       "placeholder": "​",
       "style": "IPY_MODEL_a151a03ca0304312ade7c4c2a3fca88b",
       "tabbable": null,
       "tooltip": null,
       "value": " 77/77 [00:00&lt;00:00, 599.94 examples/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
