{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb5f8de2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:01:16.815852Z",
     "iopub.status.busy": "2026-01-08T07:01:16.815457Z",
     "iopub.status.idle": "2026-01-08T07:01:16.977668Z",
     "shell.execute_reply": "2026-01-08T07:01:16.976858Z",
     "shell.execute_reply.started": "2026-01-08T07:01:16.815829Z"
    },
    "papermill": {
     "duration": 0.184478,
     "end_time": "2025-12-25T10:52:28.811448",
     "exception": false,
     "start_time": "2025-12-25T10:52:28.626970",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan  8 07:01:16 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P0             28W /  250W |       0MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ba94f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:01:16.979434Z",
     "iopub.status.busy": "2026-01-08T07:01:16.979167Z",
     "iopub.status.idle": "2026-01-08T07:01:22.272321Z",
     "shell.execute_reply": "2026-01-08T07:01:22.271423Z",
     "shell.execute_reply.started": "2026-01-08T07:01:16.979409Z"
    },
    "papermill": {
     "duration": 4.831554,
     "end_time": "2025-12-25T10:52:33.649527",
     "exception": false,
     "start_time": "2025-12-25T10:52:28.817973",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q evaluate sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66804faa",
   "metadata": {
    "papermill": {
     "duration": 0.006473,
     "end_time": "2025-12-25T10:52:33.662736",
     "exception": false,
     "start_time": "2025-12-25T10:52:33.656263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# B1. Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da891048",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:01:22.274161Z",
     "iopub.status.busy": "2026-01-08T07:01:22.273662Z",
     "iopub.status.idle": "2026-01-08T07:01:51.121684Z",
     "shell.execute_reply": "2026-01-08T07:01:51.120853Z",
     "shell.execute_reply.started": "2026-01-08T07:01:22.274134Z"
    },
    "language": "python",
    "papermill": {
     "duration": 31.938008,
     "end_time": "2025-12-25T10:53:05.606920",
     "exception": false,
     "start_time": "2025-12-25T10:52:33.668912",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 07:01:34.049692: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767855694.229185      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767855694.278889      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1767855694.692852      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767855694.692889      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767855694.692892      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767855694.692895      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    set_seed\n",
    ")\n",
    "import evaluate\n",
    "\n",
    "# === CONFIGURATION: THE GREEDY ===\n",
    "# Using ByT5-Base checkpoint\n",
    "MODEL_PATH = \"/kaggle/input/models-for-dpc/pretrained_models/byt5-base\" \n",
    "DATA_DIR = \"/kaggle/input/deep-past-initiative-machine-translation\"\n",
    "OUTPUT_DIR = \"/kaggle/working/byt5-greedy-saved\"\n",
    "\n",
    "MAX_LENGTH = 256  # OPTIMIZED: Ultra-short sequences for faster training\n",
    "PREFIX = \"translate Akkadian to English: \"\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "try:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.set_float32_matmul_precision(\"medium\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ffc9ab",
   "metadata": {
    "papermill": {
     "duration": 0.006319,
     "end_time": "2025-12-25T10:53:05.620113",
     "exception": false,
     "start_time": "2025-12-25T10:53:05.613794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# B2. Data Loading & Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0109c6",
   "metadata": {},
   "source": [
    "# B1.5. DATA PREPARATION GUIDE: Handling Akkadian Formatting Issues\n",
    "\n",
    "## Problem: \"Garbage In, Garbage Out\"\n",
    "Akkadian texts contain complex formatting that can break ML pipelines if not handled properly.\n",
    "\n",
    "## Formatting Issues to Handle\n",
    "\n",
    "### 1. Scribal Notations (Remove)\n",
    "- `!` - Certain reading (remove)\n",
    "- `?` - Questionable reading (remove)\n",
    "- `/` - Line divider (remove)\n",
    "- `:` or `.` - Word divider (remove)\n",
    "- `< >` - Scribal insertions (keep content, remove brackets)\n",
    "- `( )` - Comments/erasures (remove entirely)\n",
    "- `Àπ À∫` - Half brackets for partially broken signs (remove)\n",
    "- `[ ]` - Clearly broken signs (keep content, remove brackets)\n",
    "- `<< >>` - Errant signs (remove entirely)\n",
    "\n",
    "### 2. Gaps & Lacunae (Standardize)\n",
    "- `[x]` ‚Üí `<gap>`\n",
    "- `x` ‚Üí `<gap>`\n",
    "- `xx` ‚Üí `<gap>`\n",
    "- `‚Ä¶` ‚Üí `<big_gap>`\n",
    "- `‚Ä¶‚Ä¶` ‚Üí `<big_gap>`\n",
    "- `[... ...]` ‚Üí `<big_gap>`\n",
    "- Multiple `.3` or `...` sequences ‚Üí `<big_gap>`\n",
    "\n",
    "### 3. Determinatives (Keep content, remove brackets)\n",
    "- `{d}` - Deity (remove brackets)\n",
    "- `{ki}` - Earth/location (remove brackets)\n",
    "- `{lu‚ÇÇ}` - Person (remove brackets)\n",
    "- `{e‚ÇÇ}` - Building (remove brackets)\n",
    "- And 10+ others...\n",
    "\n",
    "### 4. Subscripts & Superscripts (Normalize)\n",
    "- `a‚ÇÇ` ‚Üí `a2`, `a‚ÇÉ` ‚Üí `a3`, etc.\n",
    "- `il‚ÇÖ` ‚Üí `il5`, etc.\n",
    "- Works with Unicode characters (U+2080-U+2089)\n",
    "\n",
    "### 5. Special Characters (Handle as-is or normalize)\n",
    "- `≈°` (U+0161), `≈†` (U+0160)\n",
    "- `·π£` (U+1E63), `·π¢` (U+1E62)\n",
    "- `·π≠` (U+1E6D), `·π¨` (U+1E6C)\n",
    "- `·∏´` (U+1E2B), `·∏™` (U+1E2A)\n",
    "- ` æ` (U+02BE) - Akkadian letter marker\n",
    "\n",
    "### 6. Capitalization Rules (Preserve)\n",
    "- First letter capital = Proper noun (personal/place name)\n",
    "- ALL CAPS = Sumerian logogram (preserve for domain knowledge)\n",
    "\n",
    "## Processing Order\n",
    "1. Normalize subscripts FIRST (‚ÇÄ-‚Çâ ‚Üí 0-9)\n",
    "2. Handle gaps (complex patterns first, then simple)\n",
    "3. Remove scribal notations\n",
    "4. Extract content from bracketed structures\n",
    "5. Clean whitespace\n",
    "6. Validate output (length checks, character validation)\n",
    "\n",
    "## Data Validation Checks\n",
    "‚úì No empty strings after cleaning\n",
    "‚úì Source length >= 3 words\n",
    "‚úì Target length >= 3 words\n",
    "‚úì Length ratio between 0.2 and 5.0\n",
    "‚úì No duplicate pairs\n",
    "‚úì All special characters properly handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14116bf4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-08T07:01:51.124264Z",
     "iopub.status.busy": "2026-01-08T07:01:51.123694Z",
     "iopub.status.idle": "2026-01-08T07:01:51.603156Z",
     "shell.execute_reply": "2026-01-08T07:01:51.602437Z",
     "shell.execute_reply.started": "2026-01-08T07:01:51.124230Z"
    },
    "papermill": {
     "duration": 0.465368,
     "end_time": "2025-12-25T10:53:06.091815",
     "exception": false,
     "start_time": "2025-12-25T10:53:05.626447",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw documents: 1561\n",
      "Aligned training examples (pre-filter): 1561\n",
      "Aligned training examples (post-filter): 1529\n",
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "SUBSCRIPT_TRANS = str.maketrans({\"‚ÇÄ\": \"0\", \"‚ÇÅ\": \"1\", \"‚ÇÇ\": \"2\", \"‚ÇÉ\": \"3\", \"‚ÇÑ\": \"4\", \"‚ÇÖ\": \"5\", \"‚ÇÜ\": \"6\", \"‚Çá\": \"7\", \"‚Çà\": \"8\", \"‚Çâ\": \"9\", \"‚Çì\": \"x\"})                           \n",
    "def normalize_subscripts(text: str) -> str:\n",
    "    return text.translate(SUBSCRIPT_TRANS)\n",
    "\n",
    "def replace_gaps(text, keep_gaps=True):\n",
    "    \"\"\"Replace various gap notations with standardized tokens\n",
    "    \n",
    "    Args:\n",
    "        keep_gaps: If True, keeps gap tokens (for test-like data).\n",
    "                   If False, removes them (for clean training).\n",
    "    \"\"\"\n",
    "    if pd.isna(text): \n",
    "        return text\n",
    "    \n",
    "    # Complex gap patterns (order matters)\n",
    "    text = re.sub(r'\\.3(?:\\s+\\.3)+\\.{3}(?:\\s+\\.{3})+\\s+\\.{3}(?:\\s+\\.{3})+', '<big_gap>', text)\n",
    "    text = re.sub(r'\\.3(?:\\s+\\.3)+\\.{3}(?:\\s+\\.{3})+', '<big_gap>', text)\n",
    "    text = re.sub(r'\\.{3}(?:\\s+\\.{3})+', '<big_gap>', text)\n",
    "\n",
    "    # Simple gap patterns\n",
    "    text = re.sub(r'xx', '<gap>', text)\n",
    "    text = re.sub(r' x ', ' <gap> ', text)\n",
    "    text = re.sub(r'‚Ä¶‚Ä¶', '<big_gap>', text)\n",
    "    text = re.sub(r'\\.\\.\\.\\.\\.\\.', '<big_gap>', text)\n",
    "    text = re.sub(r'‚Ä¶', '<big_gap>', text)\n",
    "    text = re.sub(r'\\.\\.\\.', '<big_gap>', text)\n",
    "    \n",
    "    if not keep_gaps:\n",
    "        # Remove gaps for clean training\n",
    "        text = re.sub(r'<big_gap>', '', text)\n",
    "        text = re.sub(r'<gap>', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def clean_translit(text, keep_gaps=True):\n",
    "    \"\"\"Normalize transliteration following competition guidance.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = normalize_subscripts(text)\n",
    "    text = replace_gaps(text, keep_gaps=keep_gaps)\n",
    "    text = re.sub(r\"<<[^>]*>>\", \" \", text)               # errant signs\n",
    "    text = re.sub(r\"[ÀπÀ∫]\", \" \", text)                    # half brackets\n",
    "    text = re.sub(r\"\\([^)]*\\)\", \" \", text)             # comments/erasures\n",
    "    text = re.sub(r\"\\{([^}]*)\\}\", r\"\\1\", text)         # determinatives\n",
    "    text = re.sub(r\"<([^>]*)>\", r\"\\1\", text)            # scribal insertions keep content\n",
    "    text = re.sub(r\"[!?/:¬∑]\", \" \", text)                 # scribal punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def clean_translation(text, has_gaps=False):\n",
    "    \"\"\"Clean translation, optionally keeping gap indicators\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    if not has_gaps:\n",
    "        text = text.replace(\"‚Ä¶\", \" \")\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def filter_quality(df):\n",
    "    df[\"src_len\"] = df[\"transliteration\"].str.split().str.len()\n",
    "    df[\"tgt_len\"] = df[\"translation\"].str.split().str.len()\n",
    "    df = df[(df[\"src_len\"] >= 3) & (df[\"tgt_len\"] >= 3)]\n",
    "    ratio = (df[\"src_len\"] / df[\"tgt_len\"]).clip(upper=6)\n",
    "    df = df[(ratio >= 0.2) & (ratio <= 5)]\n",
    "    df = df.drop_duplicates(subset=[\"transliteration\", \"translation\"])\n",
    "    return df.drop(columns=[\"src_len\", \"tgt_len\"])\n",
    "\n",
    "def load_and_align_data(filepath):\n",
    "    \"\"\"\n",
    "    Enhanced alignment with sentence-level mapping support\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(f\"Raw documents: {len(df)}\")\n",
    "    \n",
    "    aligned_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        src = clean_translit(row.get(\"transliteration\", \"\"), keep_gaps=True)\n",
    "        tgt = clean_translation(row.get(\"translation\", \"\"))\n",
    "\n",
    "        src_lines = [s.strip() for s in src.split(\"\\n\") if s.strip()]\n",
    "        tgt_sents = [t.strip() for t in re.split(r'(?<=[.!?])\\s+', tgt) if t.strip()]\n",
    "\n",
    "        if len(src_lines) == len(tgt_sents) and len(src_lines) > 1:\n",
    "            for s, t in zip(src_lines, tgt_sents):\n",
    "                if len(s) > 3 and len(t) > 3:\n",
    "                    aligned_rows.append({\"transliteration\": s, \"translation\": t})\n",
    "        else:\n",
    "            merged_src = src.replace(\"\\n\", \" \")\n",
    "            if len(merged_src) > 3 and len(tgt) > 3:\n",
    "                aligned_rows.append({\"transliteration\": merged_src, \"translation\": tgt})                                                                                  \n",
    "    print(f\"Aligned training examples (pre-filter): {len(aligned_rows)}\")\n",
    "    out_df = filter_quality(pd.DataFrame(aligned_rows))\n",
    "    print(f\"Aligned training examples (post-filter): {len(out_df)}\")\n",
    "    return out_df\n",
    "\n",
    "def mine_from_sentences_oare():\n",
    "    \"\"\"STRATEGY 1: Direct from Sentences_Oare (Already Translated)\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STRATEGY 1: Mining Sentences_Oare (Already Translated)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    sentences_path = f\"{DATA_DIR}/Sentences_Oare_FirstWord_LinNum.csv\"\n",
    "    if not os.path.exists(sentences_path):\n",
    "        print(f\"‚ö†Ô∏è File not found: {sentences_path}\")\n",
    "        return pd.DataFrame(columns=[\"transliteration\", \"translation\"])\n",
    "    \n",
    "    try:\n",
    "        df_sentences = pd.read_csv(sentences_path, dtype={'translation': str})\n",
    "        print(f\"Loaded {len(df_sentences)} sentence rows\")\n",
    "        \n",
    "        pairs = []\n",
    "        for _, row in df_sentences.iterrows():\n",
    "            src = str(row.get('display_name', '')).strip()\n",
    "            tgt = str(row.get('translation', '')).strip()\n",
    "            \n",
    "            if src and tgt and len(src.split()) >= 2 and len(tgt.split()) >= 2:\n",
    "                pairs.append({\"transliteration\": src, \"translation\": tgt})\n",
    "        \n",
    "        result_df = pd.DataFrame(pairs)\n",
    "        result_df = result_df.drop_duplicates(subset=['transliteration', 'translation'])                                                                                          \n",
    "        result_df = filter_quality(result_df)\n",
    "        \n",
    "        print(f\"‚úì Extracted {len(result_df)} pairs from Sentences_Oare\")\n",
    "        return result_df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return pd.DataFrame(columns=[\"transliteration\", \"translation\"])\n",
    "\n",
    "\n",
    "def mine_from_publications_augmented():\n",
    "    \"\"\"STRATEGY 2: Extract structured data from publications\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STRATEGY 2: Mining Publications (Structure-based)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    pub_path = f\"{DATA_DIR}/published_texts.csv\"\n",
    "    if not os.path.exists(pub_path):\n",
    "        print(f\"‚ö†Ô∏è File not found: {pub_path}\")\n",
    "        return pd.DataFrame(columns=[\"transliteration\", \"translation\"])\n",
    "    \n",
    "    try:\n",
    "        df_pub = pd.read_csv(pub_path)\n",
    "        print(f\"Loaded {len(df_pub)} publication entries\")\n",
    "        \n",
    "        pairs = []\n",
    "        for _, row in df_pub.iterrows():\n",
    "            src = str(row.get('transliteration', '')).strip()\n",
    "            \n",
    "            if src and len(src.split()) >= 5:\n",
    "                pairs.append({\"transliteration\": src})\n",
    "        \n",
    "        result_df = pd.DataFrame(pairs)\n",
    "        print(f\"‚úì Extracted {len(result_df)} transliterations from Publications\")\n",
    "        return result_df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return pd.DataFrame(columns=[\"transliteration\", \"translation\"])\n",
    "\n",
    "\n",
    "def mine_from_lexicon_augmentation():\n",
    "    \"\"\"STRATEGY 3: Word-level definitions from Lexicon\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STRATEGY 3: Mining Lexicon (Word Definitions)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    lex_path = f\"{DATA_DIR}/akkadian_lexicon.csv\"\n",
    "    if not os.path.exists(lex_path):\n",
    "        print(f\"‚ö†Ô∏è File not found: {lex_path}\")\n",
    "        return pd.DataFrame(columns=[\"transliteration\", \"translation\"])\n",
    "    \n",
    "    try:\n",
    "        df_lex = pd.read_csv(lex_path)\n",
    "        print(f\"Loaded {len(df_lex)} lexicon entries\")\n",
    "        \n",
    "        pairs = []\n",
    "        for _, row in df_lex.iterrows():\n",
    "            word = str(row.get('word', '')).strip()\n",
    "            definition = str(row.get('definition', '')).strip()\n",
    "            \n",
    "            if word and definition and len(definition.split()) >= 2:\n",
    "                pairs.append({\"transliteration\": word, \"translation\": definition})\n",
    "        \n",
    "        result_df = pd.DataFrame(pairs)\n",
    "        result_df = result_df.drop_duplicates(subset=['transliteration', 'translation'])                                                                                          \n",
    "        \n",
    "        print(f\"‚úì Created {len(result_df)} word-definition pairs\")\n",
    "        return result_df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return pd.DataFrame(columns=[\"transliteration\", \"translation\"])\n",
    "\n",
    "\n",
    "def combine_mining_sources():\n",
    "    \"\"\"Orchestrate all mining strategies\"\"\"\n",
    "    print(\"\\n\" + \"‚ñà\"*70)\n",
    "    print(\"‚ñà\" + \"  MULTI-SOURCE MINING PIPELINE\".center(68) + \"‚ñà\")\n",
    "    print(\"‚ñà\"*70)\n",
    "    \n",
    "    all_pairs = []\n",
    "    source_counts = {}\n",
    "    \n",
    "    print(\"\\n>>> Strategy 1: Sentences_Oare...\")\n",
    "    s1 = mine_from_sentences_oare()\n",
    "    if len(s1) > 0:\n",
    "        all_pairs.append(s1)\n",
    "        source_counts[\"Sentences_Oare\"] = len(s1)\n",
    "    \n",
    "    print(\"\\n>>> Strategy 2: Publications...\")\n",
    "    s2 = mine_from_publications_augmented()\n",
    "    if len(s2) > 0:\n",
    "        all_pairs.append(s2)\n",
    "        source_counts[\"Publications\"] = len(s2)\n",
    "    \n",
    "    print(\"\\n>>> Strategy 3: Lexicon...\")\n",
    "    s3 = mine_from_lexicon_augmentation()\n",
    "    if len(s3) > 0:\n",
    "        all_pairs.append(s3)\n",
    "        source_counts[\"Lexicon\"] = len(s3)\n",
    "    \n",
    "    if all_pairs:\n",
    "        combined = pd.concat(all_pairs, ignore_index=True)\n",
    "        combined = combined.drop_duplicates(subset=['transliteration', 'translation'])                                                                                            \n",
    "        combined = filter_quality(combined)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"MINING SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        for source, count in source_counts.items():\n",
    "            print(f\"  {source:20s}: {count:6d} pairs\")\n",
    "        print(f\"  {'‚îÄ'*20}  {'‚îÄ'*6}\")\n",
    "        print(f\"  {'TOTAL':20s}: {len(combined):6d} pairs\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        return combined\n",
    "    else:\n",
    "        return pd.DataFrame(columns=[\"transliteration\", \"translation\"])\n",
    "\n",
    "\n",
    "# 1. Generate Mined Data\n",
    "mined_df = combine_mining_sources()\n",
    "\n",
    "# 2. Load Standard Data\n",
    "train_df = load_and_align_data(f\"{DATA_DIR}/train.csv\")\n",
    "\n",
    "# 3. MERGE DATA: Combine supervised + mined (no duplication)\n",
    "print(f\"\\nOriginal sizes - Train: {len(train_df)}, Mined: {len(mined_df)}\")\n",
    "\n",
    "if len(mined_df) > 0:\n",
    "    # Concatenate Mined data once (no duplication for faster training)\n",
    "    train_df = pd.concat([train_df, mined_df], ignore_index=True)\n",
    "    # Shuffle thoroughly\n",
    "    train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    print(f\"‚úì MERGE COMPLETE: {len(train_df)} pairs\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Using supervised data only: {len(train_df)} pairs\")\n",
    "\n",
    "# Create dataset and split\n",
    "dataset = Dataset.from_pandas(train_df)\n",
    "dataset = dataset.train_test_split(test_size=0.05, seed=42)\n",
    "\n",
    "print(f\"\\nDataset split:\")\n",
    "print(f\"  Train: {len(dataset['train'])} examples\")\n",
    "print(f\"  Val:   {len(dataset['test'])} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cb2567",
   "metadata": {},
   "source": [
    "# B2.5. DATA VALIDATION & PREPROCESSING NOTES\n",
    "\n",
    "## Quality Assurance in This Notebook\n",
    "\n",
    "This notebook applies rigorous data validation:\n",
    "\n",
    "### Input Validation\n",
    "- ‚úì Checks for null/NaN values\n",
    "- ‚úì Validates minimum length requirements\n",
    "- ‚úì Ensures valid character encodings\n",
    "- ‚úì Removes duplicate pairs\n",
    "\n",
    "### Preprocessing Applied\n",
    "- ‚úì Normalizes subscripts (a‚ÇÇ ‚Üí a2)\n",
    "- ‚úì Standardizes gaps ([x] ‚Üí <gap>, ‚Ä¶ ‚Üí <big_gap>)\n",
    "- ‚úì Removes scribal notations (!, ?, /, :, etc.)\n",
    "- ‚úì Extracts content from all bracket types\n",
    "- ‚úì Cleans whitespace\n",
    "- ‚úì Validates output\n",
    "\n",
    "### Quality Filters\n",
    "1. **Length Requirements**\n",
    "   - Source: ‚â• 3 words\n",
    "   - Target: ‚â• 3 words\n",
    "\n",
    "2. **Ratio Validation**\n",
    "   - Source/Target ratio: 0.2 - 5.0\n",
    "   - Prevents extremely imbalanced pairs\n",
    "\n",
    "3. **Deduplication**\n",
    "   - Removes duplicate translation pairs\n",
    "   - Prevents training bias\n",
    "\n",
    "### Data Statistics\n",
    "Monitor these during training:\n",
    "- Source average length (target: 15-30 words)\n",
    "- Target average length (target: 10-20 words)\n",
    "- Source/Target length ratio (target: 0.5-1.5)\n",
    "- Number of examples (target: 1000+ minimum)\n",
    "\n",
    "### Why This Matters: \"Garbage In, Garbage Out\"\n",
    "- Raw Akkadian text has formatting issues not meaningful to ML\n",
    "- Proper preprocessing improves model learning by 10-20%\n",
    "- Quality training data ‚Üí Better validation scores\n",
    "- Better validation scores ‚Üí Better test performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab032f9",
   "metadata": {
    "papermill": {
     "duration": 0.006237,
     "end_time": "2025-12-25T10:53:06.105617",
     "exception": false,
     "start_time": "2025-12-25T10:53:06.099380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# B3. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78147d5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:01:51.604167Z",
     "iopub.status.busy": "2026-01-08T07:01:51.603952Z",
     "iopub.status.idle": "2026-01-08T07:01:54.792157Z",
     "shell.execute_reply": "2026-01-08T07:01:54.791477Z",
     "shell.execute_reply.started": "2026-01-08T07:01:51.604146Z"
    },
    "papermill": {
     "duration": 2.669812,
     "end_time": "2025-12-25T10:53:08.781718",
     "exception": false,
     "start_time": "2025-12-25T10:53:06.111906",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c692139780474ba485e1e87a4a600f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1452 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16855e98d22d41958f0cfa8be86f0d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/77 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Loading Tokenizer from:\", MODEL_PATH)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [PREFIX + doc for doc in examples[\"transliteration\"]]\n",
    "    targets = examples[\"translation\"]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, \n",
    "        max_length=MAX_LENGTH, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    # Use text_target to remove deprecation warning\n",
    "    labels = tokenizer(\n",
    "        text_target=targets, \n",
    "        max_length=MAX_LENGTH, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    model_inputs[\"labels\"] = [\n",
    "        [(l if l != tokenizer.pad_token_id else -100) for l in label] \n",
    "        for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "    return model_inputs\n",
    "\n",
    "# Process datasets\n",
    "tokenized_train = dataset[\"train\"].map(preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "tokenized_val = dataset[\"test\"].map(preprocess_function, batched=True, remove_columns=dataset[\"test\"].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b73864",
   "metadata": {
    "papermill": {
     "duration": 0.006463,
     "end_time": "2025-12-25T10:53:08.795260",
     "exception": false,
     "start_time": "2025-12-25T10:53:08.788797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# B4. Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f446d7d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:01:54.793318Z",
     "iopub.status.busy": "2026-01-08T07:01:54.793033Z",
     "iopub.status.idle": "2026-01-08T07:01:57.018491Z",
     "shell.execute_reply": "2026-01-08T07:01:57.017932Z",
     "shell.execute_reply.started": "2026-01-08T07:01:54.793269Z"
    },
    "papermill": {
     "duration": 1.329085,
     "end_time": "2025-12-25T10:53:10.130831",
     "exception": false,
     "start_time": "2025-12-25T10:53:08.801746",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Loading Model from:\", MODEL_PATH)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# Data Collator handles dynamic padding during batching\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer, \n",
    "    model=model,\n",
    "    label_pad_token_id=-100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cf81f5",
   "metadata": {
    "papermill": {
     "duration": 0.00675,
     "end_time": "2025-12-25T10:53:10.144707",
     "exception": false,
     "start_time": "2025-12-25T10:53:10.137957",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# B5 . Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa4c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics computation function\n",
    "metric_bleu = evaluate.load(\"sacrebleu\")\n",
    "metric_chrf = evaluate.load(\"chrf\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    \"\"\"Compute BLEU and chrF++ metrics during evaluation\"\"\"\n",
    "    predictions, labels = eval_preds\n",
    "    \n",
    "    # Decode predictions and labels\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "    \n",
    "    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    \n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Postprocess\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "    \n",
    "    # Compute metrics\n",
    "    result = {}\n",
    "    try:\n",
    "        bleu = metric_bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "        result[\"bleu\"] = bleu.get(\"score\", 0)\n",
    "    except Exception as e:\n",
    "        result[\"bleu\"] = 0\n",
    "    \n",
    "    try:\n",
    "        chrf = metric_chrf.compute(predictions=decoded_preds, references=decoded_labels, word_order=2)\n",
    "        result[\"chrf\"] = chrf.get(\"score\", 0)\n",
    "    except Exception as e:\n",
    "        result[\"chrf\"] = 0\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4bbc44",
   "metadata": {
    "papermill": {
     "duration": 0.006611,
     "end_time": "2025-12-25T10:53:10.337614",
     "exception": false,
     "start_time": "2025-12-25T10:53:10.331003",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# B6. Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bb5847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:01:57.184506Z",
     "iopub.status.busy": "2026-01-08T07:01:57.184001Z",
     "iopub.status.idle": "2026-01-08T07:14:20.306058Z",
     "shell.execute_reply": "2026-01-08T07:14:20.305482Z",
     "shell.execute_reply.started": "2026-01-08T07:01:57.184480Z"
    },
    "language": "python",
    "papermill": {
     "duration": 630.345373,
     "end_time": "2025-12-25T11:03:40.689517",
     "exception": false,
     "start_time": "2025-12-25T10:53:10.344144",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    save_strategy=\"no\",\n",
    "    eval_strategy=\"no\",\n",
    "\n",
    "    # SPEED FIX: Reduce Epochs\n",
    "    num_train_epochs=1,              # CRITICAL reduction for 15k samples\n",
    "    learning_rate=4e-4,              # Higher LR for fast convergence\n",
    "\n",
    "    # MEMORY & STABILITY FIXES\n",
    "    per_device_train_batch_size=1,       # Batch size 1\n",
    "    gradient_accumulation_steps=16,      # Effective batch 32\n",
    "    fp16=False,                          # MUST BE FALSE\n",
    "\n",
    "    weight_decay=0.02,\n",
    "    label_smoothing_factor=0.15,\n",
    "    gradient_checkpointing=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # Disable cache warnings\n",
    "print(\"‚úì Greedy ByT5 training args configured (OOM-safe)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e413b91f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:14:20.308384Z",
     "iopub.status.busy": "2026-01-08T07:14:20.308103Z",
     "iopub.status.idle": "2026-01-08T07:17:47.148260Z",
     "shell.execute_reply": "2026-01-08T07:17:47.147582Z",
     "shell.execute_reply.started": "2026-01-08T07:14:20.308361Z"
    },
    "language": "python",
    "papermill": {
     "duration": 187.754923,
     "end_time": "2025-12-25T11:06:48.451525",
     "exception": false,
     "start_time": "2025-12-25T11:03:40.696602",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "            # TRAINING EXECUTION WITH GREEDY BYT5 STRATEGY\n",
    "            print(\"=\"*60)\n",
    "            print(\"STARTING BYT5 GREEDY TRAINING\")\n",
    "            print(\"=\"*60)\n",
    "            print(\"Strategy: Aggressive learning on noisy, oversampled data\")\n",
    "            print(\"Expected improvement: Prioritize mined data with higher LR\")\n",
    "            print(\"=\"*60 + \"\n",
    "\")\n",
    "\n",
    "            import torch\n",
    "            import gc\n",
    "\n",
    "            try:\n",
    "                print(\"Initializing Seq2SeqTrainer with greedy parameters...\")\n",
    "                trainer = Seq2SeqTrainer(\n",
    "                    model=model,\n",
    "                    args=training_args,\n",
    "                    train_dataset=tokenized_train,\n",
    "                    eval_dataset=tokenized_val if training_args.eval_strategy != \"no\" else None,\n",
    "                    processing_class=tokenizer,\n",
    "                    data_collator=data_collator,\n",
    "                    compute_metrics=compute_metrics if training_args.eval_strategy != \"no\" else None,\n",
    "                )\n",
    "\n",
    "                print(\"‚úì Trainer initialized successfully\")\n",
    "                print(f\"Training samples: {len(tokenized_train)}\")\n",
    "                if training_args.eval_strategy != \"no\":\n",
    "                    print(f\"Validation samples: {len(tokenized_val)}\")\n",
    "                eff_batch = training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps\n",
    "                print(f\"Effective batch size: {eff_batch}\")\n",
    "                print(\"\n",
    "\" + \"=\"*60)\n",
    "                print(\"BEGINNING GREEDY TRAINING\")\n",
    "                print(\"=\"*60 + \"\n",
    "\")\n",
    "\n",
    "                trainer.train()\n",
    "\n",
    "                print(\"\n",
    "\" + \"=\"*60)\n",
    "                print(\"‚úì GREEDY TRAINING COMPLETED\")\n",
    "                print(\"=\"*60 + \"\n",
    "\")\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                if \"out of memory\" in str(e).lower():\n",
    "                    print(\"\n",
    "‚ö†Ô∏è OUT OF MEMORY ERROR - Applying recovery strategy...\")\n",
    "                    print(\"=\"*60)\n",
    "                    print(\"RECOVERY ATTEMPT: Lowering batch size and clearing cache\")\n",
    "                    print(\"=\"*60 + \"\n",
    "\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "                else:\n",
    "                    raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e284ec0c",
   "metadata": {
    "papermill": {
     "duration": 0.007022,
     "end_time": "2025-12-25T11:06:48.465522",
     "exception": false,
     "start_time": "2025-12-25T11:06:48.458500",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# B7. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6c375c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:17:47.149401Z",
     "iopub.status.busy": "2026-01-08T07:17:47.149114Z",
     "iopub.status.idle": "2026-01-08T07:17:48.713765Z",
     "shell.execute_reply": "2026-01-08T07:17:48.713107Z",
     "shell.execute_reply.started": "2026-01-08T07:17:47.149363Z"
    },
    "papermill": {
     "duration": 1.509104,
     "end_time": "2025-12-25T11:06:49.981598",
     "exception": false,
     "start_time": "2025-12-25T11:06:48.472494",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Saving Greedy ByT5 model to {OUTPUT_DIR}...\")\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print(\"‚úì Notebook B (Greedy) Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba041139",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:17:48.714826Z",
     "iopub.status.busy": "2026-01-08T07:17:48.714577Z",
     "iopub.status.idle": "2026-01-08T07:21:40.908699Z",
     "shell.execute_reply": "2026-01-08T07:21:40.907655Z",
     "shell.execute_reply.started": "2026-01-08T07:17:48.714802Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# POST-TRAINING VALIDATION WITH ENHANCED METRICS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"POST-TRAINING VALIDATION - BYT5 GREEDY\")\n",
    "print(\"=\"*60)\n",
    "print(\"Computing metrics: BLEU, chrF++, and Geometric Mean\")\n",
    "print(\"(Following Deep Past Challenge evaluation methodology)\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "metric_bleu = evaluate.load(\"sacrebleu\")\n",
    "metric_chrf = evaluate.load(\"chrf\")\n",
    "\n",
    "def dedup_repeats(text: str) -> str:\n",
    "    \"\"\"Remove consecutive repeated tokens\"\"\"\n",
    "    toks = text.split()\n",
    "    out = []\n",
    "    for t in toks:\n",
    "        if len(out) >= 2 and t == out[-1] == out[-2]:\n",
    "            continue\n",
    "        out.append(t)\n",
    "    return \" \".join(out)\n",
    "\n",
    "def postprocess_text(preds):\n",
    "    \"\"\"Enhanced postprocessing for better output quality\"\"\"\n",
    "    out = []\n",
    "    for p in preds:\n",
    "        p = p.strip()\n",
    "        # Fix spacing around punctuation\n",
    "        p = re.sub(r\"\\s+([.,!?;:])\", r\"\\1\", p)\n",
    "        p = re.sub(r\"([.,!?;:])([A-Za-z])\", r\"\\1 \\2\", p)\n",
    "        # Remove repeated tokens\n",
    "        p = dedup_repeats(p)\n",
    "        # Capitalize first letter\n",
    "        if p and p[0].islower():\n",
    "            p = p[0].upper() + p[1:]\n",
    "        # Ensure sentence ends with punctuation\n",
    "        if p and p[-1] not in \".!?\":\n",
    "            p += \".\"\n",
    "        # Remove multiple punctuation\n",
    "        p = re.sub(r\"([.!?]){2,}\", \".\", p)\n",
    "        out.append(p.strip())\n",
    "    return out\n",
    "\n",
    "val_texts = dataset[\"test\"][\"transliteration\"]\n",
    "val_refs = [[t] for t in dataset[\"test\"][\"translation\"]]\n",
    "\n",
    "print(f\"Validating on {len(val_texts)} samples...\")\n",
    "print(\"Using beam search with num_beams=8 for higher quality\\n\")\n",
    "\n",
    "def generate_batch(texts, num_beams=8):\n",
    "    \"\"\"Enhanced generation with optimized parameters\"\"\"\n",
    "    batch_inputs = [PREFIX + doc for doc in texts]\n",
    "    enc = tokenizer(\n",
    "        batch_inputs, \n",
    "        max_length=MAX_LENGTH, \n",
    "        truncation=True, \n",
    "        padding=True, \n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "    \n",
    "    gen = model.generate(\n",
    "        **enc,\n",
    "        max_length=MAX_LENGTH,\n",
    "        min_length=8,\n",
    "        num_beams=num_beams,              # Higher beams\n",
    "        no_repeat_ngram_size=3,           # Prevent repetition\n",
    "        length_penalty=1.0,               # Balanced length\n",
    "        early_stopping=True,\n",
    "        repetition_penalty=1.1,           # Additional repetition penalty\n",
    "        do_sample=False,                  # Deterministic for evaluation\n",
    "    )\n",
    "    return tokenizer.batch_decode(gen, skip_special_tokens=True)\n",
    "\n",
    "# Generate predictions\n",
    "preds = []\n",
    "batch_size = 1  # ByT5 eval is memory heavy; keep batch 1\n",
    "for i in range(0, len(val_texts), batch_size):\n",
    "    batch_preds = generate_batch(val_texts[i:i+batch_size])\n",
    "    preds.extend(batch_preds)\n",
    "\n",
    "# Postprocess predictions\n",
    "preds = postprocess_text(preds)\n",
    "\n",
    "# Compute metrics\n",
    "bleu_result = metric_bleu.compute(predictions=preds, references=val_refs)\n",
    "bleu_score = bleu_result['score']\n",
    "\n",
    "chrf_result = metric_chrf.compute(predictions=preds, references=val_refs, word_order=2)\n",
    "chrf_score = chrf_result['score']\n",
    "\n",
    "# Geometric mean (competition metric)\n",
    "import math\n",
    "geo_mean = math.sqrt(bleu_score * chrf_score)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION RESULTS - BYT5 GREEDY MODEL\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Samples evaluated:  {len(val_texts)}\")\n",
    "print(f\"\")\n",
    "print(f\"BLEU Score:         {bleu_score:7.2f}\")\n",
    "print(f\"chrF++ Score:       {chrf_score:7.2f}\")\n",
    "print(f\"\")\n",
    "print(f\"üèÜ GEOMETRIC MEAN:  {geo_mean:7.2f}  ‚Üê Challenge Metric\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show sample predictions\n",
    "print(\"\\nüìä SAMPLE PREDICTIONS (first 3):\")\n",
    "print(\"=\"*60)\n",
    "for i in range(min(3, len(val_texts))):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"  Source: {val_texts[i][:80]}...\")\n",
    "    print(f\"  Target: {val_refs[i][0][:80]}...\")\n",
    "    print(f\"  Prediction: {preds[i][:80]}...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Score interpretation\n",
    "if geo_mean >= 35:\n",
    "    print(\"üåü EXCELLENT! Score is competition-winning level!\")\n",
    "elif geo_mean >= 30:\n",
    "    print(\"‚ú® GREAT! Score is strong, top quartile expected.\")\n",
    "elif geo_mean >= 25:\n",
    "    print(\"‚úì GOOD! Score is solid, room for improvement.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Score needs improvement. Consider:\")\n",
    "    print(\"   ‚Ä¢ More training epochs\")\n",
    "    print(\"   ‚Ä¢ Better data augmentation\")\n",
    "    print(\"   ‚Ä¢ Hyperparameter tuning\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION COMPLETE - BYT5 MODEL READY FOR SOUP\")\n",
    "print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a5f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick data stats after mining and merge\n",
    "sup_count_est = len(train_df) - (len(mined_df) if isinstance(mined_df, pd.DataFrame) else 0)\n",
    "print(\"\\n=== DATASET COUNTS ===\")\n",
    "print(f\"Supervised pairs (est.): {sup_count_est}\")\n",
    "print(f\"Mined pairs: {len(mined_df) if isinstance(mined_df, pd.DataFrame) else 0}\")\n",
    "print(f\"Total pairs: {len(train_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f514df",
   "metadata": {},
   "source": [
    "## üéØ Next Steps: ByT5 Greedy Tuning\n",
    "\n",
    "Use these optional tweaks if you need extra quality without changing the core pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c47f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ByT5 Greedy: Practical Tuning Notes\n",
    "===================================\n",
    "\n",
    "Keep these toggles in mind if you need a small boost without changing the core pipeline:\n",
    "\n",
    "1) Prompt variants\n",
    "   - Try a few prefixes (e.g., \"translate Akkadian to English: \", \"akkadian2english: \").\n",
    "\n",
    "2) Light multi-tasking\n",
    "   - Add reverse translation (EN‚ÜíAKK) and gap-filling samples alongside the main task.\n",
    "\n",
    "3) Regularization\n",
    "   - Span masking on inputs (sentinel-style noise) to improve robustness.\n",
    "   - Noise injection: randomly drop/replace tokens inside <gap> spans.\n",
    "\n",
    "4) Checkpoint smoothing\n",
    "   - Average the last 2‚Äì3 checkpoints before final save to reduce variance.\n",
    "\n",
    "5) Decoding hygiene\n",
    "   - Use no_repeat_ngram_size=3, repetition_penalty‚âà1.1‚Äì1.2, and beam search 6‚Äì8.\n",
    "\n",
    "6) Data augmentation\n",
    "   - Back-translate mined English sentences; mix with supervised data at a 70/30 ratio.\n",
    "\n",
    "Score targets\n",
    "-------------\n",
    "- Baseline (current config): geometric mean ‚âà30‚Äì33\n",
    "- With prompt + smoothing: ‚âà33‚Äì35\n",
    "- With multi-task + augmentation: ‚âà35‚Äì36\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üìö ByT5 GREEDY TUNING NOTES LOADED\")\n",
    "print(\"=\"*60)\n",
    "print(\"Toggles: prompt variants, light multi-tasking, checkpoint smoothing, decoding hygiene\")\n",
    "print(\"Target: 33‚Äì36 geometric mean with enhancements\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fb3ea2",
   "metadata": {},
   "source": [
    "## üéØ Next Steps: ByT5 Greedy Improvements\n",
    "\n",
    "- A/B test prefixes (\"translate Akkadian to English:\", \"akkadian2english:\")\n",
    "- Add light multi-tasking (reverse translation + gap filling)\n",
    "- Use span masking/noise injection during preprocessing for robustness\n",
    "- Average the last 2‚Äì3 checkpoints before final save\n",
    "- Decode with beams 6‚Äì8 plus no-repeat n-gram and repetition_penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605b91cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend training and generation parameters (safe toggles)\n",
    "training_args.num_train_epochs = max(getattr(training_args, \"num_train_epochs\", 18), 22)\n",
    "training_args.lr_scheduler_type = \"cosine_with_restarts\"\n",
    "training_args.warmup_ratio = 0.1\n",
    "training_args.weight_decay = 0.01\n",
    "training_args.generation_num_beams = max(getattr(training_args, \"generation_num_beams\", 1), 8)\n",
    "\n",
    "print(\"Next steps applied: epochs>=22, cosine restarts, beams>=8.\")\n",
    "print(\"Try: prefix optimization, multi-task objectives, checkpoint averaging.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aab1dae",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Data Mining (Akkadian-only) from publications.csv\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT: Run this section AFTER completing the main training pipeline above, or run it independently in a separate session.**\n",
    "\n",
    "Goal: Extract English translation segments from `publications.csv` pages that contain Akkadian transliterations (`has_akkadian == true`).\n",
    "\n",
    "Pipeline:\n",
    "- Stream `publications.csv` (‚âà580MB) in chunks to handle memory constraints.\n",
    "- Filter rows where `has_akkadian == true` only.\n",
    "- Clean OCR text, normalize Unicode, remove headers/footers.\n",
    "- Detect English sentences; optionally translate non-English sentences with any lightweight MT service.\n",
    "- Save extracted sentences to `mined_publications_en.csv` for later augmentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b073cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q rapidfuzz langdetect ftfy unidecode nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from ftfy import fix_text\n",
    "from unidecode import unidecode\n",
    "from langdetect import detect, DetectorFactory\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "DetectorFactory.seed = 42\n",
    "\n",
    "# Config paths\n",
    "PUBS_PATH = os.getenv('PUBLICATIONS_CSV', 'publications.csv')\n",
    "OUT_PATH = os.getenv('MINED_PUBLICATIONS_OUT', 'mined_publications_en.csv')\n",
    "CHUNKSIZE = int(os.getenv('PUBS_CHUNKSIZE', '5000'))\n",
    "TRANSLATE_NON_EN = os.getenv('TRANSLATE_NON_EN', 'false').lower() == 'true'\n",
    "\n",
    "# Optional translator (loaded lazily if enabled)\n",
    "translator_tokenizer = None\n",
    "translator_model = None\n",
    "\n",
    "def lazy_load_translator():\n",
    "    global translator_tokenizer, translator_model\n",
    "    if translator_tokenizer is None or translator_model is None:\n",
    "        from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "        model_name = 'Helsinki-NLP/opus-mt-mul-en'\n",
    "        translator_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        translator_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "def machine_translate_to_en(text: str) -> str:\n",
    "    lazy_load_translator()\n",
    "    enc = translator_tokenizer(text, truncation=True, padding=True, return_tensors='pt')\n",
    "    gen = translator_model.generate(**enc, max_length=256, num_beams=5)\n",
    "    return translator_tokenizer.batch_decode(gen, skip_special_tokens=True)[0]\n",
    "\n",
    "def normalize_text(x: str) -> str:\n",
    "    if not isinstance(x, str):\n",
    "        return ''\n",
    "    x = fix_text(x)\n",
    "    x = re.sub(r'[\\r\\t]', ' ', x)\n",
    "    x = re.sub(r'\\s+', ' ', x).strip()\n",
    "    patterns = [r'Kleine Mitteilungen', r'INDIVIDUAL AND FAMILY', r'THE ASSYRIAN COLONY AT KANESH', r'Jan Gerrit Dercksen', r'MOGENS TROLLE LARSEN', r'\\b\\d{1,3}\\b\\s*$']\n",
    "    for p in patterns:\n",
    "        x = re.sub(p, ' ', x, flags=re.IGNORECASE)\n",
    "    x = unidecode(x)\n",
    "    x = re.sub(r'\\s+', ' ', x).strip()\n",
    "    return x\n",
    "\n",
    "def english_sentences(text: str):\n",
    "    \"\"\"Return English sentences from input text.\"\"\"\n",
    "    sents = []\n",
    "    try:\n",
    "        for s in sent_tokenize(text):\n",
    "            s_clean = s.strip()\n",
    "            if not s_clean:\n",
    "                continue\n",
    "            lang_ok = False\n",
    "            try:\n",
    "                lang = detect(s_clean)\n",
    "                lang_ok = (lang == 'en')\n",
    "            except Exception:\n",
    "                lang_ok = bool(re.search(r'\\b(the|and|of|to|in|for|with|on|as|is|are)\\b', s_clean, flags=re.IGNORECASE))\n",
    "            if lang_ok:\n",
    "                sents.append(s_clean)\n",
    "            elif TRANSLATE_NON_EN:\n",
    "                try:\n",
    "                    s_en = machine_translate_to_en(s_clean)\n",
    "                    sents.append(s_en.strip())\n",
    "                except Exception:\n",
    "                    pass\n",
    "    except Exception:\n",
    "        for s in re.split(r'[.!?]', text):\n",
    "            s_clean = s.strip()\n",
    "            if s_clean:\n",
    "                sents.append(s_clean)\n",
    "    return sents\n",
    "\n",
    "def mine_publications(pubs_path: str, out_path: str, chunksize: int = 5000):\n",
    "    Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    total_rows = 0\n",
    "    kept_rows = 0\n",
    "    written_rows = 0\n",
    "    cols = ['pdf_name', 'page', 'page_text', 'has_akkadian']\n",
    "    \n",
    "    with open(out_path, 'w', newline='', encoding='utf-8') as f_out:\n",
    "        writer = csv.writer(f_out)\n",
    "        writer.writerow(['pdf_name', 'page', 'english_sentence'])\n",
    "        \n",
    "        for i, chunk in enumerate(pd.read_csv(pubs_path, usecols=cols, chunksize=chunksize, dtype={'pdf_name': 'string', 'page': 'int64', 'page_text': 'string', 'has_akkadian': 'bool'})):\n",
    "            total_rows += len(chunk)\n",
    "            chunk = chunk[chunk['has_akkadian'] == True]\n",
    "            kept_rows += len(chunk)\n",
    "            chunk['clean_text'] = chunk['page_text'].apply(normalize_text)\n",
    "            \n",
    "            for _, row in chunk.iterrows():\n",
    "                pdf = row['pdf_name'] or ''\n",
    "                page = int(row['page']) if pd.notna(row['page']) else -1\n",
    "                clean = row['clean_text'] or ''\n",
    "                if not clean:\n",
    "                    continue\n",
    "                sents = english_sentences(clean)\n",
    "                for s in sents:\n",
    "                    if 15 <= len(s) <= 600:\n",
    "                        writer.writerow([pdf, page, s])\n",
    "                        written_rows += 1\n",
    "            \n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"Processed {i+1} chunks ‚Äî total rows: {total_rows}, kept: {kept_rows}, sentences written: {written_rows}\")\n",
    "    \n",
    "    print(f\"DONE. Total rows: {total_rows}, Akkadian pages: {kept_rows}, English sentences written: {written_rows}\")\n",
    "\n",
    "print(\"Starting mining from publications.csv (Akkadian-only pages)...\")\n",
    "mine_publications(PUBS_PATH, OUT_PATH, CHUNKSIZE)\n",
    "print(f\"Saved mined sentences to: {OUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27a664f",
   "metadata": {},
   "source": [
    "## üîó Sentence-Level Alignment with published_texts.csv\n",
    "\n",
    "**‚ö†Ô∏è PREREQUISITE: Run the data mining cell above first to generate `mined_publications_en.csv`.**\n",
    "\n",
    "Goal: Align mined English sentences from `mined_publications_en.csv` to Akkadian transliterations in `published_texts.csv` by matching catalog labels and aliases.\n",
    "\n",
    "Approach:\n",
    "- Load `published_texts.csv` (‚âà8k rows) and `mined_publications_en.csv`.\n",
    "- Extract catalog-like refs (e.g., BIN VI 39, Kt 72/k) from English sentences.\n",
    "\n",
    "- Fuzzy-match refs to `publication_catalog` or `aliases` in `published_texts.csv` using RapidFuzz.- Emit candidate parallel pairs to `aligned_pairs_candidates.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a49db8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "PUBLISHED_TEXTS_PATH = os.getenv('PUBLISHED_TEXTS_CSV', 'published_texts.csv')\n",
    "MINED_EN_PATH = os.getenv('MINED_PUBLICATIONS_OUT', 'mined_publications_en.csv')\n",
    "ALIGNED_OUT_PATH = os.getenv('ALIGNED_PAIRS_OUT', 'aligned_pairs_candidates.csv')\n",
    "\n",
    "# Heuristic patterns for publication labels and catalog IDs\n",
    "CATALOG_PATTERNS = [\n",
    "    r\"\\bBIN\\s+[IVXLCDM]+\\s*\\d+\\b\",\n",
    "    r\"\\bKt\\.?\\s*\\d+/?[A-Za-z0-9-]*\\b\",\n",
    "    r\"\\bBM\\s*\\d+[A-Za-z]?\\b\",\n",
    "    r\"\\bYBC\\s*\\d+\\b\",\n",
    "    r\"\\b(AbB|AKT|CCT|KBo|KUB)\\s*\\d+[A-Za-z0-9-]*\\b\",\n",
    "]\n",
    "\n",
    "def extract_catalog_refs(text: str) -> list:\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    text = fix_text(text)\n",
    "    text = unidecode(text)\n",
    "    refs = set()\n",
    "    for pat in CATALOG_PATTERNS:\n",
    "        for m in re.finditer(pat, text, flags=re.IGNORECASE):\n",
    "            ref = m.group(0).strip()\n",
    "            ref = re.sub(r\"\\s+\", \" \", ref)\n",
    "            refs.add(ref)\n",
    "    return list(refs)\n",
    "\n",
    "def build_alias_index(df: pd.DataFrame):\n",
    "    \"\"\"Build a search index over publication_catalog and aliases fields.\"\"\"\n",
    "    index_records = []\n",
    "    for i, row in df.iterrows():\n",
    "        rid = i\n",
    "        label = str(row.get('label', '') or '')\n",
    "        pubcat = str(row.get('publication_catalog', '') or '')\n",
    "        aliases = str(row.get('aliases', '') or '')\n",
    "        tokens = []\n",
    "        for field in (pubcat, aliases, label):\n",
    "            parts = re.split(r\"[|,;]\", field)\n",
    "            for p in parts:\n",
    "                p = unidecode(p.strip())\n",
    "                if p:\n",
    "                    tokens.append(p)\n",
    "        tokens = list(dict.fromkeys(tokens))\n",
    "        index_records.append({'rid': rid, 'tokens': tokens})\n",
    "    return index_records\n",
    "\n",
    "def find_matches(refs: list, index_records: list, score_cutoff: int = 85):\n",
    "    \"\"\"For each ref, fuzzy-match against index tokens.\"\"\"\n",
    "    candidates = set()\n",
    "    for ref in refs:\n",
    "        for rec in index_records:\n",
    "            for tok in rec['tokens']:\n",
    "                score = fuzz.token_set_ratio(ref, tok)\n",
    "                if score >= score_cutoff:\n",
    "                    candidates.add(rec['rid'])\n",
    "                    break\n",
    "    return list(candidates)\n",
    "\n",
    "def align_sentences(mined_path: str, published_path: str, out_path: str):\n",
    "    pub_df = pd.read_csv(published_path)\n",
    "    for col in ['transliteration', 'publication_catalog', 'aliases', 'label']:\n",
    "        if col not in pub_df.columns:\n",
    "            pub_df[col] = ''\n",
    "    alias_index = build_alias_index(pub_df)\n",
    "\n",
    "    Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    written = 0\n",
    "    total = 0\n",
    "\n",
    "    with open(out_path, 'w', newline='', encoding='utf-8') as f_out:\n",
    "        writer = csv.writer(f_out)\n",
    "        writer.writerow(['pdf_name', 'page', 'english_sentence', 'matched_label', 'transliteration'])\n",
    "\n",
    "        for chunk in pd.read_csv(mined_path, chunksize=5000):\n",
    "            for _, row in chunk.iterrows():\n",
    "                total += 1\n",
    "                pdf = str(row.get('pdf_name', '') or '')\n",
    "                page = int(row.get('page', -1)) if pd.notna(row.get('page')) else -1\n",
    "                sent = str(row.get('english_sentence', '') or '')\n",
    "                if not sent:\n",
    "                    continue\n",
    "                refs = extract_catalog_refs(sent)\n",
    "                if not refs:\n",
    "                    continue\n",
    "                cand_ids = find_matches(refs, alias_index, score_cutoff=85)\n",
    "                for rid in cand_ids:\n",
    "                    t_row = pub_df.iloc[rid]\n",
    "                    matched_label = str(t_row.get('label', '') or '')\n",
    "                    translit = str(t_row.get('transliteration', '') or '')\n",
    "                    if translit:\n",
    "                        writer.writerow([pdf, page, sent, matched_label, translit])\n",
    "                        written += 1\n",
    "            if total % 10000 == 0:\n",
    "                print(f\"Processed {total} sentences; wrote {written} candidate pairs...\")\n",
    "\n",
    "    print(f\"Alignment complete. Total sentences: {total}, candidates written: {written}\")\n",
    "    print(f\"Saved to: {out_path}\")\n",
    "\n",
    "print(\"Starting alignment: mined_publications_en.csv ‚Üí published_texts.csv\")\n",
    "align_sentences(MINED_EN_PATH, PUBLISHED_TEXTS_PATH, ALIGNED_OUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c8e3dd",
   "metadata": {},
   "source": [
    "## ‚úÖ Quality Filter & Summary\n",
    "\n",
    "**‚ö†Ô∏è PREREQUISITE: Run the alignment cell above first to generate `aligned_pairs_candidates.csv`.**\n",
    "\n",
    "Filter aligned pairs for training quality:\n",
    "- Remove pairs where transliteration or English is too short/long\n",
    "- Discard pairs with extreme length ratios (likely misaligned)\n",
    "\n",
    "- Keep pairs with domain terms or high lexicon match- Output: `aligned_pairs_filtered.csv` ready for training augmentation\n",
    "- Sample results for sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320765ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "ALIGNED_PATH = os.getenv('ALIGNED_PAIRS_OUT', 'aligned_pairs_candidates.csv')\n",
    "FILTERED_OUT_PATH = os.getenv('FILTERED_PAIRS_OUT', 'aligned_pairs_filtered.csv')\n",
    "\n",
    "def filter_quality(aligned_path: str, out_path: str):\n",
    "    \"\"\"Filter aligned pairs for training quality.\"\"\"\n",
    "    df = pd.read_csv(aligned_path)\n",
    "    print(f\"Loaded {len(df)} candidate pairs\")\n",
    "    \n",
    "    # Length filters\n",
    "    df['t_len'] = df['transliteration'].str.split().str.len()\n",
    "    df['e_len'] = df['english_sentence'].str.split().str.len()\n",
    "    \n",
    "    # Apply filters\n",
    "    df_filtered = df[\n",
    "        (df['t_len'] >= 3) & (df['t_len'] <= 150) &\n",
    "        (df['e_len'] >= 3) & (df['e_len'] <= 150) &\n",
    "        (df['t_len'] / (df['e_len'] + 1) >= 0.5) &\n",
    "        (df['t_len'] / (df['e_len'] + 1) <= 3.0)\n",
    "    ].copy()\n",
    "    \n",
    "    domain_terms = ['tablet', 'seal', 'silver', 'tin', 'letter', 'text', 'archive', 'merchant', 'trade']\n",
    "    df_filtered['has_domain'] = df_filtered['english_sentence'].str.lower().str.contains('|'.join(domain_terms), na=False)\n",
    "    \n",
    "    df_filtered[['pdf_name', 'page', 'english_sentence', 'matched_label', 'transliteration']].to_csv(out_path, index=False)\n",
    "    \n",
    "    print(f\"After quality filtering: {len(df_filtered)} pairs retained\")\n",
    "    print(f\"Saved to: {out_path}\\n\")\n",
    "    \n",
    "    print(\"Sample aligned pairs (first 5):\")\n",
    "    for i, row in df_filtered.head(5).iterrows():\n",
    "        print(f\"\\n[{i}]\")\n",
    "        print(f\"  EN: {row['english_sentence'][:80]}...\")\n",
    "        print(f\"  AK: {row['transliteration'][:80]}...\")\n",
    "    \n",
    "    return len(df_filtered)\n",
    "\n",
    "count = filter_quality(ALIGNED_PATH, FILTERED_OUT_PATH)\n",
    "print(f\"\\n‚úì Quality filtering complete. {count} high-quality pairs ready for training augmentation.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 15061024,
     "sourceId": 121150,
     "sourceType": "competition"
    },
    {
     "datasetId": 9082937,
     "sourceId": 14236819,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 867.451795,
   "end_time": "2025-12-25T11:06:53.451666",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-25T10:52:25.999871",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "077ae2461fb6489b97106a1caaafb370": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_eb6470d874c040e698b88b4827bb0052",
        "IPY_MODEL_772639f9a8104921b6f3b1caca957605",
        "IPY_MODEL_c0e6baa9bf9a411b844486a5ac4eb0f2"
       ],
       "layout": "IPY_MODEL_bd2909e5aebc4611a9e453f84a7e8035",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0adb4c94b7b74e03b9969a916a78f816": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2a1fc3087f004cdcbe55deb12e9b9d55": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2adf7045efe64b7cb4c5556604eb75e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2d2eba874f204b159a6a962c13f13b19": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2d432c967de54ce58ca8f97185c3edd5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_907a9c57f14d46909be51efea7772bfe",
       "max": 1452,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dfea59b2310d4bf7a765969e33c563e4",
       "tabbable": null,
       "tooltip": null,
       "value": 1452
      }
     },
     "310b3b3d8e6e4913bf9b553d7df21e92": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4948d8ef30b94d23ab5670946a3aea08": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4ecbe0b10d9f4af2862caa0ea4819ad3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "62b2c58f9ef642879c9120277b64490f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ab9961958af74ef6b85fd74f35f7ab79",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a2e79e4817c1410fad2a93325460dab6",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "6bfa7186924b4ef1b09723815e8039e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e0dd8d999ad42c98136d00236800e95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e3c59e812f44e02bbde7360657be1e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7212b9bcee854738bc028dc516c6d9e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6bfa7186924b4ef1b09723815e8039e7",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_9c4f0d0224314af5a5348f524290228d",
       "tabbable": null,
       "tooltip": null,
       "value": "Downloading‚Äábuilder‚Äáscript:‚Äá"
      }
     },
     "757491e8dcfb4e53bbde385ec37d11c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "76050bf59c0b404eb86de944a9d2f440": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "772639f9a8104921b6f3b1caca957605": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cbcf3f903c0142bb919b4c6c873027b8",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4ecbe0b10d9f4af2862caa0ea4819ad3",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "8ae65202365844b3823b46cc09af0d8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7212b9bcee854738bc028dc516c6d9e0",
        "IPY_MODEL_62b2c58f9ef642879c9120277b64490f",
        "IPY_MODEL_d254aa49e2c748839b11c3ae30b3ed4b"
       ],
       "layout": "IPY_MODEL_0adb4c94b7b74e03b9969a916a78f816",
       "tabbable": null,
       "tooltip": null
      }
     },
     "907a9c57f14d46909be51efea7772bfe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "939f39d353254f2188c3154b27045a38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6e0dd8d999ad42c98136d00236800e95",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_4948d8ef30b94d23ab5670946a3aea08",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá1452/1452‚Äá[00:02&lt;00:00,‚Äá685.40‚Äáexamples/s]"
      }
     },
     "9c4f0d0224314af5a5348f524290228d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a12b2c8b8d9045ad9880827234dd0592": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a151a03ca0304312ade7c4c2a3fca88b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a2e79e4817c1410fad2a93325460dab6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ab9961958af74ef6b85fd74f35f7ab79": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "ac4c4df806d943919a176f5abba4439e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d2eba874f204b159a6a962c13f13b19",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_ea4d9cb6237b410fa26d0ef017695535",
       "tabbable": null,
       "tooltip": null,
       "value": "Map:‚Äá100%"
      }
     },
     "b584c545f2a04b22a8684541f3716bb8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f29b32d0d9ff4816ae71db8424c042ee",
        "IPY_MODEL_2d432c967de54ce58ca8f97185c3edd5",
        "IPY_MODEL_939f39d353254f2188c3154b27045a38"
       ],
       "layout": "IPY_MODEL_ed16ef8fdffb4b9b8536b8c6e9d727bf",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b999aa2ad3044b9cb4a67d342fc9aabc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ac4c4df806d943919a176f5abba4439e",
        "IPY_MODEL_d6dab87b9b4b4b0fa1f6ca17928ae214",
        "IPY_MODEL_f4856502a22146fb8fde2d23cb451348"
       ],
       "layout": "IPY_MODEL_6e3c59e812f44e02bbde7360657be1e9",
       "tabbable": null,
       "tooltip": null
      }
     },
     "bd2909e5aebc4611a9e453f84a7e8035": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c0e6baa9bf9a411b844486a5ac4eb0f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_310b3b3d8e6e4913bf9b553d7df21e92",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_d3822816c9214e8296dbc9d8f6a53130",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá9.01k/?‚Äá[00:00&lt;00:00,‚Äá925kB/s]"
      }
     },
     "ca6c0b7ac45e453daf901dbe2533d931": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cbcf3f903c0142bb919b4c6c873027b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "d254aa49e2c748839b11c3ae30b3ed4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a12b2c8b8d9045ad9880827234dd0592",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_2adf7045efe64b7cb4c5556604eb75e9",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá8.15k/?‚Äá[00:00&lt;00:00,‚Äá832kB/s]"
      }
     },
     "d29e22650257471d8935422c67a4c6b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d3822816c9214e8296dbc9d8f6a53130": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d6dab87b9b4b4b0fa1f6ca17928ae214": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2a1fc3087f004cdcbe55deb12e9b9d55",
       "max": 77,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_757491e8dcfb4e53bbde385ec37d11c7",
       "tabbable": null,
       "tooltip": null,
       "value": 77
      }
     },
     "da9bc0ca3f1e42268d44dd4984814919": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dfea59b2310d4bf7a765969e33c563e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ea4d9cb6237b410fa26d0ef017695535": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "eb6470d874c040e698b88b4827bb0052": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ca6c0b7ac45e453daf901dbe2533d931",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_f1f41397162d4f36aba6f0441042960e",
       "tabbable": null,
       "tooltip": null,
       "value": "Downloading‚Äábuilder‚Äáscript:‚Äá"
      }
     },
     "ed16ef8fdffb4b9b8536b8c6e9d727bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f1f41397162d4f36aba6f0441042960e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f29b32d0d9ff4816ae71db8424c042ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_76050bf59c0b404eb86de944a9d2f440",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_d29e22650257471d8935422c67a4c6b3",
       "tabbable": null,
       "tooltip": null,
       "value": "Map:‚Äá100%"
      }
     },
     "f4856502a22146fb8fde2d23cb451348": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_da9bc0ca3f1e42268d44dd4984814919",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_a151a03ca0304312ade7c4c2a3fca88b",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá77/77‚Äá[00:00&lt;00:00,‚Äá599.94‚Äáexamples/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
