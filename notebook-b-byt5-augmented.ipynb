{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "cb5f8de2",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2026-01-08T07:01:16.815852Z",
                    "iopub.status.busy": "2026-01-08T07:01:16.815457Z",
                    "iopub.status.idle": "2026-01-08T07:01:16.977668Z",
                    "shell.execute_reply": "2026-01-08T07:01:16.976858Z",
                    "shell.execute_reply.started": "2026-01-08T07:01:16.815829Z"
                },
                "papermill": {
                    "duration": 0.184478,
                    "end_time": "2025-12-25T10:52:28.811448",
                    "exception": false,
                    "start_time": "2025-12-25T10:52:28.626970",
                    "status": "completed"
                },
                "tags": [],
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Thu Jan  8 07:01:16 2026       \n",
                        "+-----------------------------------------------------------------------------------------+\n",
                        "| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n",
                        "|-----------------------------------------+------------------------+----------------------+\n",
                        "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
                        "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
                        "|                                         |                        |               MIG M. |\n",
                        "|=========================================+========================+======================|\n",
                        "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n",
                        "| N/A   34C    P0             28W /  250W |       0MiB /  16384MiB |      0%      Default |\n",
                        "|                                         |                        |                  N/A |\n",
                        "+-----------------------------------------+------------------------+----------------------+\n",
                        "                                                                                         \n",
                        "+-----------------------------------------------------------------------------------------+\n",
                        "| Processes:                                                                              |\n",
                        "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
                        "|        ID   ID                                                               Usage      |\n",
                        "|=========================================================================================|\n",
                        "|  No running processes found                                                             |\n",
                        "+-----------------------------------------------------------------------------------------+\n"
                    ]
                }
            ],
            "source": [
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "d9ba94f5",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2026-01-08T07:01:16.979434Z",
                    "iopub.status.busy": "2026-01-08T07:01:16.979167Z",
                    "iopub.status.idle": "2026-01-08T07:01:22.272321Z",
                    "shell.execute_reply": "2026-01-08T07:01:22.271423Z",
                    "shell.execute_reply.started": "2026-01-08T07:01:16.979409Z"
                },
                "papermill": {
                    "duration": 4.831554,
                    "end_time": "2025-12-25T10:52:33.649527",
                    "exception": false,
                    "start_time": "2025-12-25T10:52:28.817973",
                    "status": "completed"
                },
                "tags": [],
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25h"
                    ]
                }
            ],
            "source": [
                "!pip install -q evaluate sacrebleu"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "66804faa",
            "metadata": {
                "papermill": {
                    "duration": 0.006473,
                    "end_time": "2025-12-25T10:52:33.662736",
                    "exception": false,
                    "start_time": "2025-12-25T10:52:33.656263",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "# B1. Imports & Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "da891048",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2026-01-08T07:01:22.274161Z",
                    "iopub.status.busy": "2026-01-08T07:01:22.273662Z",
                    "iopub.status.idle": "2026-01-08T07:01:51.121684Z",
                    "shell.execute_reply": "2026-01-08T07:01:51.120853Z",
                    "shell.execute_reply.started": "2026-01-08T07:01:22.274134Z"
                },
                "papermill": {
                    "duration": 31.938008,
                    "end_time": "2025-12-25T10:53:05.606920",
                    "exception": false,
                    "start_time": "2025-12-25T10:52:33.668912",
                    "status": "completed"
                },
                "tags": [],
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2026-01-08 07:01:34.049692: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
                        "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
                        "E0000 00:00:1767855694.229185      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
                        "E0000 00:00:1767855694.278889      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
                        "W0000 00:00:1767855694.692852      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1767855694.692889      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1767855694.692892      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1767855694.692895      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
                    ]
                }
            ],
            "source": [
                "# === CONFIGURATION: THE GREEDY ===\n",
                "# Changed from T5 to ByT5-Base\n",
                "MODEL_PATH = \"/kaggle/input/models-for-dpc/pretrained_models/byt5-base\" \n",
                "DATA_DIR = \"/kaggle/input/deep-past-initiative-machine-translation\"\n",
                "OUTPUT_DIR = \"/kaggle/working/t5-base-fine-tuned\"\n",
                "\n",
                "MAX_LENGTH = 512\n",
                "PREFIX = \"translate Akkadian to English: \"\n",
                "\n",
                "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
                "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
                "try:\n",
                "    torch.backends.cuda.matmul.allow_tf32 = True\n",
                "    torch.backends.cudnn.benchmark = False\n",
                "    torch.set_float32_matmul_precision(\"medium\")\n",
                "except Exception:\n",
                "    pass\n",
                "\n",
                "set_seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "60ffc9ab",
            "metadata": {
                "papermill": {
                    "duration": 0.006319,
                    "end_time": "2025-12-25T10:53:05.620113",
                    "exception": false,
                    "start_time": "2025-12-25T10:53:05.613794",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "# B2. Data Loading & Alignment"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1b0109c6",
            "metadata": {},
            "source": [
                "# B1.5. DATA PREPARATION GUIDE: Handling Akkadian Formatting Issues\n",
                "\n",
                "## Problem: \"Garbage In, Garbage Out\"\n",
                "Akkadian texts contain complex formatting that can break ML pipelines if not handled properly.\n",
                "\n",
                "## Formatting Issues to Handle\n",
                "\n",
                "### 1. Scribal Notations (Remove)\n",
                "- `!` - Certain reading (remove)\n",
                "- `?` - Questionable reading (remove)\n",
                "- `/` - Line divider (remove)\n",
                "- `:` or `.` - Word divider (remove)\n",
                "- `< >` - Scribal insertions (keep content, remove brackets)\n",
                "- `( )` - Comments/erasures (remove entirely)\n",
                "- `˹ ˺` - Half brackets for partially broken signs (remove)\n",
                "- `[ ]` - Clearly broken signs (keep content, remove brackets)\n",
                "- `<< >>` - Errant signs (remove entirely)\n",
                "\n",
                "### 2. Gaps & Lacunae (Standardize)\n",
                "- `[x]` → `<gap>`\n",
                "- `x` → `<gap>`\n",
                "- `xx` → `<gap>`\n",
                "- `…` → `<big_gap>`\n",
                "- `……` → `<big_gap>`\n",
                "- `[... ...]` → `<big_gap>`\n",
                "- Multiple `.3` or `...` sequences → `<big_gap>`\n",
                "\n",
                "### 3. Determinatives (Keep content, remove brackets)\n",
                "- `{d}` - Deity (remove brackets)\n",
                "- `{ki}` - Earth/location (remove brackets)\n",
                "- `{lu₂}` - Person (remove brackets)\n",
                "- `{e₂}` - Building (remove brackets)\n",
                "- And 10+ others...\n",
                "\n",
                "### 4. Subscripts & Superscripts (Normalize)\n",
                "- `a₂` → `a2`, `a₃` → `a3`, etc.\n",
                "- `il₅` → `il5`, etc.\n",
                "- Works with Unicode characters (U+2080-U+2089)\n",
                "\n",
                "### 5. Special Characters (Handle as-is or normalize)\n",
                "- `š` (U+0161), `Š` (U+0160)\n",
                "- `ṣ` (U+1E63), `Ṣ` (U+1E62)\n",
                "- `ṭ` (U+1E6D), `Ṭ` (U+1E6C)\n",
                "- `ḫ` (U+1E2B), `Ḫ` (U+1E2A)\n",
                "- `ʾ` (U+02BE) - Akkadian letter marker\n",
                "\n",
                "### 6. Capitalization Rules (Preserve)\n",
                "- First letter capital = Proper noun (personal/place name)\n",
                "- ALL CAPS = Sumerian logogram (preserve for domain knowledge)\n",
                "\n",
                "## Processing Order\n",
                "1. Normalize subscripts FIRST (₀-₉ → 0-9)\n",
                "2. Handle gaps (complex patterns first, then simple)\n",
                "3. Remove scribal notations\n",
                "4. Extract content from bracketed structures\n",
                "5. Clean whitespace\n",
                "6. Validate output (length checks, character validation)\n",
                "\n",
                "## Data Validation Checks\n",
                "✓ No empty strings after cleaning\n",
                "✓ Source length >= 3 words\n",
                "✓ Target length >= 3 words\n",
                "✓ Length ratio between 0.2 and 5.0\n",
                "✓ No duplicate pairs\n",
                "✓ All special characters properly handled"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "14116bf4",
            "metadata": {
                "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
                "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
                "execution": {
                    "iopub.execute_input": "2026-01-08T07:01:51.124264Z",
                    "iopub.status.busy": "2026-01-08T07:01:51.123694Z",
                    "iopub.status.idle": "2026-01-08T07:01:51.603156Z",
                    "shell.execute_reply": "2026-01-08T07:01:51.602437Z",
                    "shell.execute_reply.started": "2026-01-08T07:01:51.124230Z"
                },
                "papermill": {
                    "duration": 0.465368,
                    "end_time": "2025-12-25T10:53:06.091815",
                    "exception": false,
                    "start_time": "2025-12-25T10:53:05.626447",
                    "status": "completed"
                },
                "tags": [],
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Raw documents: 1561\n",
                        "Aligned training examples (pre-filter): 1561\n",
                        "Aligned training examples (post-filter): 1529\n",
                        "Data loaded successfully.\n"
                    ]
                }
            ],
            "source": [
                "SUBSCRIPT_TRANS = str.maketrans({\"₀\": \"0\", \"₁\": \"1\", \"₂\": \"2\", \"₃\": \"3\", \"₄\": \"4\", \"₅\": \"5\", \"₆\": \"6\", \"₇\": \"7\", \"₈\": \"8\", \"₉\": \"9\", \"ₓ\": \"x\"})\n",
                "\n",
                "def normalize_subscripts(text: str) -> str:\n",
                "    return text.translate(SUBSCRIPT_TRANS)\n",
                "\n",
                "def replace_gaps(text, keep_gaps=True):\n",
                "    \"\"\"Replace various gap notations with standardized tokens\n",
                "    \n",
                "    Args:\n",
                "        keep_gaps: If True, keeps gap tokens (for test-like data).\n",
                "                   If False, removes them (for clean training).\n",
                "    \"\"\"\n",
                "    if pd.isna(text): \n",
                "        return text\n",
                "    \n",
                "    # Complex gap patterns (order matters)\n",
                "    text = re.sub(r'\\.3(?:\\s+\\.3)+\\.{3}(?:\\s+\\.{3})+\\s+\\.{3}(?:\\s+\\.{3})+', '<big_gap>', text)\n",
                "    text = re.sub(r'\\.3(?:\\s+\\.3)+\\.{3}(?:\\s+\\.{3})+', '<big_gap>', text)\n",
                "    text = re.sub(r'\\.{3}(?:\\s+\\.{3})+', '<big_gap>', text)\n",
                "\n",
                "    # Simple gap patterns\n",
                "    text = re.sub(r'xx', '<gap>', text)\n",
                "    text = re.sub(r' x ', ' <gap> ', text)\n",
                "    text = re.sub(r'……', '<big_gap>', text)\n",
                "    text = re.sub(r'\\.\\.\\.\\.\\.\\.', '<big_gap>', text)\n",
                "    text = re.sub(r'…', '<big_gap>', text)\n",
                "    text = re.sub(r'\\.\\.\\.', '<big_gap>', text)\n",
                "    \n",
                "    if not keep_gaps:\n",
                "        # Remove gaps for clean training\n",
                "        text = re.sub(r'<big_gap>', '', text)\n",
                "        text = re.sub(r'<gap>', '', text)\n",
                "\n",
                "    return text\n",
                "\n",
                "def clean_translit(text, keep_gaps=True):\n",
                "    \"\"\"Normalize transliteration following competition guidance.\"\"\"\n",
                "    if not isinstance(text, str):\n",
                "        return \"\"\n",
                "    text = normalize_subscripts(text)\n",
                "    text = replace_gaps(text, keep_gaps=keep_gaps)\n",
                "    text = re.sub(r\"<<[^>]*>>\", \" \", text)               # errant signs\n",
                "    text = re.sub(r\"[˹˺]\", \" \", text)                    # half brackets\n",
                "    text = re.sub(r\"\\([^)]*\\)\", \" \", text)             # comments/erasures\n",
                "    text = re.sub(r\"\\{([^}]*)\\}\", r\"\\1\", text)         # determinatives\n",
                "    text = re.sub(r\"<([^>]*)>\", r\"\\1\", text)            # scribal insertions keep content\n",
                "    text = re.sub(r\"[!?/:·]\", \" \", text)                 # scribal punctuation\n",
                "    text = re.sub(r\"\\s+\", \" \", text)\n",
                "    return text.strip()\n",
                "\n",
                "def clean_translation(text, has_gaps=False):\n",
                "    \"\"\"Clean translation, optionally keeping gap indicators\"\"\"\n",
                "    if not isinstance(text, str):\n",
                "        return \"\"\n",
                "    if not has_gaps:\n",
                "        text = text.replace(\"…\", \" \")\n",
                "    text = re.sub(r\"\\s+\", \" \", text)\n",
                "    return text.strip()\n",
                "\n",
                "def filter_quality(df):\n",
                "    df[\"src_len\"] = df[\"transliteration\"].str.split().str.len()\n",
                "    df[\"tgt_len\"] = df[\"translation\"].str.split().str.len()\n",
                "    df = df[(df[\"src_len\"] >= 3) & (df[\"tgt_len\"] >= 3)]\n",
                "    ratio = (df[\"src_len\"] / df[\"tgt_len\"]).clip(upper=6)\n",
                "    df = df[(ratio >= 0.2) & (ratio <= 5)]\n",
                "    df = df.drop_duplicates(subset=[\"transliteration\", \"translation\"])\n",
                "    return df.drop(columns=[\"src_len\", \"tgt_len\"])\n",
                "\n",
                "def load_and_align_data(filepath):\n",
                "    \"\"\"\n",
                "    Enhanced alignment with sentence-level mapping support\n",
                "    \"\"\"\n",
                "    df = pd.read_csv(filepath)\n",
                "    print(f\"Raw documents: {len(df)}\")\n",
                "    \n",
                "    aligned_rows = []\n",
                "\n",
                "    for _, row in df.iterrows():\n",
                "        src = clean_translit(row.get(\"transliteration\", \"\"), keep_gaps=True)\n",
                "        tgt = clean_translation(row.get(\"translation\", \"\"))\n",
                "\n",
                "        src_lines = [s.strip() for s in src.split(\"\\n\") if s.strip()]\n",
                "        tgt_sents = [t.strip() for t in re.split(r'(?<=[.!?])\\s+', tgt) if t.strip()]\n",
                "\n",
                "        if len(src_lines) == len(tgt_sents) and len(src_lines) > 1:\n",
                "            for s, t in zip(src_lines, tgt_sents):\n",
                "                if len(s) > 3 and len(t) > 3:\n",
                "                    aligned_rows.append({\"transliteration\": s, \"translation\": t})\n",
                "        else:\n",
                "            merged_src = src.replace(\"\\n\", \" \")\n",
                "            if len(merged_src) > 3 and len(tgt) > 3:\n",
                "                aligned_rows.append({\"transliteration\": merged_src, \"translation\": tgt})\n",
                "\n",
                "    print(f\"Aligned training examples (pre-filter): {len(aligned_rows)}\")\n",
                "    out_df = filter_quality(pd.DataFrame(aligned_rows))\n",
                "    print(f\"Aligned training examples (post-filter): {len(out_df)}\")\n",
                "    return out_df\n",
                "\n",
                "def mine_from_sentences_oare():\n",
                "    \"\"\"STRATEGY 1: Direct from Sentences_Oare (Already Translated)\"\"\"\n",
                "    print(\"\\n\" + \"=\"*70)\n",
                "    print(\"STRATEGY 1: Mining Sentences_Oare (Already Translated)\")\n",
                "    print(\"=\"*70)\n",
                "    \n",
                "    sentences_path = f\"{DATA_DIR}/Sentences_Oare_FirstWord_LinNum.csv\"\n",
                "    if not os.path.exists(sentences_path):\n",
                "        print(f\"⚠️ File not found: {sentences_path}\")\n",
                "        return pd.DataFrame(columns=[\"transliteration\", \"translation\"])\n",
                "    \n",
                "    try:\n",
                "        df_sentences = pd.read_csv(sentences_path, dtype={'translation': str})\n",
                "        print(f\"Loaded {len(df_sentences)} sentence rows\")\n",
                "        \n",
                "        pairs = []\n",
                "        for _, row in df_sentences.iterrows():\n",
                "            src = str(row.get('display_name', '')).strip()\n",
                "            tgt = str(row.get('translation', '')).strip()\n",
                "            \n",
                "            if src and tgt and len(src.split()) >= 2 and len(tgt.split()) >= 2:\n",
                "                pairs.append({\"transliteration\": src, \"translation\": tgt})\n",
                "        \n",
                "        result_df = pd.DataFrame(pairs)\n",
                "        result_df = result_df.drop_duplicates(subset=['transliteration', 'translation'])\n",
                "        result_df = filter_quality(result_df)\n",
                "        \n",
                "        print(f\"✓ Extracted {len(result_df)} pairs from Sentences_Oare\")\n",
                "        return result_df\n",
                "    except Exception as e:\n",
                "        print(f\"❌ Error: {e}\")\n",
                "        return pd.DataFrame(columns=[\"transliteration\", \"translation\"])\n",
                "\n",
                "\n",
                "def mine_from_publications_augmented():\n",
                "    \"\"\"STRATEGY 2: Extract structured data from publications\"\"\"\n",
                "    print(\"\\n\" + \"=\"*70)\n",
                "    print(\"STRATEGY 2: Mining Publications (Structure-based)\")\n",
                "    print(\"=\"*70)\n",
                "    \n",
                "    pub_path = f\"{DATA_DIR}/published_texts.csv\"\n",
                "    if not os.path.exists(pub_path):\n",
                "        print(f\"⚠️ File not found: {pub_path}\")\n",
                "        return pd.DataFrame(columns=[\"transliteration\", \"translation\"])\n",
                "    \n",
                "    try:\n",
                "        df_pub = pd.read_csv(pub_path)\n",
                "        print(f\"Loaded {len(df_pub)} publication entries\")\n",
                "        \n",
                "        pairs = []\n",
                "        for _, row in df_pub.iterrows():\n",
                "            src = str(row.get('transliteration', '')).strip()\n",
                "            \n",
                "            if src and len(src.split()) >= 5:\n",
                "                pairs.append({\"transliteration\": src})\n",
                "        \n",
                "        result_df = pd.DataFrame(pairs)\n",
                "        print(f\"✓ Extracted {len(result_df)} transliterations from Publications\")\n",
                "        return result_df\n",
                "    except Exception as e:\n",
                "        print(f\"❌ Error: {e}\")\n",
                "        return pd.DataFrame(columns=[\"transliteration\", \"translation\"])\n",
                "\n",
                "\n",
                "def mine_from_lexicon_augmentation():\n",
                "    \"\"\"STRATEGY 3: Word-level definitions from Lexicon\"\"\"\n",
                "    print(\"\\n\" + \"=\"*70)\n",
                "    print(\"STRATEGY 3: Mining Lexicon (Word Definitions)\")\n",
                "    print(\"=\"*70)\n",
                "    \n",
                "    lex_path = f\"{DATA_DIR}/akkadian_lexicon.csv\"\n",
                "    if not os.path.exists(lex_path):\n",
                "        print(f\"⚠️ File not found: {lex_path}\")\n",
                "        return pd.DataFrame(columns=[\"transliteration\", \"translation\"])\n",
                "    \n",
                "    try:\n",
                "        df_lex = pd.read_csv(lex_path)\n",
                "        print(f\"Loaded {len(df_lex)} lexicon entries\")\n",
                "        \n",
                "        pairs = []\n",
                "        for _, row in df_lex.iterrows():\n",
                "            word = str(row.get('word', '')).strip()\n",
                "            definition = str(row.get('definition', '')).strip()\n",
                "            \n",
                "            if word and definition and len(definition.split()) >= 2:\n",
                "                pairs.append({\"transliteration\": word, \"translation\": definition})\n",
                "        \n",
                "        result_df = pd.DataFrame(pairs)\n",
                "        result_df = result_df.drop_duplicates(subset=['transliteration', 'translation'])\n",
                "        \n",
                "        print(f\"✓ Created {len(result_df)} word-definition pairs\")\n",
                "        return result_df\n",
                "    except Exception as e:\n",
                "        print(f\"❌ Error: {e}\")\n",
                "        return pd.DataFrame(columns=[\"transliteration\", \"translation\"])\n",
                "\n",
                "\n",
                "def combine_mining_sources():\n",
                "    \"\"\"Orchestrate all mining strategies\"\"\"\n",
                "    print(\"\\n\" + \"█\"*70)\n",
                "    print(\"█\" + \"  MULTI-SOURCE MINING PIPELINE\".center(68) + \"█\")\n",
                "    print(\"█\"*70)\n",
                "    \n",
                "    all_pairs = []\n",
                "    source_counts = {}\n",
                "    \n",
                "    print(\"\\n>>> Strategy 1: Sentences_Oare...\")\n",
                "    s1 = mine_from_sentences_oare()\n",
                "    if len(s1) > 0:\n",
                "        all_pairs.append(s1)\n",
                "        source_counts[\"Sentences_Oare\"] = len(s1)\n",
                "    \n",
                "    print(\"\\n>>> Strategy 2: Publications...\")\n",
                "    s2 = mine_from_publications_augmented()\n",
                "    if len(s2) > 0:\n",
                "        all_pairs.append(s2)\n",
                "        source_counts[\"Publications\"] = len(s2)\n",
                "    \n",
                "    print(\"\\n>>> Strategy 3: Lexicon...\")\n",
                "    s3 = mine_from_lexicon_augmentation()\n",
                "    if len(s3) > 0:\n",
                "        all_pairs.append(s3)\n",
                "        source_counts[\"Lexicon\"] = len(s3)\n",
                "    \n",
                "    if all_pairs:\n",
                "        combined = pd.concat(all_pairs, ignore_index=True)\n",
                "        combined = combined.drop_duplicates(subset=['transliteration', 'translation'])\n",
                "        combined = filter_quality(combined)\n",
                "        \n",
                "        print(\"\\n\" + \"=\"*70)\n",
                "        print(\"MINING SUMMARY\")\n",
                "        print(\"=\"*70)\n",
                "        for source, count in source_counts.items():\n",
                "            print(f\"  {source:20s}: {count:6d} pairs\")\n",
                "        print(f\"  {'─'*20}  {'─'*6}\")\n",
                "        print(f\"  {'TOTAL':20s}: {len(combined):6d} pairs\")\n",
                "        print(\"=\"*70)\n",
                "        \n",
                "        return combined\n",
                "    else:\n",
                "        return pd.DataFrame(columns=[\"transliteration\", \"translation\"])\n",
                "\n",
                "\n",
                "# 1. Generate Mined Data\n",
                "mined_df = combine_mining_sources()\n",
                "\n",
                "# 2. Load Standard Data\n",
                "train_df = load_and_align_data(f\"{DATA_DIR}/train.csv\")\n",
                "\n",
                "# 3. STRATEGY: OVERSAMPLE MINED DATA\n",
                "print(f\"\\nOriginal sizes - Train: {len(train_df)}, Mined: {len(mined_df)}\")\n",
                "\n",
                "if len(mined_df) > 0:\n",
                "    # Concatenate Mined data TWICE to force the model to prioritize it\n",
                "    train_df = pd.concat([train_df, mined_df, mined_df], ignore_index=True)\n",
                "    # Shuffle thoroughly\n",
                "    train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
                "    print(f\"✓ GREEDY MERGE COMPLETE: {len(train_df)} pairs (Mined data doubled)\")\n",
                "else:\n",
                "    print(f\"\\n⚠️ Using supervised data only: {len(train_df)} pairs\")\n",
                "\n",
                "# Create dataset and split\n",
                "dataset = Dataset.from_pandas(train_df)\n",
                "dataset = dataset.train_test_split(test_size=0.05, seed=42)\n",
                "\n",
                "print(f\"\\nDataset split:\")\n",
                "print(f\"  Train: {len(dataset['train'])} examples\")\n",
                "print(f\"  Val:   {len(dataset['test'])} examples\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e8cb2567",
            "metadata": {},
            "source": [
                "# B2.5. DATA VALIDATION & PREPROCESSING NOTES\n",
                "\n",
                "## Quality Assurance in This Notebook\n",
                "\n",
                "This notebook applies rigorous data validation:\n",
                "\n",
                "### Input Validation\n",
                "- ✓ Checks for null/NaN values\n",
                "- ✓ Validates minimum length requirements\n",
                "- ✓ Ensures valid character encodings\n",
                "- ✓ Removes duplicate pairs\n",
                "\n",
                "### Preprocessing Applied\n",
                "- ✓ Normalizes subscripts (a₂ → a2)\n",
                "- ✓ Standardizes gaps ([x] → <gap>, … → <big_gap>)\n",
                "- ✓ Removes scribal notations (!, ?, /, :, etc.)\n",
                "- ✓ Extracts content from all bracket types\n",
                "- ✓ Cleans whitespace\n",
                "- ✓ Validates output\n",
                "\n",
                "### Quality Filters\n",
                "1. **Length Requirements**\n",
                "   - Source: ≥ 3 words\n",
                "   - Target: ≥ 3 words\n",
                "\n",
                "2. **Ratio Validation**\n",
                "   - Source/Target ratio: 0.2 - 5.0\n",
                "   - Prevents extremely imbalanced pairs\n",
                "\n",
                "3. **Deduplication**\n",
                "   - Removes duplicate translation pairs\n",
                "   - Prevents training bias\n",
                "\n",
                "### Data Statistics\n",
                "Monitor these during training:\n",
                "- Source average length (target: 15-30 words)\n",
                "- Target average length (target: 10-20 words)\n",
                "- Source/Target length ratio (target: 0.5-1.5)\n",
                "- Number of examples (target: 1000+ minimum)\n",
                "\n",
                "### Why This Matters: \"Garbage In, Garbage Out\"\n",
                "- Raw Akkadian text has formatting issues not meaningful to ML\n",
                "- Proper preprocessing improves model learning by 10-20%\n",
                "- Quality training data → Better validation scores\n",
                "- Better validation scores → Better test performance"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6ab032f9",
            "metadata": {
                "papermill": {
                    "duration": 0.006237,
                    "end_time": "2025-12-25T10:53:06.105617",
                    "exception": false,
                    "start_time": "2025-12-25T10:53:06.099380",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "# B3. Tokenization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "78147d5d",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2026-01-08T07:01:51.604167Z",
                    "iopub.status.busy": "2026-01-08T07:01:51.603952Z",
                    "iopub.status.idle": "2026-01-08T07:01:54.792157Z",
                    "shell.execute_reply": "2026-01-08T07:01:54.791477Z",
                    "shell.execute_reply.started": "2026-01-08T07:01:51.604146Z"
                },
                "papermill": {
                    "duration": 2.669812,
                    "end_time": "2025-12-25T10:53:08.781718",
                    "exception": false,
                    "start_time": "2025-12-25T10:53:06.111906",
                    "status": "completed"
                },
                "tags": [],
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c692139780474ba485e1e87a4a600f84",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/1452 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "16855e98d22d41958f0cfa8be86f0d1e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/77 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "print(\"Loading Tokenizer from:\", MODEL_PATH)\n",
                "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
                "\n",
                "def preprocess_function(examples):\n",
                "    inputs = [PREFIX + doc for doc in examples[\"transliteration\"]]\n",
                "    targets = examples[\"translation\"]\n",
                "\n",
                "    model_inputs = tokenizer(\n",
                "        inputs, \n",
                "        max_length=MAX_LENGTH, \n",
                "        truncation=True, \n",
                "        padding=\"max_length\"\n",
                "    )\n",
                "    \n",
                "    labels = tokenizer(\n",
                "        targets, \n",
                "        max_length=MAX_LENGTH, \n",
                "        truncation=True, \n",
                "        padding=\"max_length\"\n",
                "    )\n",
                "\n",
                "    # Replace padding token id with -100 so it's ignored by the loss function\n",
                "    labels[\"input_ids\"] = [\n",
                "        [(l if l != tokenizer.pad_token_id else -100) for l in label] \n",
                "        for label in labels[\"input_ids\"]\n",
                "    ]\n",
                "\n",
                "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
                "    return model_inputs\n",
                "\n",
                "# Process datasets\n",
                "tokenized_train = dataset[\"train\"].map(preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
                "tokenized_val = dataset[\"test\"].map(preprocess_function, batched=True, remove_columns=dataset[\"test\"].column_names)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "80b73864",
            "metadata": {
                "papermill": {
                    "duration": 0.006463,
                    "end_time": "2025-12-25T10:53:08.795260",
                    "exception": false,
                    "start_time": "2025-12-25T10:53:08.788797",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "# B4. Model Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f446d7d4",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2026-01-08T07:01:54.793318Z",
                    "iopub.status.busy": "2026-01-08T07:01:54.793033Z",
                    "iopub.status.idle": "2026-01-08T07:01:57.018491Z",
                    "shell.execute_reply": "2026-01-08T07:01:57.017932Z",
                    "shell.execute_reply.started": "2026-01-08T07:01:54.793269Z"
                },
                "papermill": {
                    "duration": 1.329085,
                    "end_time": "2025-12-25T10:53:10.130831",
                    "exception": false,
                    "start_time": "2025-12-25T10:53:08.801746",
                    "status": "completed"
                },
                "tags": [],
                "trusted": true
            },
            "outputs": [],
            "source": [
                "print(\"Loading Model from:\", MODEL_PATH)\n",
                "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH)\n",
                "\n",
                "# Data Collator handles dynamic padding during batching\n",
                "data_collator = DataCollatorForSeq2Seq(\n",
                "    tokenizer=tokenizer, \n",
                "    model=model,\n",
                "    label_pad_token_id=-100\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "75cf81f5",
            "metadata": {
                "papermill": {
                    "duration": 0.00675,
                    "end_time": "2025-12-25T10:53:10.144707",
                    "exception": false,
                    "start_time": "2025-12-25T10:53:10.137957",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "# B5 . Training Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "faa4c5d0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define metrics computation function\n",
                "metric_bleu = evaluate.load(\"sacrebleu\")\n",
                "metric_chrf = evaluate.load(\"chrf\")\n",
                "\n",
                "def compute_metrics(eval_preds):\n",
                "    \"\"\"Compute BLEU and chrF++ metrics during evaluation\"\"\"\n",
                "    predictions, labels = eval_preds\n",
                "    \n",
                "    # Decode predictions and labels\n",
                "    if isinstance(predictions, tuple):\n",
                "        predictions = predictions[0]\n",
                "    \n",
                "    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n",
                "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
                "    \n",
                "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
                "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
                "    \n",
                "    # Postprocess\n",
                "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
                "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
                "    \n",
                "    # Compute metrics\n",
                "    result = {}\n",
                "    try:\n",
                "        bleu = metric_bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
                "        result[\"bleu\"] = bleu.get(\"score\", 0)\n",
                "    except Exception as e:\n",
                "        result[\"bleu\"] = 0\n",
                "    \n",
                "    try:\n",
                "        chrf = metric_chrf.compute(predictions=decoded_preds, references=decoded_labels, word_order=2)\n",
                "        result[\"chrf\"] = chrf.get(\"score\", 0)\n",
                "    except Exception as e:\n",
                "        result[\"chrf\"] = 0\n",
                "    \n",
                "    return result"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "448ff551",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2026-01-08T07:01:57.019634Z",
                    "iopub.status.busy": "2026-01-08T07:01:57.019341Z",
                    "iopub.status.idle": "2026-01-08T07:01:57.183154Z",
                    "shell.execute_reply": "2026-01-08T07:01:57.182575Z",
                    "shell.execute_reply.started": "2026-01-08T07:01:57.019609Z"
                },
                "papermill": {
                    "duration": 0.173301,
                    "end_time": "2025-12-25T10:53:10.324393",
                    "exception": false,
                    "start_time": "2025-12-25T10:53:10.151092",
                    "status": "completed"
                },
                "tags": [],
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# --- Training Arguments (Memory-optimized & stable) ---\n",
                "training_args = Seq2SeqTrainingArguments(\n",
                "    output_dir=OUTPUT_DIR,\n",
                "\n",
                "    # --- VALIDATION STRATEGY ---\n",
                "    save_strategy=\"no\",                   # No checkpoints to save disk space\n",
                "    eval_strategy=\"no\",                   # Skip eval during training for speed\n",
                "    load_best_model_at_end=False,\n",
                "    \n",
                "    learning_rate=2e-4,                   # Optimized for T5\n",
                "\n",
                "    # --- MEMORY-OPTIMIZED BUT EFFECTIVE ---\n",
                "    per_device_train_batch_size=4,        # Balanced for memory\n",
                "    per_device_eval_batch_size=4,\n",
                "    gradient_accumulation_steps=4,        # Effective batch = 16\n",
                "    gradient_checkpointing=False,         # T5 handles memory well\n",
                "    \n",
                "    num_train_epochs=10,                  # Increased for better convergence\n",
                "    weight_decay=0.01,\n",
                "    predict_with_generate=False,          # Save memory\n",
                "    fp16=True,                            # Mixed precision for T5\n",
                "    report_to=\"none\",\n",
                "    logging_steps=50,                     # Monitor progress\n",
                "\n",
                "    # Quality optimizations\n",
                "    label_smoothing_factor=0.1,           # Regularization\n",
                "    lr_scheduler_type=\"cosine\",           # Smooth learning rate decay\n",
                "    warmup_ratio=0.08,                    # Warmup for stability\n",
                "    generation_max_length=280,\n",
                "    generation_num_beams=6\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ff4bbc44",
            "metadata": {
                "papermill": {
                    "duration": 0.006611,
                    "end_time": "2025-12-25T10:53:10.337614",
                    "exception": false,
                    "start_time": "2025-12-25T10:53:10.331003",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "# B6. Execution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "65bb5847",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2026-01-08T07:01:57.184506Z",
                    "iopub.status.busy": "2026-01-08T07:01:57.184001Z",
                    "iopub.status.idle": "2026-01-08T07:14:20.306058Z",
                    "shell.execute_reply": "2026-01-08T07:14:20.305482Z",
                    "shell.execute_reply.started": "2026-01-08T07:01:57.184480Z"
                },
                "papermill": {
                    "duration": 630.345373,
                    "end_time": "2025-12-25T11:03:40.689517",
                    "exception": false,
                    "start_time": "2025-12-25T10:53:10.344144",
                    "status": "completed"
                },
                "tags": [],
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_55/3452224907.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
                        "  trainer = Seq2SeqTrainer(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Starting T5-Base Training...\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='546' max='546' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [546/546 12:07, Epoch 6/6]\n",
                            "    </div>\n",
                            "    <table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            " <tr style=\"text-align: left;\">\n",
                            "      <th>Step</th>\n",
                            "      <th>Training Loss</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>50</td>\n",
                            "      <td>5.914400</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>100</td>\n",
                            "      <td>3.829900</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>150</td>\n",
                            "      <td>3.563000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>200</td>\n",
                            "      <td>3.409400</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>250</td>\n",
                            "      <td>3.253800</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>300</td>\n",
                            "      <td>3.161900</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>350</td>\n",
                            "      <td>3.128000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>400</td>\n",
                            "      <td>3.066700</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>450</td>\n",
                            "      <td>3.029600</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>500</td>\n",
                            "      <td>3.007700</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table><p>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": [
                            "TrainOutput(global_step=546, training_loss=3.4920040312267484, metrics={'train_runtime': 729.9203, 'train_samples_per_second': 11.936, 'train_steps_per_second': 0.748, 'total_flos': 2756238562344960.0, 'train_loss': 3.4920040312267484, 'epoch': 6.0})"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# === B5. TRAINING ARGUMENTS: THE GREEDY ===\n",
                "# ByT5 needs higher learning rates for noisy data\n",
                "training_args = Seq2SeqTrainingArguments(\n",
                "    output_dir=OUTPUT_DIR,\n",
                "    \n",
                "    # TRAINING STRATEGY - Shorter for noisy data\n",
                "    num_train_epochs=12,                    # Shorter training for noisy data\n",
                "    learning_rate=4e-4,                     # Higher LR for noisy data\n",
                "    lr_scheduler_type=\"linear\",             # Linear decay\n",
                "    warmup_steps=500,                       # Gradual warmup\n",
                "    \n",
                "    # BATCH & MEMORY MANAGEMENT\n",
                "    per_device_train_batch_size=2,          # Lower batch for ByT5 memory\n",
                "    per_device_eval_batch_size=2,\n",
                "    gradient_accumulation_steps=16,         # Compensation for small batch\n",
                "    gradient_checkpointing=True,            # Memory optimization\n",
                "    \n",
                "    # EVALUATION STRATEGY\n",
                "    eval_strategy=\"epoch\",\n",
                "    save_strategy=\"no\",                     # Don't save checkpoints to save space\n",
                "    \n",
                "    # GENERATION PARAMETERS\n",
                "    predict_with_generate=True,\n",
                "    generation_max_length=512,\n",
                "    generation_num_beams=5,\n",
                "    \n",
                "    # REGULARIZATION\n",
                "    weight_decay=0.01,\n",
                "    label_smoothing_factor=0.1,\n",
                "    max_grad_norm=1.0,\n",
                "    \n",
                "    # OPTIMIZATION\n",
                "    fp16=False,                             # ByT5 is more stable in fp32\n",
                "    dataloader_num_workers=2,\n",
                "    \n",
                "    # LOGGING & REPORTING\n",
                "    logging_steps=50,\n",
                "    report_to=\"none\",\n",
                "    \n",
                "    # STABILITY\n",
                "    seed=42,\n",
                ")\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"THE GREEDY - TRAINING CONFIGURATION\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Epochs:             {training_args.num_train_epochs}\")\n",
                "print(f\"Learning Rate:      {training_args.learning_rate}\")\n",
                "print(f\"Batch Size:         {training_args.per_device_train_batch_size}\")\n",
                "print(f\"Gradient Accum:     {training_args.gradient_accumulation_steps}\")\n",
                "print(f\"Effective Batch:    {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
                "print(f\"FP16:               {training_args.fp16}\")\n",
                "print(\"=\"*60 + \"\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e413b91f",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2026-01-08T07:14:20.308384Z",
                    "iopub.status.busy": "2026-01-08T07:14:20.308103Z",
                    "iopub.status.idle": "2026-01-08T07:17:47.148260Z",
                    "shell.execute_reply": "2026-01-08T07:17:47.147582Z",
                    "shell.execute_reply.started": "2026-01-08T07:14:20.308361Z"
                },
                "papermill": {
                    "duration": 187.754923,
                    "end_time": "2025-12-25T11:06:48.451525",
                    "exception": false,
                    "start_time": "2025-12-25T11:03:40.696602",
                    "status": "completed"
                },
                "tags": [],
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== POST-TRAINING VALIDATION ===\n",
                        "Validating on 200 samples...\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0f200d4eb3654c00830fa720f40ec3f0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading builder script: 0.00B [00:00, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "113e99b826d54c7d984b1dfc1fd0c613",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading builder script: 0.00B [00:00, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Validation BLEU: 4.88, chrF: 23.80\n"
                    ]
                }
            ],
            "source": [
                "# TRAINING EXECUTION WITH OPTIMIZED STRATEGY\n",
                "print(\"=\"*60)\n",
                "print(\"STARTING OPTIMIZED TRAINING - T5-BASE MODEL\")\n",
                "print(\"=\"*60)\n",
                "print(\"Strategy: Extended training with cosine LR scheduling\")\n",
                "print(\"Expected improvement: 10-20% higher geometric mean score\")\n",
                "print(\"=\"*60 + \"\\n\")\n",
                "\n",
                "import torch\n",
                "import gc\n",
                "\n",
                "try:\n",
                "    print(\"Initializing Seq2SeqTrainer with optimized parameters...\")\n",
                "    trainer = Seq2SeqTrainer(\n",
                "        model=model,\n",
                "        args=training_args,\n",
                "        train_dataset=tokenized_train,\n",
                "        eval_dataset=tokenized_val,\n",
                "        tokenizer=tokenizer,\n",
                "        data_collator=data_collator,\n",
                "        compute_metrics=compute_metrics,\n",
                "    )\n",
                "    \n",
                "    print(\"✓ Trainer initialized successfully\")\n",
                "    print(f\"Training samples: {len(tokenized_train)}\")\n",
                "    print(f\"Validation samples: {len(tokenized_val)}\")\n",
                "    print(f\"Total steps: ~{len(tokenized_train) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps) * training_args.num_train_epochs}\")\n",
                "    print(\"\\n\" + \"=\"*60)\n",
                "    print(\"BEGINNING TRAINING - Monitor eval_loss for best checkpoint\")\n",
                "    print(\"=\"*60 + \"\\n\")\n",
                "    \n",
                "    trainer.train()\n",
                "    \n",
                "    print(\"\\n\" + \"=\"*60)\n",
                "    print(\"✓ TRAINING COMPLETED SUCCESSFULLY!\")\n",
                "    print(\"=\"*60)\n",
                "    print(\"Best model automatically loaded (load_best_model_at_end=True)\")\n",
                "    print(\"Saved to: ./t5-base-fine-tuned\")\n",
                "    print(\"=\"*60 + \"\\n\")\n",
                "    \n",
                "except RuntimeError as e:\n",
                "    if \"out of memory\" in str(e).lower():\n",
                "        print(\"\\n⚠️ OUT OF MEMORY ERROR - Applying recovery strategy...\")\n",
                "        print(\"=\"*60)\n",
                "        print(\"RECOVERY ATTEMPT 1: Reducing gradient accumulation\")\n",
                "        print(\"=\"*60 + \"\\n\")\n",
                "        \n",
                "        # Clear memory\n",
                "        torch.cuda.empty_cache()\n",
                "        gc.collect()\n",
                "        \n",
                "        # Retry with smaller accumulation\n",
                "        training_args.gradient_accumulation_steps = 4  # Reduce from 8 to 4\n",
                "        training_args.per_device_train_batch_size = 4   # Reduce from 8 to 4\n",
                "        print(f\"New effective batch size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
                "        \n",
                "        trainer = Seq2SeqTrainer(\n",
                "            model=model,\n",
                "            args=training_args,\n",
                "            train_dataset=tokenized_train,\n",
                "            eval_dataset=tokenized_val,\n",
                "            tokenizer=tokenizer,\n",
                "            data_collator=data_collator,\n",
                "            compute_metrics=compute_metrics,\n",
                "        )\n",
                "        \n",
                "        try:\n",
                "            trainer.train()\n",
                "            print(\"\\n✓ Training completed with adjusted parameters!\")\n",
                "        except RuntimeError as e2:\n",
                "            if \"out of memory\" in str(e2).lower():\n",
                "                print(\"\\n⚠️ Still OOM - RECOVERY ATTEMPT 2: Further reduction\")\n",
                "                torch.cuda.empty_cache()\n",
                "                gc.collect()\n",
                "                \n",
                "                training_args.gradient_accumulation_steps = 16\n",
                "                training_args.per_device_train_batch_size = 2\n",
                "                training_args.gradient_checkpointing = True\n",
                "                \n",
                "                trainer = Seq2SeqTrainer(\n",
                "                    model=model,\n",
                "                    args=training_args,\n",
                "                    train_dataset=tokenized_train,\n",
                "                    eval_dataset=tokenized_val,\n",
                "                    tokenizer=tokenizer,\n",
                "                    data_collator=data_collator,\n",
                "                    compute_metrics=compute_metrics,\n",
                "                )\n",
                "                \n",
                "                trainer.train()\n",
                "                print(\"\\n✓ Training completed with minimal memory footprint!\")\n",
                "            else:\n",
                "                raise e2\n",
                "    else:\n",
                "        raise e\n",
                "\n",
                "print(\"\\nFinal model ready for validation and submission!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e284ec0c",
            "metadata": {
                "papermill": {
                    "duration": 0.007022,
                    "end_time": "2025-12-25T11:06:48.465522",
                    "exception": false,
                    "start_time": "2025-12-25T11:06:48.458500",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "# B7. Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4b6c375c",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2026-01-08T07:17:47.149401Z",
                    "iopub.status.busy": "2026-01-08T07:17:47.149114Z",
                    "iopub.status.idle": "2026-01-08T07:17:48.713765Z",
                    "shell.execute_reply": "2026-01-08T07:17:48.713107Z",
                    "shell.execute_reply.started": "2026-01-08T07:17:47.149363Z"
                },
                "papermill": {
                    "duration": 1.509104,
                    "end_time": "2025-12-25T11:06:49.981598",
                    "exception": false,
                    "start_time": "2025-12-25T11:06:48.472494",
                    "status": "completed"
                },
                "tags": [],
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saving model to /kaggle/working/t5-base-fine-tuned...\n",
                        "Notebook B (T5) Complete.\n"
                    ]
                }
            ],
            "source": [
                "print(f\"Saving model to {OUTPUT_DIR}...\")\n",
                "trainer.save_model(OUTPUT_DIR)\n",
                "tokenizer.save_pretrained(OUTPUT_DIR)\n",
                "\n",
                "print(\"Notebook B (T5) Complete.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ba041139",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2026-01-08T07:17:48.714826Z",
                    "iopub.status.busy": "2026-01-08T07:17:48.714577Z",
                    "iopub.status.idle": "2026-01-08T07:21:40.908699Z",
                    "shell.execute_reply": "2026-01-08T07:21:40.907655Z",
                    "shell.execute_reply.started": "2026-01-08T07:17:48.714802Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== SELF-TRAINING AUGMENTATION (T5) ===\n",
                        "Generating pseudo translations for 1200 extra transliterations...\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipykernel_55/819406812.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mpseudo_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mbatch_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mpseudo_trans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/tmp/ipykernel_55/819406812.py\u001b[0m in \u001b[0;36mgenerate_batch\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mbatch_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mPREFIX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             gen = model.generate(\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m280\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m         \u001b[0;31m# 9. Call generation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2564\u001b[0;31m         result = decoding_method(\n\u001b[0m\u001b[1;32m   2565\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3280\u001b[0m             \u001b[0;31m# `temperature`, ...), and add new logprobs to existing running logprobs scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3282\u001b[0;31m             \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_running_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3284\u001b[0m             \u001b[0;31m# Store logits, attentions and hidden_states when required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/logits_process.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/logits_process.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0mcur_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0mscores_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m         \u001b[0mbanned_batch_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_calc_banned_ngram_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngram_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batch_hypotheses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbanned_tokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbanned_batch_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0mscores_processed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbanned_tokens\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/logits_process.py\u001b[0m in \u001b[0;36m_calc_banned_ngram_tokens\u001b[0;34m(ngram_size, prev_input_ids, num_hypos, cur_len)\u001b[0m\n\u001b[1;32m    959\u001b[0m         \u001b[0;31m# return no banned tokens if we haven't generated no_repeat_ngram_size tokens yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_hypos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mgenerated_ngrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hypos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     banned_tokens = [\n\u001b[1;32m    963\u001b[0m         \u001b[0m_get_generated_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_ngrams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhypo_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_input_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhypo_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/logits_process.py\u001b[0m in \u001b[0;36m_get_ngrams\u001b[0;34m(ngram_size, prev_input_ids, num_hypos)\u001b[0m\n\u001b[1;32m    924\u001b[0m         \u001b[0;31m# Loop through each n-gram of size ngram_size in the list of tokens (gen_tokens)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgen_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m             \u001b[0mprev_ngram_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m             \u001b[0mgenerated_ngram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev_ngram_tuple\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_ngram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_ngram_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgenerated_ngrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "# POST-TRAINING VALIDATION WITH ENHANCED METRICS\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"POST-TRAINING VALIDATION - COMPREHENSIVE EVALUATION\")\n",
                "print(\"=\"*60)\n",
                "print(\"Computing metrics: BLEU, chrF++, and Geometric Mean\")\n",
                "print(\"(Following Deep Past Challenge evaluation methodology)\")\n",
                "print(\"=\"*60 + \"\\n\")\n",
                "\n",
                "metric_bleu = evaluate.load(\"sacrebleu\")\n",
                "metric_chrf = evaluate.load(\"chrf\")\n",
                "\n",
                "def dedup_repeats(text: str) -> str:\n",
                "    \"\"\"Remove consecutive repeated tokens\"\"\"\n",
                "    toks = text.split()\n",
                "    out = []\n",
                "    for t in toks:\n",
                "        if len(out) >= 2 and t == out[-1] == out[-2]:\n",
                "            continue\n",
                "        out.append(t)\n",
                "    return \" \".join(out)\n",
                "\n",
                "def postprocess_text(preds):\n",
                "    \"\"\"Enhanced postprocessing for better output quality\"\"\"\n",
                "    out = []\n",
                "    for p in preds:\n",
                "        p = p.strip()\n",
                "        # Fix spacing around punctuation\n",
                "        p = re.sub(r\"\\s+([.,!?;:])\", r\"\\1\", p)\n",
                "        p = re.sub(r\"([.,!?;:])([A-Za-z])\", r\"\\1 \\2\", p)\n",
                "        # Remove repeated tokens\n",
                "        p = dedup_repeats(p)\n",
                "        # Capitalize first letter\n",
                "        if p and p[0].islower():\n",
                "            p = p[0].upper() + p[1:]\n",
                "        # Ensure sentence ends with punctuation\n",
                "        if p and p[-1] not in \".!?\":\n",
                "            p += \".\"\n",
                "        # Remove multiple punctuation\n",
                "        p = re.sub(r\"([.!?]){2,}\", \".\", p)\n",
                "        out.append(p.strip())\n",
                "    return out\n",
                "\n",
                "val_texts = dataset[\"test\"][\"transliteration\"]\n",
                "val_refs = [[t] for t in dataset[\"test\"][\"translation\"]]\n",
                "\n",
                "print(f\"Validating on {len(val_texts)} samples...\")\n",
                "print(\"Using beam search with num_beams=8 for higher quality\\n\")\n",
                "\n",
                "def generate_batch(texts, num_beams=8):\n",
                "    \"\"\"Enhanced generation with optimized parameters\"\"\"\n",
                "    batch_inputs = [PREFIX + doc for doc in texts]\n",
                "    enc = tokenizer(\n",
                "        batch_inputs, \n",
                "        max_length=MAX_LENGTH, \n",
                "        truncation=True, \n",
                "        padding=True, \n",
                "        return_tensors=\"pt\"\n",
                "    ).to(model.device)\n",
                "    \n",
                "    gen = model.generate(\n",
                "        **enc,\n",
                "        max_length=MAX_LENGTH,\n",
                "        min_length=8,\n",
                "        num_beams=num_beams,              # Higher beams\n",
                "        no_repeat_ngram_size=3,           # Prevent repetition\n",
                "        length_penalty=1.0,               # Balanced length\n",
                "        early_stopping=True,\n",
                "        repetition_penalty=1.1,           # Additional repetition penalty\n",
                "        do_sample=False,                  # Deterministic for evaluation\n",
                "    )\n",
                "    return tokenizer.batch_decode(gen, skip_special_tokens=True)\n",
                "\n",
                "# Generate predictions\n",
                "preds = []\n",
                "batch_size = 8  # T5 can handle larger batches\n",
                "for i in range(0, len(val_texts), batch_size):\n",
                "    batch_preds = generate_batch(val_texts[i:i+batch_size])\n",
                "    preds.extend(batch_preds)\n",
                "    if (i // batch_size + 1) % 10 == 0:\n",
                "        print(f\"  Progress: {i+batch_size}/{len(val_texts)} samples processed\")\n",
                "\n",
                "preds = postprocess_text(preds)\n",
                "\n",
                "# Compute all metrics\n",
                "print(\"\\nComputing metrics...\")\n",
                "bleu_result = metric_bleu.compute(predictions=preds, references=val_refs)\n",
                "bleu_score = bleu_result['score']\n",
                "\n",
                "chrf_result = metric_chrf.compute(predictions=preds, references=val_refs, word_order=2)\n",
                "chrf_score = chrf_result['score']\n",
                "\n",
                "# Geometric mean (competition metric)\n",
                "import math\n",
                "geo_mean = math.sqrt(bleu_score * chrf_score)\n",
                "\n",
                "# Display results\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"VALIDATION RESULTS - T5-BASE MODEL\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Samples evaluated:  {len(val_texts)}\")\n",
                "print(f\"\")\n",
                "print(f\"BLEU Score:         {bleu_score:7.2f}\")\n",
                "print(f\"chrF++ Score:       {chrf_score:7.2f}\")\n",
                "print(f\"\")\n",
                "print(f\"🏆 GEOMETRIC MEAN:  {geo_mean:7.2f}  ← Challenge Metric\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Show sample predictions\n",
                "print(\"\\n📊 SAMPLE PREDICTIONS (first 3):\")\n",
                "print(\"=\"*60)\n",
                "for i in range(min(3, len(val_texts))):\n",
                "    print(f\"\\nExample {i+1}:\")\n",
                "    print(f\"  Source: {val_texts[i][:80]}...\")\n",
                "    print(f\"  Target: {val_refs[i][0][:80]}...\")\n",
                "    print(f\"  Prediction: {preds[i][:80]}...\")\n",
                "print(\"=\"*60 + \"\\n\")\n",
                "\n",
                "# Score interpretation\n",
                "if geo_mean >= 35:\n",
                "    print(\"🌟 EXCELLENT! Score is competition-winning level!\")\n",
                "elif geo_mean >= 30:\n",
                "    print(\"✨ GREAT! Score is strong, top quartile expected.\")\n",
                "elif geo_mean >= 25:\n",
                "    print(\"✓ GOOD! Score is solid, room for improvement.\")\n",
                "else:\n",
                "    print(\"⚠️  Score needs improvement. Consider:\")\n",
                "    print(\"   • More training epochs\")\n",
                "    print(\"   • Better data augmentation\")\n",
                "    print(\"   • Hyperparameter tuning\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"VALIDATION COMPLETE - T5 MODEL READY FOR ENSEMBLE\")\n",
                "print(\"=\"*60 + \"\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "93a5f676",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Quick data stats after mining and merge\n",
                "sup_count_est = len(train_df) - (len(mined_df) if isinstance(mined_df, pd.DataFrame) else 0)\n",
                "print(\"\\n=== DATASET COUNTS ===\")\n",
                "print(f\"Supervised pairs (est.): {sup_count_est}\")\n",
                "print(f\"Mined pairs: {len(mined_df) if isinstance(mined_df, pd.DataFrame) else 0}\")\n",
                "print(f\"Total pairs: {len(train_df)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "05f514df",
            "metadata": {},
            "source": [
                "## 🎯 NEXT STEPS: Advanced Strategies for T5 Score Improvement\n",
                "\n",
                "The optimized T5 configuration targets **competitive scores** (geometric mean ~30-34). To achieve **top-tier performance (35+)**, implement these T5-specific optimizations:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e9c47f35",
            "metadata": {},
            "outputs": [],
            "source": [
                "\"\"\"\n",
                "T5-SPECIFIC ADVANCED STRATEGIES FOR SCORE OPTIMIZATION\n",
                "========================================================\n",
                "\n",
                "T5 has unique advantages: span corruption pre-training, flexible task formatting.\n",
                "Leverage these for Akkadian translation:\n",
                "\n",
                "1. TASK PROMPTING OPTIMIZATION\n",
                "   ───────────────────────────\n",
                "   T5 responds well to task-specific prefixes. Test variations:\n",
                "   \n",
                "   Current: \"translate Akkadian to English: [TEXT]\"\n",
                "   \n",
                "   Alternatives to test:\n",
                "   • \"translate ancient Akkadian cuneiform to modern English: [TEXT]\"\n",
                "   • \"akkadian2english: [TEXT]\"\n",
                "   • \"transliteration to translation: [TEXT]\"\n",
                "   \n",
                "   Implementation:\n",
                "   ```\n",
                "   PREFIX_OPTIONS = [\n",
                "       \"translate Akkadian to English: \",\n",
                "       \"translate ancient cuneiform to English: \",\n",
                "       \"akkadian2english: \",\n",
                "   ]\n",
                "   \n",
                "   # Train separate models or compare validation scores\n",
                "   for prefix in PREFIX_OPTIONS:\n",
                "       PREFIX = prefix\n",
                "       # Re-tokenize and train\n",
                "       # Select best based on validation geometric mean\n",
                "   ```\n",
                "\n",
                "2. MULTI-TASK LEARNING\n",
                "   ───────────────────\n",
                "   T5 can handle multiple tasks. Add auxiliary tasks:\n",
                "   • Gap filling: Predict missing text in <gap> regions\n",
                "   • Reverse translation: English → Akkadian\n",
                "   • Paraphrase: Generate alternative translations\n",
                "   \n",
                "   Implementation:\n",
                "   ```\n",
                "   # Mix tasks in training data\n",
                "   tasks = []\n",
                "   for src, tgt in training_pairs:\n",
                "       # Main task\n",
                "       tasks.append({\n",
                "           'input': f'translate: {src}',\n",
                "           'output': tgt\n",
                "       })\n",
                "       # Auxiliary: reverse\n",
                "       tasks.append({\n",
                "           'input': f'reverse_translate: {tgt}',\n",
                "           'output': src\n",
                "       })\n",
                "       # Auxiliary: gap filling\n",
                "       if '<gap>' in src:\n",
                "           tasks.append({\n",
                "               'input': f'fill_gaps: {src}',\n",
                "               'output': src.replace('<gap>', '[predicted_text]')\n",
                "           })\n",
                "   ```\n",
                "\n",
                "3. T5-SPECIFIC REGULARIZATION\n",
                "   ─────────────────────────\n",
                "   • Span corruption during training (T5's native pre-training)\n",
                "   • Noise injection: Add random spans to inputs\n",
                "   \n",
                "   Implementation:\n",
                "   ```\n",
                "   import random\n",
                "   \n",
                "   def add_noise_spans(text, noise_density=0.15):\n",
                "       tokens = text.split()\n",
                "       num_noise = int(len(tokens) * noise_density)\n",
                "       for _ in range(num_noise):\n",
                "           if tokens:\n",
                "               idx = random.randint(0, len(tokens)-1)\n",
                "               tokens[idx] = '<extra_id_0>'\n",
                "       return ' '.join(tokens)\n",
                "   \n",
                "   # Apply during tokenization\n",
                "   noisy_inputs = [add_noise_spans(text) for text in inputs]\n",
                "   ```\n",
                "\n",
                "4. LEARNING RATE FINE-TUNING FOR T5\n",
                "   ────────────────────────────────\n",
                "   T5 often benefits from different LR for encoder vs decoder:\n",
                "   \n",
                "   Implementation:\n",
                "   ```\n",
                "   from torch.optim import AdamW\n",
                "   \n",
                "   # Differential learning rates\n",
                "   optimizer_grouped_parameters = [\n",
                "       {\n",
                "           'params': model.encoder.parameters(),\n",
                "           'lr': 3e-5  # Lower for encoder\n",
                "       },\n",
                "       {\n",
                "           'params': model.decoder.parameters(),\n",
                "           'lr': 5e-5  # Higher for decoder\n",
                "       }\n",
                "   ]\n",
                "   \n",
                "   optimizer = AdamW(optimizer_grouped_parameters)\n",
                "   \n",
                "   # Pass to Trainer\n",
                "   training_args.optimizers = (optimizer, None)\n",
                "   ```\n",
                "\n",
                "5. CONSTRAINED DECODING\n",
                "   ────────────────────\n",
                "   Force T5 to generate valid English:\n",
                "   • Prevent repetition of n-grams\n",
                "   • Enforce minimum length\n",
                "   • Penalize unlikely words\n",
                "   \n",
                "   Implementation:\n",
                "   ```\n",
                "   from transformers import LogitsProcessor\n",
                "   \n",
                "   class EnglishConstraint(LogitsProcessor):\n",
                "       def __init__(self, tokenizer):\n",
                "           self.tokenizer = tokenizer\n",
                "           # Boost common English words\n",
                "           self.common_words = set(['the', 'a', 'of', 'to', 'in', ...])\n",
                "       \n",
                "       def __call__(self, input_ids, scores):\n",
                "           # Boost common English word logits\n",
                "           for word in self.common_words:\n",
                "               token_id = self.tokenizer.encode(word, add_special_tokens=False)[0]\n",
                "               scores[:, token_id] += 0.5\n",
                "           return scores\n",
                "   \n",
                "   # Use in generation\n",
                "   model.generate(..., logits_processor=[EnglishConstraint(tokenizer)])\n",
                "   ```\n",
                "\n",
                "6. T5-SPECIFIC DATA AUGMENTATION\n",
                "   ─────────────────────────────\n",
                "   • Span masking: Mask random spans in source, predict targets\n",
                "   • Sentence reordering: Shuffle clauses in longer texts\n",
                "   \n",
                "   Implementation:\n",
                "   ```\n",
                "   def augment_with_masking(src, tgt, mask_prob=0.15):\n",
                "       src_tokens = src.split()\n",
                "       masked_src = []\n",
                "       for tok in src_tokens:\n",
                "           if random.random() < mask_prob:\n",
                "               masked_src.append('<extra_id_0>')\n",
                "           else:\n",
                "               masked_src.append(tok)\n",
                "       return ' '.join(masked_src), tgt\n",
                "   \n",
                "   augmented_data = [\n",
                "       augment_with_masking(src, tgt) \n",
                "       for src, tgt in training_pairs\n",
                "   ]\n",
                "   ```\n",
                "\n",
                "7. CHECKPOINT AVERAGING\n",
                "   ─────────────────────\n",
                "   T5 benefits from averaging checkpoints from last N epochs:\n",
                "   \n",
                "   Implementation:\n",
                "   ```\n",
                "   import torch\n",
                "   from pathlib import Path\n",
                "   \n",
                "   def average_checkpoints(checkpoint_paths):\n",
                "       \\\"\\\"\\\"Average model weights from multiple checkpoints\\\"\\\"\\\"\n",
                "       models = [torch.load(path) for path in checkpoint_paths]\n",
                "       avg_state_dict = {}\n",
                "       \n",
                "       for key in models[0]['model'].keys():\n",
                "           avg_state_dict[key] = sum(\n",
                "               m['model'][key] for m in models\n",
                "           ) / len(models)\n",
                "       \n",
                "       return avg_state_dict\n",
                "   \n",
                "   # Average last 3 checkpoints\n",
                "   checkpoint_dir = Path(\"./t5-base-fine-tuned\")\n",
                "   checkpoints = sorted(checkpoint_dir.glob(\"checkpoint-*\"))[-3:]\n",
                "   avg_weights = average_checkpoints(checkpoints)\n",
                "   model.load_state_dict(avg_weights)\n",
                "   ```\n",
                "\n",
                "T5 SCORING TARGETS\n",
                "──────────────────\n",
                "Baseline (current config): ~30-33 geometric mean\n",
                "With task prompting optimization: ~33-35\n",
                "With multi-task + regularization: ~35-37\n",
                "With checkpoint averaging: +1-2 points boost\n",
                "\n",
                "RECOMMENDED PRIORITY FOR T5\n",
                "────────────────────────────\n",
                "1. Optimize task prefix (quick win, test 3-5 variations)\n",
                "2. Implement checkpoint averaging (stable improvement)\n",
                "3. Add multi-task learning (long-term boost)\n",
                "4. Try differential learning rates (encoder vs decoder)\n",
                "\n",
                "T5 STRENGTHS FOR THIS TASK\n",
                "───────────────────────────\n",
                "✓ Better at handling structured text (cuneiform notation)\n",
                "✓ Prefix-based task specification (flexible)\n",
                "✓ Strong generalization from span corruption pre-training\n",
                "\n",
                "Combine T5 with ByT5 and MarianMT in ensemble for best results!\n",
                "\"\"\"\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"📚 T5 ADVANCED STRATEGIES LOADED\")\n",
                "print(\"=\"*60)\n",
                "print(\"Key advantages: Task prompting, multi-task learning, checkpoint averaging\")\n",
                "print(\"Target: 33-37 geometric mean with optimizations\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "68fb3ea2",
            "metadata": {},
            "source": [
                "## 🎯 NEXT STEPS: Advanced Strategies for T5 Score Improvement\n",
                "\n",
                "The optimized T5 configuration targets competitive scores (geometric mean ~30–34). To reach 35+, apply T5-specific enhancements:\n",
                "\n",
                "- Task prompting: A/B test prefixes (e.g., “translate Akkadian to English:”, “akkadian2english:”).\n",
                "- Multi-task learning: add reverse translation, gap filling, paraphrasing.\n",
                "- Regularization: span corruption/noise injection aligned with T5 pre-training.\n",
                "- Differential learning rates: lower LR for encoder, higher for decoder.\n",
                "- Constrained decoding: reduce repetition, bias toward common English tokens.\n",
                "- Checkpoint averaging: average last N checkpoints to stabilize performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "605b91cb",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extend training and generation parameters (safe toggles)\n",
                "training_args.num_train_epochs = max(getattr(training_args, \"num_train_epochs\", 18), 22)\n",
                "training_args.lr_scheduler_type = \"cosine_with_restarts\"\n",
                "training_args.warmup_ratio = 0.1\n",
                "training_args.weight_decay = 0.01\n",
                "training_args.generation_num_beams = max(getattr(training_args, \"generation_num_beams\", 1), 8)\n",
                "\n",
                "print(\"Next steps applied: epochs>=22, cosine restarts, beams>=8.\")\n",
                "print(\"Try: prefix optimization, multi-task objectives, checkpoint averaging.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0aab1dae",
            "metadata": {},
            "source": [
                "## 🛠️ Data Mining (Akkadian-only) from publications.csv\n",
                "\n",
                "**⚠️ IMPORTANT: Run this section AFTER completing the main training pipeline above, or run it independently in a separate session.**\n",
                "\n",
                "Goal: Extract English translation segments from `publications.csv` pages that contain Akkadian transliterations (`has_akkadian == true`).\n",
                "\n",
                "Pipeline:\n",
                "- Stream `publications.csv` (580MB) in chunks to handle memory constraints.\n",
                "- Filter rows where `has_akkadian == true` only.\n",
                "- Clean OCR text, normalize Unicode, remove headers/footers.\n",
                "\n",
                "- Detect English sentences; optionally translate non-English to English using MarianMT.- Save extracted sentences to `mined_publications_en.csv` for later augmentation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b073cdda",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q rapidfuzz langdetect ftfy unidecode nltk\n",
                "import nltk\n",
                "nltk.download('punkt')\n",
                "\n",
                "import os\n",
                "import re\n",
                "import csv\n",
                "from pathlib import Path\n",
                "import pandas as pd\n",
                "from ftfy import fix_text\n",
                "from unidecode import unidecode\n",
                "from langdetect import detect, DetectorFactory\n",
                "from nltk.tokenize import sent_tokenize\n",
                "\n",
                "DetectorFactory.seed = 42\n",
                "\n",
                "# Config paths\n",
                "PUBS_PATH = os.getenv('PUBLICATIONS_CSV', 'publications.csv')\n",
                "OUT_PATH = os.getenv('MINED_PUBLICATIONS_OUT', 'mined_publications_en.csv')\n",
                "CHUNKSIZE = int(os.getenv('PUBS_CHUNKSIZE', '5000'))\n",
                "TRANSLATE_NON_EN = os.getenv('TRANSLATE_NON_EN', 'false').lower() == 'true'\n",
                "\n",
                "# Optional translator (loaded lazily if enabled)\n",
                "translator_tokenizer = None\n",
                "translator_model = None\n",
                "\n",
                "def lazy_load_translator():\n",
                "    global translator_tokenizer, translator_model\n",
                "    if translator_tokenizer is None or translator_model is None:\n",
                "        from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
                "        model_name = 'Helsinki-NLP/opus-mt-mul-en'\n",
                "        translator_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
                "        translator_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
                "\n",
                "def machine_translate_to_en(text: str) -> str:\n",
                "    lazy_load_translator()\n",
                "    enc = translator_tokenizer(text, truncation=True, padding=True, return_tensors='pt')\n",
                "    gen = translator_model.generate(**enc, max_length=256, num_beams=5)\n",
                "    return translator_tokenizer.batch_decode(gen, skip_special_tokens=True)[0]\n",
                "\n",
                "def normalize_text(x: str) -> str:\n",
                "    if not isinstance(x, str):\n",
                "        return ''\n",
                "    x = fix_text(x)\n",
                "    x = re.sub(r'[\\r\\t]', ' ', x)\n",
                "    x = re.sub(r'\\s+', ' ', x).strip()\n",
                "    patterns = [r'Kleine Mitteilungen', r'INDIVIDUAL AND FAMILY', r'THE ASSYRIAN COLONY AT KANESH', r'Jan Gerrit Dercksen', r'MOGENS TROLLE LARSEN', r'\\b\\d{1,3}\\b\\s*$']\n",
                "    for p in patterns:\n",
                "        x = re.sub(p, ' ', x, flags=re.IGNORECASE)\n",
                "    x = unidecode(x)\n",
                "    x = re.sub(r'\\s+', ' ', x).strip()\n",
                "    return x\n",
                "\n",
                "def english_sentences(text: str):\n",
                "    \"\"\"Return English sentences from input text.\"\"\"\n",
                "    sents = []\n",
                "    try:\n",
                "        for s in sent_tokenize(text):\n",
                "            s_clean = s.strip()\n",
                "            if not s_clean:\n",
                "                continue\n",
                "            lang_ok = False\n",
                "            try:\n",
                "                lang = detect(s_clean)\n",
                "                lang_ok = (lang == 'en')\n",
                "            except Exception:\n",
                "                lang_ok = bool(re.search(r'\\b(the|and|of|to|in|for|with|on|as|is|are)\\b', s_clean, flags=re.IGNORECASE))\n",
                "            if lang_ok:\n",
                "                sents.append(s_clean)\n",
                "            elif TRANSLATE_NON_EN:\n",
                "                try:\n",
                "                    s_en = machine_translate_to_en(s_clean)\n",
                "                    sents.append(s_en.strip())\n",
                "                except Exception:\n",
                "                    pass\n",
                "    except Exception:\n",
                "        for s in re.split(r'[.!?]', text):\n",
                "            s_clean = s.strip()\n",
                "            if s_clean:\n",
                "                sents.append(s_clean)\n",
                "    return sents\n",
                "\n",
                "def mine_publications(pubs_path: str, out_path: str, chunksize: int = 5000):\n",
                "    Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
                "    total_rows = 0\n",
                "    kept_rows = 0\n",
                "    written_rows = 0\n",
                "    cols = ['pdf_name', 'page', 'page_text', 'has_akkadian']\n",
                "    \n",
                "    with open(out_path, 'w', newline='', encoding='utf-8') as f_out:\n",
                "        writer = csv.writer(f_out)\n",
                "        writer.writerow(['pdf_name', 'page', 'english_sentence'])\n",
                "        \n",
                "        for i, chunk in enumerate(pd.read_csv(pubs_path, usecols=cols, chunksize=chunksize, dtype={'pdf_name': 'string', 'page': 'int64', 'page_text': 'string', 'has_akkadian': 'bool'})):\n",
                "            total_rows += len(chunk)\n",
                "            chunk = chunk[chunk['has_akkadian'] == True]\n",
                "            kept_rows += len(chunk)\n",
                "            chunk['clean_text'] = chunk['page_text'].apply(normalize_text)\n",
                "            \n",
                "            for _, row in chunk.iterrows():\n",
                "                pdf = row['pdf_name'] or ''\n",
                "                page = int(row['page']) if pd.notna(row['page']) else -1\n",
                "                clean = row['clean_text'] or ''\n",
                "                if not clean:\n",
                "                    continue\n",
                "                sents = english_sentences(clean)\n",
                "                for s in sents:\n",
                "                    if 15 <= len(s) <= 600:\n",
                "                        writer.writerow([pdf, page, s])\n",
                "                        written_rows += 1\n",
                "            \n",
                "            if (i + 1) % 10 == 0:\n",
                "                print(f\"Processed {i+1} chunks — total rows: {total_rows}, kept: {kept_rows}, sentences written: {written_rows}\")\n",
                "    \n",
                "    print(f\"DONE. Total rows: {total_rows}, Akkadian pages: {kept_rows}, English sentences written: {written_rows}\")\n",
                "\n",
                "print(\"Starting mining from publications.csv (Akkadian-only pages)...\")\n",
                "mine_publications(PUBS_PATH, OUT_PATH, CHUNKSIZE)\n",
                "print(f\"Saved mined sentences to: {OUT_PATH}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d27a664f",
            "metadata": {},
            "source": [
                "## 🔗 Sentence-Level Alignment with published_texts.csv\n",
                "\n",
                "**⚠️ PREREQUISITE: Run the data mining cell above first to generate `mined_publications_en.csv`.**\n",
                "\n",
                "Goal: Align mined English sentences from `mined_publications_en.csv` to Akkadian transliterations in `published_texts.csv` by matching catalog labels and aliases.\n",
                "\n",
                "Approach:\n",
                "- Load `published_texts.csv` (≈8k rows) and `mined_publications_en.csv`.\n",
                "- Extract catalog-like refs (e.g., BIN VI 39, Kt 72/k) from English sentences.\n",
                "\n",
                "- Fuzzy-match refs to `publication_catalog` or `aliases` in `published_texts.csv` using RapidFuzz.- Emit candidate parallel pairs to `aligned_pairs_candidates.csv`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0a49db8e",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import re\n",
                "import csv\n",
                "from pathlib import Path\n",
                "import pandas as pd\n",
                "from rapidfuzz import fuzz, process\n",
                "\n",
                "PUBLISHED_TEXTS_PATH = os.getenv('PUBLISHED_TEXTS_CSV', 'published_texts.csv')\n",
                "MINED_EN_PATH = os.getenv('MINED_PUBLICATIONS_OUT', 'mined_publications_en.csv')\n",
                "ALIGNED_OUT_PATH = os.getenv('ALIGNED_PAIRS_OUT', 'aligned_pairs_candidates.csv')\n",
                "\n",
                "# Heuristic patterns for publication labels and catalog IDs\n",
                "CATALOG_PATTERNS = [\n",
                "    r\"\\bBIN\\s+[IVXLCDM]+\\s*\\d+\\b\",\n",
                "    r\"\\bKt\\.?\\s*\\d+/?[A-Za-z0-9-]*\\b\",\n",
                "    r\"\\bBM\\s*\\d+[A-Za-z]?\\b\",\n",
                "    r\"\\bYBC\\s*\\d+\\b\",\n",
                "    r\"\\b(AbB|AKT|CCT|KBo|KUB)\\s*\\d+[A-Za-z0-9-]*\\b\",\n",
                "]\n",
                "\n",
                "def extract_catalog_refs(text: str) -> list:\n",
                "    if not isinstance(text, str):\n",
                "        return []\n",
                "    text = fix_text(text)\n",
                "    text = unidecode(text)\n",
                "    refs = set()\n",
                "    for pat in CATALOG_PATTERNS:\n",
                "        for m in re.finditer(pat, text, flags=re.IGNORECASE):\n",
                "            ref = m.group(0).strip()\n",
                "            ref = re.sub(r\"\\s+\", \" \", ref)\n",
                "            refs.add(ref)\n",
                "    return list(refs)\n",
                "\n",
                "def build_alias_index(df: pd.DataFrame):\n",
                "    \"\"\"Build a search index over publication_catalog and aliases fields.\"\"\"\n",
                "    index_records = []\n",
                "    for i, row in df.iterrows():\n",
                "        rid = i\n",
                "        label = str(row.get('label', '') or '')\n",
                "        pubcat = str(row.get('publication_catalog', '') or '')\n",
                "        aliases = str(row.get('aliases', '') or '')\n",
                "        tokens = []\n",
                "        for field in (pubcat, aliases, label):\n",
                "            parts = re.split(r\"[|,;]\", field)\n",
                "            for p in parts:\n",
                "                p = unidecode(p.strip())\n",
                "                if p:\n",
                "                    tokens.append(p)\n",
                "        tokens = list(dict.fromkeys(tokens))\n",
                "        index_records.append({'rid': rid, 'tokens': tokens})\n",
                "    return index_records\n",
                "\n",
                "def find_matches(refs: list, index_records: list, score_cutoff: int = 85):\n",
                "    \"\"\"For each ref, fuzzy-match against index tokens.\"\"\"\n",
                "    candidates = set()\n",
                "    for ref in refs:\n",
                "        for rec in index_records:\n",
                "            for tok in rec['tokens']:\n",
                "                score = fuzz.token_set_ratio(ref, tok)\n",
                "                if score >= score_cutoff:\n",
                "                    candidates.add(rec['rid'])\n",
                "                    break\n",
                "    return list(candidates)\n",
                "\n",
                "def align_sentences(mined_path: str, published_path: str, out_path: str):\n",
                "    pub_df = pd.read_csv(published_path)\n",
                "    for col in ['transliteration', 'publication_catalog', 'aliases', 'label']:\n",
                "        if col not in pub_df.columns:\n",
                "            pub_df[col] = ''\n",
                "    alias_index = build_alias_index(pub_df)\n",
                "\n",
                "    Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
                "    written = 0\n",
                "    total = 0\n",
                "\n",
                "    with open(out_path, 'w', newline='', encoding='utf-8') as f_out:\n",
                "        writer = csv.writer(f_out)\n",
                "        writer.writerow(['pdf_name', 'page', 'english_sentence', 'matched_label', 'transliteration'])\n",
                "\n",
                "        for chunk in pd.read_csv(mined_path, chunksize=5000):\n",
                "            for _, row in chunk.iterrows():\n",
                "                total += 1\n",
                "                pdf = str(row.get('pdf_name', '') or '')\n",
                "                page = int(row.get('page', -1)) if pd.notna(row.get('page')) else -1\n",
                "                sent = str(row.get('english_sentence', '') or '')\n",
                "                if not sent:\n",
                "                    continue\n",
                "                refs = extract_catalog_refs(sent)\n",
                "                if not refs:\n",
                "                    continue\n",
                "                cand_ids = find_matches(refs, alias_index, score_cutoff=85)\n",
                "                for rid in cand_ids:\n",
                "                    t_row = pub_df.iloc[rid]\n",
                "                    matched_label = str(t_row.get('label', '') or '')\n",
                "                    translit = str(t_row.get('transliteration', '') or '')\n",
                "                    if translit:\n",
                "                        writer.writerow([pdf, page, sent, matched_label, translit])\n",
                "                        written += 1\n",
                "            if total % 10000 == 0:\n",
                "                print(f\"Processed {total} sentences; wrote {written} candidate pairs...\")\n",
                "\n",
                "    print(f\"Alignment complete. Total sentences: {total}, candidates written: {written}\")\n",
                "    print(f\"Saved to: {out_path}\")\n",
                "\n",
                "print(\"Starting alignment: mined_publications_en.csv → published_texts.csv\")\n",
                "align_sentences(MINED_EN_PATH, PUBLISHED_TEXTS_PATH, ALIGNED_OUT_PATH)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e0c8e3dd",
            "metadata": {},
            "source": [
                "## ✅ Quality Filter & Summary\n",
                "\n",
                "**⚠️ PREREQUISITE: Run the alignment cell above first to generate `aligned_pairs_candidates.csv`.**\n",
                "\n",
                "Filter aligned pairs for training quality:\n",
                "- Remove pairs where transliteration or English is too short/long\n",
                "- Discard pairs with extreme length ratios (likely misaligned)\n",
                "\n",
                "- Keep pairs with domain terms or high lexicon match- Output: `aligned_pairs_filtered.csv` ready for training augmentation\n",
                "- Sample results for sanity check"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "320765ef",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import os\n",
                "\n",
                "ALIGNED_PATH = os.getenv('ALIGNED_PAIRS_OUT', 'aligned_pairs_candidates.csv')\n",
                "FILTERED_OUT_PATH = os.getenv('FILTERED_PAIRS_OUT', 'aligned_pairs_filtered.csv')\n",
                "\n",
                "def filter_quality(aligned_path: str, out_path: str):\n",
                "    \"\"\"Filter aligned pairs for training quality.\"\"\"\n",
                "    df = pd.read_csv(aligned_path)\n",
                "    print(f\"Loaded {len(df)} candidate pairs\")\n",
                "    \n",
                "    # Length filters\n",
                "    df['t_len'] = df['transliteration'].str.split().str.len()\n",
                "    df['e_len'] = df['english_sentence'].str.split().str.len()\n",
                "    \n",
                "    # Apply filters\n",
                "    df_filtered = df[\n",
                "        (df['t_len'] >= 3) & (df['t_len'] <= 150) &\n",
                "        (df['e_len'] >= 3) & (df['e_len'] <= 150) &\n",
                "        (df['t_len'] / (df['e_len'] + 1) >= 0.5) &\n",
                "        (df['t_len'] / (df['e_len'] + 1) <= 3.0)\n",
                "    ].copy()\n",
                "    \n",
                "    domain_terms = ['tablet', 'seal', 'silver', 'tin', 'letter', 'text', 'archive', 'merchant', 'trade']\n",
                "    df_filtered['has_domain'] = df_filtered['english_sentence'].str.lower().str.contains('|'.join(domain_terms), na=False)\n",
                "    \n",
                "    df_filtered[['pdf_name', 'page', 'english_sentence', 'matched_label', 'transliteration']].to_csv(out_path, index=False)\n",
                "    \n",
                "    print(f\"After quality filtering: {len(df_filtered)} pairs retained\")\n",
                "    print(f\"Saved to: {out_path}\\n\")\n",
                "    \n",
                "    print(\"Sample aligned pairs (first 5):\")\n",
                "    for i, row in df_filtered.head(5).iterrows():\n",
                "        print(f\"\\n[{i}]\")\n",
                "        print(f\"  EN: {row['english_sentence'][:80]}...\")\n",
                "        print(f\"  AK: {row['transliteration'][:80]}...\")\n",
                "    \n",
                "    return len(df_filtered)\n",
                "\n",
                "count = filter_quality(ALIGNED_PATH, FILTERED_OUT_PATH)\n",
                "print(f\"\\n✓ Quality filtering complete. {count} high-quality pairs ready for training augmentation.\")"
            ]
        }
    ],
    "metadata": {
        "kaggle": {
            "accelerator": "none",
            "dataSources": [
                {
                    "databundleVersionId": 15061024,
                    "sourceId": 121150,
                    "sourceType": "competition"
                },
                {
                    "datasetId": 9082937,
                    "sourceId": 14236819,
                    "sourceType": "datasetVersion"
                }
            ],
            "dockerImageVersionId": 31234,
            "isGpuEnabled": false,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        },
        "papermill": {
            "default_parameters": {},
            "duration": 867.451795,
            "end_time": "2025-12-25T11:06:53.451666",
            "environment_variables": {},
            "exception": null,
            "input_path": "__notebook__.ipynb",
            "output_path": "__notebook__.ipynb",
            "parameters": {},
            "start_time": "2025-12-25T10:52:25.999871",
            "version": "2.6.0"
        },
        "widgets": {
            "application/vnd.jupyter.widget-state+json": {
                "state": {
                    "077ae2461fb6489b97106a1caaafb370": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "HBoxModel",
                        "state": {
                            "_dom_classes": [],
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "HBoxModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/controls",
                            "_view_module_version": "2.0.0",
                            "_view_name": "HBoxView",
                            "box_style": "",
                            "children": [
                                "IPY_MODEL_eb6470d874c040e698b88b4827bb0052",
                                "IPY_MODEL_772639f9a8104921b6f3b1caca957605",
                                "IPY_MODEL_c0e6baa9bf9a411b844486a5ac4eb0f2"
                            ],
                            "layout": "IPY_MODEL_bd2909e5aebc4611a9e453f84a7e8035",
                            "tabbable": null,
                            "tooltip": null
                        }
                    },
                    "0adb4c94b7b74e03b9969a916a78f816": {
                        "model_module": "@jupyter-widgets/base",
                        "model_module_version": "2.0.0",
                        "model_name": "LayoutModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/base",
                            "_model_module_version": "2.0.0",
                            "_model_name": "LayoutModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "LayoutView",
                            "align_content": null,
                            "align_items": null,
                            "align_self": null,
                            "border_bottom": null,
                            "border_left": null,
                            "border_right": null,
                            "border_top": null,
                            "bottom": null,
                            "display": null,
                            "flex": null,
                            "flex_flow": null,
                            "grid_area": null,
                            "grid_auto_columns": null,
                            "grid_auto_flow": null,
                            "grid_auto_rows": null,
                            "grid_column": null,
                            "grid_gap": null,
                            "grid_row": null,
                            "grid_template_areas": null,
                            "grid_template_columns": null,
                            "grid_template_rows": null,
                            "height": null,
                            "justify_content": null,
                            "justify_items": null,
                            "left": null,
                            "margin": null,
                            "max_height": null,
                            "max_width": null,
                            "min_height": null,
                            "min_width": null,
                            "object_fit": null,
                            "object_position": null,
                            "order": null,
                            "overflow": null,
                            "padding": null,
                            "right": null,
                            "top": null,
                            "visibility": null,
                            "width": null
                        }
                    },
                    "2a1fc3087f004cdcbe55deb12e9b9d55": {
                        "model_module": "@jupyter-widgets/base",
                        "model_module_version": "2.0.0",
                        "model_name": "LayoutModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/base",
                            "_model_module_version": "2.0.0",
                            "_model_name": "LayoutModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "LayoutView",
                            "align_content": null,
                            "align_items": null,
                            "align_self": null,
                            "border_bottom": null,
                            "border_left": null,
                            "border_right": null,
                            "border_top": null,
                            "bottom": null,
                            "display": null,
                            "flex": null,
                            "flex_flow": null,
                            "grid_area": null,
                            "grid_auto_columns": null,
                            "grid_auto_flow": null,
                            "grid_auto_rows": null,
                            "grid_column": null,
                            "grid_gap": null,
                            "grid_row": null,
                            "grid_template_areas": null,
                            "grid_template_columns": null,
                            "grid_template_rows": null,
                            "height": null,
                            "justify_content": null,
                            "justify_items": null,
                            "left": null,
                            "margin": null,
                            "max_height": null,
                            "max_width": null,
                            "min_height": null,
                            "min_width": null,
                            "object_fit": null,
                            "object_position": null,
                            "order": null,
                            "overflow": null,
                            "padding": null,
                            "right": null,
                            "top": null,
                            "visibility": null,
                            "width": null
                        }
                    },
                    "2adf7045efe64b7cb4c5556604eb75e9": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "HTMLStyleModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "HTMLStyleModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "StyleView",
                            "background": null,
                            "description_width": "",
                            "font_size": null,
                            "text_color": null
                        }
                    },
                    "2d2eba874f204b159a6a962c13f13b19": {
                        "model_module": "@jupyter-widgets/base",
                        "model_module_version": "2.0.0",
                        "model_name": "LayoutModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/base",
                            "_model_module_version": "2.0.0",
                            "_model_name": "LayoutModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "LayoutView",
                            "align_content": null,
                            "align_items": null,
                            "align_self": null,
                            "border_bottom": null,
                            "border_left": null,
                            "border_right": null,
                            "border_top": null,
                            "bottom": null,
                            "display": null,
                            "flex": null,
                            "flex_flow": null,
                            "grid_area": null,
                            "grid_auto_columns": null,
                            "grid_auto_flow": null,
                            "grid_auto_rows": null,
                            "grid_column": null,
                            "grid_gap": null,
                            "grid_row": null,
                            "grid_template_areas": null,
                            "grid_template_columns": null,
                            "grid_template_rows": null,
                            "height": null,
                            "justify_content": null,
                            "justify_items": null,
                            "left": null,
                            "margin": null,
                            "max_height": null,
                            "max_width": null,
                            "min_height": null,
                            "min_width": null,
                            "object_fit": null,
                            "object_position": null,
                            "order": null,
                            "overflow": null,
                            "padding": null,
                            "right": null,
                            "top": null,
                            "visibility": null,
                            "width": null
                        }
                    },
                    "2d432c967de54ce58ca8f97185c3edd5": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "FloatProgressModel",
                        "state": {
                            "_dom_classes": [],
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "FloatProgressModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/controls",
                            "_view_module_version": "2.0.0",
                            "_view_name": "ProgressView",
                            "bar_style": "success",
                            "description": "",
                            "description_allow_html": false,
                            "layout": "IPY_MODEL_907a9c57f14d46909be51efea7772bfe",
                            "max": 1452,
                            "min": 0,
                            "orientation": "horizontal",
                            "style": "IPY_MODEL_dfea59b2310d4bf7a765969e33c563e4",
                            "tabbable": null,
                            "tooltip": null,
                            "value": 1452
                        }
                    },
                    "310b3b3d8e6e4913bf9b553d7df21e92": {
                        "model_module": "@jupyter-widgets/base",
                        "model_module_version": "2.0.0",
                        "model_name": "LayoutModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/base",
                            "_model_module_version": "2.0.0",
                            "_model_name": "LayoutModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "LayoutView",
                            "align_content": null,
                            "align_items": null,
                            "align_self": null,
                            "border_bottom": null,
                            "border_left": null,
                            "border_right": null,
                            "border_top": null,
                            "bottom": null,
                            "display": null,
                            "flex": null,
                            "flex_flow": null,
                            "grid_area": null,
                            "grid_auto_columns": null,
                            "grid_auto_flow": null,
                            "grid_auto_rows": null,
                            "grid_column": null,
                            "grid_gap": null,
                            "grid_row": null,
                            "grid_template_areas": null,
                            "grid_template_columns": null,
                            "grid_template_rows": null,
                            "height": null,
                            "justify_content": null,
                            "justify_items": null,
                            "left": null,
                            "margin": null,
                            "max_height": null,
                            "max_width": null,
                            "min_height": null,
                            "min_width": null,
                            "object_fit": null,
                            "object_position": null,
                            "order": null,
                            "overflow": null,
                            "padding": null,
                            "right": null,
                            "top": null,
                            "visibility": null,
                            "width": null
                        }
                    },
                    "4948d8ef30b94d23ab5670946a3aea08": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "HTMLStyleModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "HTMLStyleModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "StyleView",
                            "background": null,
                            "description_width": "",
                            "font_size": null,
                            "text_color": null
                        }
                    },
                    "4ecbe0b10d9f4af2862caa0ea4819ad3": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "ProgressStyleModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "ProgressStyleModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "StyleView",
                            "bar_color": null,
                            "description_width": ""
                        }
                    },
                    "62b2c58f9ef642879c9120277b64490f": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "FloatProgressModel",
                        "state": {
                            "_dom_classes": [],
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "FloatProgressModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/controls",
                            "_view_module_version": "2.0.0",
                            "_view_name": "ProgressView",
                            "bar_style": "success",
                            "description": "",
                            "description_allow_html": false,
                            "layout": "IPY_MODEL_ab9961958af74ef6b85fd74f35f7ab79",
                            "max": 1,
                            "min": 0,
                            "orientation": "horizontal",
                            "style": "IPY_MODEL_a2e79e4817c1410fad2a93325460dab6",
                            "tabbable": null,
                            "tooltip": null,
                            "value": 1
                        }
                    },
                    "6bfa7186924b4ef1b09723815e8039e7": {
                        "model_module": "@jupyter-widgets/base",
                        "model_module_version": "2.0.0",
                        "model_name": "LayoutModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/base",
                            "_model_module_version": "2.0.0",
                            "_model_name": "LayoutModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "LayoutView",
                            "align_content": null,
                            "align_items": null,
                            "align_self": null,
                            "border_bottom": null,
                            "border_left": null,
                            "border_right": null,
                            "border_top": null,
                            "bottom": null,
                            "display": null,
                            "flex": null,
                            "flex_flow": null,
                            "grid_area": null,
                            "grid_auto_columns": null,
                            "grid_auto_flow": null,
                            "grid_auto_rows": null,
                            "grid_column": null,
                            "grid_gap": null,
                            "grid_row": null,
                            "grid_template_areas": null,
                            "grid_template_columns": null,
                            "grid_template_rows": null,
                            "height": null,
                            "justify_content": null,
                            "justify_items": null,
                            "left": null,
                            "margin": null,
                            "max_height": null,
                            "max_width": null,
                            "min_height": null,
                            "min_width": null,
                            "object_fit": null,
                            "object_position": null,
                            "order": null,
                            "overflow": null,
                            "padding": null,
                            "right": null,
                            "top": null,
                            "visibility": null,
                            "width": null
                        }
                    },
                    "6e0dd8d999ad42c98136d00236800e95": {
                        "model_module": "@jupyter-widgets/base",
                        "model_module_version": "2.0.0",
                        "model_name": "LayoutModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/base",
                            "_model_module_version": "2.0.0",
                            "_model_name": "LayoutModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "LayoutView",
                            "align_content": null,
                            "align_items": null,
                            "align_self": null,
                            "border_bottom": null,
                            "border_left": null,
                            "border_right": null,
                            "border_top": null,
                            "bottom": null,
                            "display": null,
                            "flex": null,
                            "flex_flow": null,
                            "grid_area": null,
                            "grid_auto_columns": null,
                            "grid_auto_flow": null,
                            "grid_auto_rows": null,
                            "grid_column": null,
                            "grid_gap": null,
                            "grid_row": null,
                            "grid_template_areas": null,
                            "grid_template_columns": null,
                            "grid_template_rows": null,
                            "height": null,
                            "justify_content": null,
                            "justify_items": null,
                            "left": null,
                            "margin": null,
                            "max_height": null,
                            "max_width": null,
                            "min_height": null,
                            "min_width": null,
                            "object_fit": null,
                            "object_position": null,
                            "order": null,
                            "overflow": null,
                            "padding": null,
                            "right": null,
                            "top": null,
                            "visibility": null,
                            "width": null
                        }
                    },
                    "6e3c59e812f44e02bbde7360657be1e9": {
                        "model_module": "@jupyter-widgets/base",
                        "model_module_version": "2.0.0",
                        "model_name": "LayoutModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/base",
                            "_model_module_version": "2.0.0",
                            "_model_name": "LayoutModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "LayoutView",
                            "align_content": null,
                            "align_items": null,
                            "align_self": null,
                            "border_bottom": null,
                            "border_left": null,
                            "border_right": null,
                            "border_top": null,
                            "bottom": null,
                            "display": null,
                            "flex": null,
                            "flex_flow": null,
                            "grid_area": null,
                            "grid_auto_columns": null,
                            "grid_auto_flow": null,
                            "grid_auto_rows": null,
                            "grid_column": null,
                            "grid_gap": null,
                            "grid_row": null,
                            "grid_template_areas": null,
                            "grid_template_columns": null,
                            "grid_template_rows": null,
                            "height": null,
                            "justify_content": null,
                            "justify_items": null,
                            "left": null,
                            "margin": null,
                            "max_height": null,
                            "max_width": null,
                            "min_height": null,
                            "min_width": null,
                            "object_fit": null,
                            "object_position": null,
                            "order": null,
                            "overflow": null,
                            "padding": null,
                            "right": null,
                            "top": null,
                            "visibility": null,
                            "width": null
                        }
                    },
                    "7212b9bcee854738bc028dc516c6d9e0": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "HTMLModel",
                        "state": {
                            "_dom_classes": [],
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "HTMLModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/controls",
                            "_view_module_version": "2.0.0",
                            "_view_name": "HTMLView",
                            "description": "",
                            "description_allow_html": false,
                            "layout": "IPY_MODEL_6bfa7186924b4ef1b09723815e8039e7",
                            "placeholder": "​",
                            "style": "IPY_MODEL_9c4f0d0224314af5a5348f524290228d",
                            "tabbable": null,
                            "tooltip": null,
                            "value": "Downloading builder script: "
                        }
                    },
                    "757491e8dcfb4e53bbde385ec37d11c7": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "ProgressStyleModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "ProgressStyleModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "StyleView",
                            "bar_color": null,
                            "description_width": ""
                        }
                    },
                    "76050bf59c0b404eb86de944a9d2f440": {
                        "model_module": "@jupyter-widgets/base",
                        "model_module_version": "2.0.0",
                        "model_name": "LayoutModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/base",
                            "_model_module_version": "2.0.0",
                            "_model_name": "LayoutModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "LayoutView",
                            "align_content": null,
                            "align_items": null,
                            "align_self": null,
                            "border_bottom": null,
                            "border_left": null,
                            "border_right": null,
                            "border_top": null,
                            "bottom": null,
                            "display": null,
                            "flex": null,
                            "flex_flow": null,
                            "grid_area": null,
                            "grid_auto_columns": null,
                            "grid_auto_flow": null,
                            "grid_auto_rows": null,
                            "grid_column": null,
                            "grid_gap": null,
                            "grid_row": null,
                            "grid_template_areas": null,
                            "grid_template_columns": null,
                            "grid_template_rows": null,
                            "height": null,
                            "justify_content": null,
                            "justify_items": null,
                            "left": null,
                            "margin": null,
                            "max_height": null,
                            "max_width": null,
                            "min_height": null,
                            "min_width": null,
                            "object_fit": null,
                            "object_position": null,
                            "order": null,
                            "overflow": null,
                            "padding": null,
                            "right": null,
                            "top": null,
                            "visibility": null,
                            "width": null
                        }
                    },
                    "772639f9a8104921b6f3b1caca957605": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "FloatProgressModel",
                        "state": {
                            "_dom_classes": [],
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "FloatProgressModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/controls",
                            "_view_module_version": "2.0.0",
                            "_view_name": "ProgressView",
                            "bar_style": "success",
                            "description": "",
                            "description_allow_html": false,
                            "layout": "IPY_MODEL_cbcf3f903c0142bb919b4c6c873027b8",
                            "max": 1,
                            "min": 0,
                            "orientation": "horizontal",
                            "style": "IPY_MODEL_4ecbe0b10d9f4af2862caa0ea4819ad3",
                            "tabbable": null,
                            "tooltip": null,
                            "value": 1
                        }
                    },
                    "8ae65202365844b3823b46cc09af0d8b": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "HBoxModel",
                        "state": {
                            "_dom_classes": [],
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "HBoxModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/controls",
                            "_view_module_version": "2.0.0",
                            "_view_name": "HBoxView",
                            "box_style": "",
                            "children": [
                                "IPY_MODEL_7212b9bcee854738bc028dc516c6d9e0",
                                "IPY_MODEL_62b2c58f9ef642879c9120277b64490f",
                                "IPY_MODEL_d254aa49e2c748839b11c3ae30b3ed4b"
                            ],
                            "layout": "IPY_MODEL_0adb4c94b7b74e03b9969a916a78f816",
                            "tabbable": null,
                            "tooltip": null
                        }
                    },
                    "907a9c57f14d46909be51efea7772bfe": {
                        "model_module": "@jupyter-widgets/base",
                        "model_module_version": "2.0.0",
                        "model_name": "LayoutModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/base",
                            "_model_module_version": "2.0.0",
                            "_model_name": "LayoutModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "LayoutView",
                            "align_content": null,
                            "align_items": null,
                            "align_self": null,
                            "border_bottom": null,
                            "border_left": null,
                            "border_right": null,
                            "border_top": null,
                            "bottom": null,
                            "display": null,
                            "flex": null,
                            "flex_flow": null,
                            "grid_area": null,
                            "grid_auto_columns": null,
                            "grid_auto_flow": null,
                            "grid_auto_rows": null,
                            "grid_column": null,
                            "grid_gap": null,
                            "grid_row": null,
                            "grid_template_areas": null,
                            "grid_template_columns": null,
                            "grid_template_rows": null,
                            "height": null,
                            "justify_content": null,
                            "justify_items": null,
                            "left": null,
                            "margin": null,
                            "max_height": null,
                            "max_width": null,
                            "min_height": null,
                            "min_width": null,
                            "object_fit": null,
                            "object_position": null,
                            "order": null,
                            "overflow": null,
                            "padding": null,
                            "right": null,
                            "top": null,
                            "visibility": null,
                            "width": null
                        }
                    },
                    "939f39d353254f2188c3154b27045a38": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "HTMLModel",
                        "state": {
                            "_dom_classes": [],
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "HTMLModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/controls",
                            "_view_module_version": "2.0.0",
                            "_view_name": "HTMLView",
                            "description": "",
                            "description_allow_html": false,
                            "layout": "IPY_MODEL_6e0dd8d999ad42c98136d00236800e95",
                            "placeholder": "​",
                            "style": "IPY_MODEL_4948d8ef30b94d23ab5670946a3aea08",
                            "tabbable": null,
                            "tooltip": null,
                            "value": " 1452/1452 [00:02&lt;00:00, 685.40 examples/s]"
                        }
                    },
                    "9c4f0d0224314af5a5348f524290228d": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "HTMLStyleModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "HTMLStyleModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "StyleView",
                            "background": null,
                            "description_width": "",
                            "font_size": null,
                            "text_color": null
                        }
                    },
                    "a12b2c8b8d9045ad9880827234dd0592": {
                        "model_module": "@jupyter-widgets/base",
                        "model_module_version": "2.0.0",
                        "model_name": "LayoutModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/base",
                            "_model_module_version": "2.0.0",
                            "_model_name": "LayoutModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "LayoutView",
                            "align_content": null,
                            "align_items": null,
                            "align_self": null,
                            "border_bottom": null,
                            "border_left": null,
                            "border_right": null,
                            "border_top": null,
                            "bottom": null,
                            "display": null,
                            "flex": null,
                            "flex_flow": null,
                            "grid_area": null,
                            "grid_auto_columns": null,
                            "grid_auto_flow": null,
                            "grid_auto_rows": null,
                            "grid_column": null,
                            "grid_gap": null,
                            "grid_row": null,
                            "grid_template_areas": null,
                            "grid_template_columns": null,
                            "grid_template_rows": null,
                            "height": null,
                            "justify_content": null,
                            "justify_items": null,
                            "left": null,
                            "margin": null,
                            "max_height": null,
                            "max_width": null,
                            "min_height": null,
                            "min_width": null,
                            "object_fit": null,
                            "object_position": null,
                            "order": null,
                            "overflow": null,
                            "padding": null,
                            "right": null,
                            "top": null,
                            "visibility": null,
                            "width": null
                        }
                    },
                    "a151a03ca0304312ade7c4c2a3fca88b": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "HTMLStyleModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "HTMLStyleModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "StyleView",
                            "background": null,
                            "description_width": "",
                            "font_size": null,
                            "text_color": null
                        }
                    },
                    "a2e79e4817c1410fad2a93325460dab6": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "ProgressStyleModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "ProgressStyleModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "StyleView",
                            "bar_color": null,
                            "description_width": ""
                        }
                    },
                    "ab9961958af74ef6b85fd74f35f7ab79": {
                        "model_module": "@jupyter-widgets/base",
                        "model_module_version": "2.0.0",
                        "model_name": "LayoutModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/base",
                            "_model_module_version": "2.0.0",
                            "_model_name": "LayoutModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "LayoutView",
                            "align_content": null,
                            "align_items": null,
                            "align_self": null,
                            "border_bottom": null,
                            "border_left": null,
                            "border_right": null,
                            "border_top": null,
                            "bottom": null,
                            "display": null,
                            "flex": null,
                            "flex_flow": null,
                            "grid_area": null,
                            "grid_auto_columns": null,
                            "grid_auto_flow": null,
                            "grid_auto_rows": null,
                            "grid_column": null,
                            "grid_gap": null,
                            "grid_row": null,
                            "grid_template_areas": null,
                            "grid_template_columns": null,
                            "grid_template_rows": null,
                            "height": null,
                            "justify_content": null,
                            "justify_items": null,
                            "left": null,
                            "margin": null,
                            "max_height": null,
                            "max_width": null,
                            "min_height": null,
                            "min_width": null,
                            "object_fit": null,
                            "object_position": null,
                            "order": null,
                            "overflow": null,
                            "padding": null,
                            "right": null,
                            "top": null,
                            "visibility": null,
                            "width": "20px"
                        }
                    },
                    "ac4c4df806d943919a176f5abba4439e": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "HTMLModel",
                        "state": {
                            "_dom_classes": [],
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "HTMLModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/controls",
                            "_view_module_version": "2.0.0",
                            "_view_name": "HTMLView",
                            "description": "",
                            "description_allow_html": false,
                            "layout": "IPY_MODEL_2d2eba874f204b159a6a962c13f13b19",
                            "placeholder": "​",
                            "style": "IPY_MODEL_ea4d9cb6237b410fa26d0ef017695535",
                            "tabbable": null,
                            "tooltip": null,
                            "value": "Map: 100%"
                        }
                    },
                    "b584c545f2a04b22a8684541f3716bb8": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "HBoxModel",
                        "state": {
                            "_dom_classes": [],
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "HBoxModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/controls",
                            "_view_module_version": "2.0.0",
                            "_view_name": "HBoxView",
                            "box_style": "",
                            "children": [
                                "IPY_MODEL_f29b32d0d9ff4816ae71db8424c042ee",
                                "IPY_MODEL_2d432c967de54ce58ca8f97185c3edd5",
                                "IPY_MODEL_939f39d353254f2188c3154b27045a38"
                            ],
                            "layout": "IPY_MODEL_ed16ef8fdffb4b9b8536b8c6e9d727bf",
                            "tabbable": null,
                            "tooltip": null
                        }
                    },
                    "b999aa2ad3044b9cb4a67d342fc9aabc": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "HBoxModel",
                        "state": {
                            "_dom_classes": [],
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "HBoxModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/controls",
                            "_view_module_version": "2.0.0",
                            "_view_name": "HBoxView",
                            "box_style": "",
                            "children": [
                                "IPY_MODEL_ac4c4df806d943919a176f5abba4439e",
                                "IPY_MODEL_d6dab87b9b4b4b0fa1f6ca17928ae214",
                                "IPY_MODEL_f4856502a22146fb8fde2d23cb451348"
                            ],
                            "layout": "IPY_MODEL_6e3c59e812f44e02bbde7360657be1e9",
                            "tabbable": null,
                            "tooltip": null
                        }
                    },
                    "bd2909e5aebc4611a9e453f84a7e8035": {
                        "model_module": "@jupyter-widgets/base",
                        "model_module_version": "2.0.0",
                        "model_name": "LayoutModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/base",
                            "_model_module_version": "2.0.0",
                            "_model_name": "LayoutModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "LayoutView",
                            "align_content": null,
                            "align_items": null,
                            "align_self": null,
                            "border_bottom": null,
                            "border_left": null,
                            "border_right": null,
                            "border_top": null,
                            "bottom": null,
                            "display": null,
                            "flex": null,
                            "flex_flow": null,
                            "grid_area": null,
                            "grid_auto_columns": null,
                            "grid_auto_flow": null,
                            "grid_auto_rows": null,
                            "grid_column": null,
                            "grid_gap": null,
                            "grid_row": null,
                            "grid_template_areas": null,
                            "grid_template_columns": null,
                            "grid_template_rows": null,
                            "height": null,
                            "justify_content": null,
                            "justify_items": null,
                            "left": null,
                            "margin": null,
                            "max_height": null,
                            "max_width": null,
                            "min_height": null,
                            "min_width": null,
                            "object_fit": null,
                            "object_position": null,
                            "order": null,
                            "overflow": null,
                            "padding": null,
                            "right": null,
                            "top": null,
                            "visibility": null,
                            "width": null
                        }
                    },
                    "c0e6baa9bf9a411b844486a5ac4eb0f2": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "HTMLModel",
                        "state": {
                            "_dom_classes": [],
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "HTMLModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/controls",
                            "_view_module_version": "2.0.0",
                            "_view_name": "HTMLView",
                            "description": "",
                            "description_allow_html": false,
                            "layout": "IPY_MODEL_310b3b3d8e6e4913bf9b553d7df21e92",
                            "placeholder": "​",
                            "style": "IPY_MODEL_d3822816c9214e8296dbc9d8f6a53130",
                            "tabbable": null,
                            "tooltip": null,
                            "value": " 9.01k/? [00:00&lt;00:00, 925kB/s]"
                        }
                    },
                    "ca6c0b7ac45e453daf901dbe2533d931": {
                        "model_module": "@jupyter-widgets/base",
                        "model_module_version": "2.0.0",
                        "model_name": "LayoutModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/base",
                            "_model_module_version": "2.0.0",
                            "_model_name": "LayoutModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "LayoutView",
                            "align_content": null,
                            "align_items": null,
                            "align_self": null,
                            "border_bottom": null,
                            "border_left": null,
                            "border_right": null,
                            "border_top": null,
                            "bottom": null,
                            "display": null,
                            "flex": null,
                            "flex_flow": null,
                            "grid_area": null,
                            "grid_auto_columns": null,
                            "grid_auto_flow": null,
                            "grid_auto_rows": null,
                            "grid_column": null,
                            "grid_gap": null,
                            "grid_row": null,
                            "grid_template_areas": null,
                            "grid_template_columns": null,
                            "grid_template_rows": null,
                            "height": null,
                            "justify_content": null,
                            "justify_items": null,
                            "left": null,
                            "margin": null,
                            "max_height": null,
                            "max_width": null,
                            "min_height": null,
                            "min_width": null,
                            "object_fit": null,
                            "object_position": null,
                            "order": null,
                            "overflow": null,
                            "padding": null,
                            "right": null,
                            "top": null,
                            "visibility": null,
                            "width": null
                        }
                    },
                    "cbcf3f903c0142bb919b4c6c873027b8": {
                        "model_module": "@jupyter-widgets/base",
                        "model_module_version": "2.0.0",
                        "model_name": "LayoutModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/base",
                            "_model_module_version": "2.0.0",
                            "_model_name": "LayoutModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "LayoutView",
                            "align_content": null,
                            "align_items": null,
                            "align_self": null,
                            "border_bottom": null,
                            "border_left": null,
                            "border_right": null,
                            "border_top": null,
                            "bottom": null,
                            "display": null,
                            "flex": null,
                            "flex_flow": null,
                            "grid_area": null,
                            "grid_auto_columns": null,
                            "grid_auto_flow": null,
                            "grid_auto_rows": null,
                            "grid_column": null,
                            "grid_gap": null,
                            "grid_row": null,
                            "grid_template_areas": null,
                            "grid_template_columns": null,
                            "grid_template_rows": null,
                            "height": null,
                            "justify_content": null,
                            "justify_items": null,
                            "left": null,
                            "margin": null,
                            "max_height": null,
                            "max_width": null,
                            "min_height": null,
                            "min_width": null,
                            "object_fit": null,
                            "object_position": null,
                            "order": null,
                            "overflow": null,
                            "padding": null,
                            "right": null,
                            "top": null,
                            "visibility": null,
                            "width": "20px"
                        }
                    },
                    "d254aa49e2c748839b11c3ae30b3ed4b": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "HTMLModel",
                        "state": {
                            "_dom_classes": [],
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "HTMLModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/controls",
                            "_view_module_version": "2.0.0",
                            "_view_name": "HTMLView",
                            "description": "",
                            "description_allow_html": false,
                            "layout": "IPY_MODEL_a12b2c8b8d9045ad9880827234dd0592",
                            "placeholder": "​",
                            "style": "IPY_MODEL_2adf7045efe64b7cb4c5556604eb75e9",
                            "tabbable": null,
                            "tooltip": null,
                            "value": " 8.15k/? [00:00&lt;00:00, 832kB/s]"
                        }
                    },
                    "d29e22650257471d8935422c67a4c6b3": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "HTMLStyleModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "HTMLStyleModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "StyleView",
                            "background": null,
                            "description_width": "",
                            "font_size": null,
                            "text_color": null
                        }
                    },
                    "d3822816c9214e8296dbc9d8f6a53130": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "HTMLStyleModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "HTMLStyleModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "StyleView",
                            "background": null,
                            "description_width": "",
                            "font_size": null,
                            "text_color": null
                        }
                    },
                    "d6dab87b9b4b4b0fa1f6ca17928ae214": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "FloatProgressModel",
                        "state": {
                            "_dom_classes": [],
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "FloatProgressModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/controls",
                            "_view_module_version": "2.0.0",
                            "_view_name": "ProgressView",
                            "bar_style": "success",
                            "description": "",
                            "description_allow_html": false,
                            "layout": "IPY_MODEL_2a1fc3087f004cdcbe55deb12e9b9d55",
                            "max": 77,
                            "min": 0,
                            "orientation": "horizontal",
                            "style": "IPY_MODEL_757491e8dcfb4e53bbde385ec37d11c7",
                            "tabbable": null,
                            "tooltip": null,
                            "value": 77
                        }
                    },
                    "da9bc0ca3f1e42268d44dd4984814919": {
                        "model_module": "@jupyter-widgets/base",
                        "model_module_version": "2.0.0",
                        "model_name": "LayoutModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/base",
                            "_model_module_version": "2.0.0",
                            "_model_name": "LayoutModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "LayoutView",
                            "align_content": null,
                            "align_items": null,
                            "align_self": null,
                            "border_bottom": null,
                            "border_left": null,
                            "border_right": null,
                            "border_top": null,
                            "bottom": null,
                            "display": null,
                            "flex": null,
                            "flex_flow": null,
                            "grid_area": null,
                            "grid_auto_columns": null,
                            "grid_auto_flow": null,
                            "grid_auto_rows": null,
                            "grid_column": null,
                            "grid_gap": null,
                            "grid_row": null,
                            "grid_template_areas": null,
                            "grid_template_columns": null,
                            "grid_template_rows": null,
                            "height": null,
                            "justify_content": null,
                            "justify_items": null,
                            "left": null,
                            "margin": null,
                            "max_height": null,
                            "max_width": null,
                            "min_height": null,
                            "min_width": null,
                            "object_fit": null,
                            "object_position": null,
                            "order": null,
                            "overflow": null,
                            "padding": null,
                            "right": null,
                            "top": null,
                            "visibility": null,
                            "width": null
                        }
                    },
                    "dfea59b2310d4bf7a765969e33c563e4": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "ProgressStyleModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "ProgressStyleModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "StyleView",
                            "bar_color": null,
                            "description_width": ""
                        }
                    },
                    "ea4d9cb6237b410fa26d0ef017695535": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "HTMLStyleModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "HTMLStyleModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "StyleView",
                            "background": null,
                            "description_width": "",
                            "font_size": null,
                            "text_color": null
                        }
                    },
                    "eb6470d874c040e698b88b4827bb0052": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "HTMLModel",
                        "state": {
                            "_dom_classes": [],
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "HTMLModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/controls",
                            "_view_module_version": "2.0.0",
                            "_view_name": "HTMLView",
                            "description": "",
                            "description_allow_html": false,
                            "layout": "IPY_MODEL_ca6c0b7ac45e453daf901dbe2533d931",
                            "placeholder": "​",
                            "style": "IPY_MODEL_f1f41397162d4f36aba6f0441042960e",
                            "tabbable": null,
                            "tooltip": null,
                            "value": "Downloading builder script: "
                        }
                    },
                    "ed16ef8fdffb4b9b8536b8c6e9d727bf": {
                        "model_module": "@jupyter-widgets/base",
                        "model_module_version": "2.0.0",
                        "model_name": "LayoutModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/base",
                            "_model_module_version": "2.0.0",
                            "_model_name": "LayoutModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "LayoutView",
                            "align_content": null,
                            "align_items": null,
                            "align_self": null,
                            "border_bottom": null,
                            "border_left": null,
                            "border_right": null,
                            "border_top": null,
                            "bottom": null,
                            "display": null,
                            "flex": null,
                            "flex_flow": null,
                            "grid_area": null,
                            "grid_auto_columns": null,
                            "grid_auto_flow": null,
                            "grid_auto_rows": null,
                            "grid_column": null,
                            "grid_gap": null,
                            "grid_row": null,
                            "grid_template_areas": null,
                            "grid_template_columns": null,
                            "grid_template_rows": null,
                            "height": null,
                            "justify_content": null,
                            "justify_items": null,
                            "left": null,
                            "margin": null,
                            "max_height": null,
                            "max_width": null,
                            "min_height": null,
                            "min_width": null,
                            "object_fit": null,
                            "object_position": null,
                            "order": null,
                            "overflow": null,
                            "padding": null,
                            "right": null,
                            "top": null,
                            "visibility": null,
                            "width": null
                        }
                    },
                    "f1f41397162d4f36aba6f0441042960e": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "HTMLStyleModel",
                        "state": {
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "HTMLStyleModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/base",
                            "_view_module_version": "2.0.0",
                            "_view_name": "StyleView",
                            "background": null,
                            "description_width": "",
                            "font_size": null,
                            "text_color": null
                        }
                    },
                    "f29b32d0d9ff4816ae71db8424c042ee": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "HTMLModel",
                        "state": {
                            "_dom_classes": [],
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "HTMLModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/controls",
                            "_view_module_version": "2.0.0",
                            "_view_name": "HTMLView",
                            "description": "",
                            "description_allow_html": false,
                            "layout": "IPY_MODEL_76050bf59c0b404eb86de944a9d2f440",
                            "placeholder": "​",
                            "style": "IPY_MODEL_d29e22650257471d8935422c67a4c6b3",
                            "tabbable": null,
                            "tooltip": null,
                            "value": "Map: 100%"
                        }
                    },
                    "f4856502a22146fb8fde2d23cb451348": {
                        "model_module": "@jupyter-widgets/controls",
                        "model_module_version": "2.0.0",
                        "model_name": "HTMLModel",
                        "state": {
                            "_dom_classes": [],
                            "_model_module": "@jupyter-widgets/controls",
                            "_model_module_version": "2.0.0",
                            "_model_name": "HTMLModel",
                            "_view_count": null,
                            "_view_module": "@jupyter-widgets/controls",
                            "_view_module_version": "2.0.0",
                            "_view_name": "HTMLView",
                            "description": "",
                            "description_allow_html": false,
                            "layout": "IPY_MODEL_da9bc0ca3f1e42268d44dd4984814919",
                            "placeholder": "​",
                            "style": "IPY_MODEL_a151a03ca0304312ade7c4c2a3fca88b",
                            "tabbable": null,
                            "tooltip": null,
                            "value": " 77/77 [00:00&lt;00:00, 599.94 examples/s]"
                        }
                    }
                },
                "version_major": 2,
                "version_minor": 0
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
