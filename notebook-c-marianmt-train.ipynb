{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":121150,"databundleVersionId":15061024,"sourceType":"competition"},{"sourceId":14236819,"sourceType":"datasetVersion","datasetId":9082937}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":650.176672,"end_time":"2025-12-25T11:19:18.784764","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-12-25T11:08:28.608092","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"006e704aa6c944859bb0012667971140":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"0da07a92ee1145c6ba75f73034a80896":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_0f40ba21fc344bfeb6fc29b276337ca9","placeholder":"​","style":"IPY_MODEL_782121dc5bf5409787b423d190a97a2a","tabbable":null,"tooltip":null,"value":"Map: 100%"}},"0f40ba21fc344bfeb6fc29b276337ca9":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a7c757198d04482967f172c44c07168":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d1e2d02d3994b8197c937fe0cd36768":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e6586f643174c608f4af4c3fa7cc77b":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e9adeda3aad4a82b53cc784c141c0cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_e127272439614b07988bebdd9358f449","placeholder":"​","style":"IPY_MODEL_a649a617000146cc901c681c0d541f1c","tabbable":null,"tooltip":null,"value":" 8.15k/? [00:00&lt;00:00, 851kB/s]"}},"1f09169e8dde4a9db3cf0afe7543792b":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23f123af2ed94e98ba76c3a0886fe02b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb984c93171c4674b03816e7b09e0147","IPY_MODEL_c78541bb1cc042689e463e891c1676f9","IPY_MODEL_37ad3d25de25423aa68dd0c2f185de10"],"layout":"IPY_MODEL_1a7c757198d04482967f172c44c07168","tabbable":null,"tooltip":null}},"276b62defb65456b92ddf9b0470f142e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28a277a8fb104456a74d691689c840b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_7359401f7fa644938932f706306c8ab3","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a4867292379424b83eca085157110c6","tabbable":null,"tooltip":null,"value":1}},"2b2198dbdcb74158b34bf460b63dd7cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"37ad3d25de25423aa68dd0c2f185de10":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_e5f6bd19bbb34b569bb667df055db4ae","placeholder":"​","style":"IPY_MODEL_006e704aa6c944859bb0012667971140","tabbable":null,"tooltip":null,"value":" 1452/1452 [00:03&lt;00:00, 476.19 examples/s]"}},"467e02d583c54e7fb140d85cf10d28a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_66a1a97c09324c50964b24bd04a2fc5c","IPY_MODEL_28a277a8fb104456a74d691689c840b8","IPY_MODEL_1e9adeda3aad4a82b53cc784c141c0cb"],"layout":"IPY_MODEL_865eb4fb87fe413db56a281d5e7bdc70","tabbable":null,"tooltip":null}},"4dc297123ac24df1b75b584d9c7f701a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52f062255cd941e3bb5d9b9e9616c805":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_bd7545197a1349deaa902dfd002c54cb","placeholder":"​","style":"IPY_MODEL_940b13d03342464b968e822ed411db2c","tabbable":null,"tooltip":null,"value":" 9.01k/? [00:00&lt;00:00, 1.02MB/s]"}},"54ac63530acd4a7ea511996d18038415":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_c9b8c2b47124449b80f89fc38d88cc18","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b71c04220ae84ed398f80345103403af","tabbable":null,"tooltip":null,"value":1}},"63f470b1c69a4b659c397a9131a1787e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66a1a97c09324c50964b24bd04a2fc5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_e3ff9f8522974d489a6602947050b1f5","placeholder":"​","style":"IPY_MODEL_83b4199739ff4dbfa7fd6045b6592888","tabbable":null,"tooltip":null,"value":"Downloading builder script: "}},"6a4867292379424b83eca085157110c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7359401f7fa644938932f706306c8ab3":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"782121dc5bf5409787b423d190a97a2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"83b4199739ff4dbfa7fd6045b6592888":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"865eb4fb87fe413db56a281d5e7bdc70":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"940b13d03342464b968e822ed411db2c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"96980b824d484b4bb658d91f3181f000":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0da07a92ee1145c6ba75f73034a80896","IPY_MODEL_fc47b1bb981d45e0b731240619bbe710","IPY_MODEL_b8f18ea2ddb64b4c8db2e1e4f2fa45b4"],"layout":"IPY_MODEL_1d1e2d02d3994b8197c937fe0cd36768","tabbable":null,"tooltip":null}},"a649a617000146cc901c681c0d541f1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"b71c04220ae84ed398f80345103403af":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b81ee50a854d42cbb085b2d6ed88f651":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dece704073e744fcb2777ac3e8d7a2f9","IPY_MODEL_54ac63530acd4a7ea511996d18038415","IPY_MODEL_52f062255cd941e3bb5d9b9e9616c805"],"layout":"IPY_MODEL_4dc297123ac24df1b75b584d9c7f701a","tabbable":null,"tooltip":null}},"b8f18ea2ddb64b4c8db2e1e4f2fa45b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_1e6586f643174c608f4af4c3fa7cc77b","placeholder":"​","style":"IPY_MODEL_2b2198dbdcb74158b34bf460b63dd7cb","tabbable":null,"tooltip":null,"value":" 77/77 [00:00&lt;00:00, 461.19 examples/s]"}},"bb984c93171c4674b03816e7b09e0147":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_be798dbd13b14c2fb91107dfb5f8d54f","placeholder":"​","style":"IPY_MODEL_fde531abd1984d699ff0f100cd4e39ec","tabbable":null,"tooltip":null,"value":"Map: 100%"}},"bd7545197a1349deaa902dfd002c54cb":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be798dbd13b14c2fb91107dfb5f8d54f":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c78541bb1cc042689e463e891c1676f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_63f470b1c69a4b659c397a9131a1787e","max":1452,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e489c3a4e6184a24b04e1fb646771f00","tabbable":null,"tooltip":null,"value":1452}},"c9b8c2b47124449b80f89fc38d88cc18":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"d0db33fadcf1494b976a13cb382b0610":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"da06d7bfd43b40f5af5ad66daef05398":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dece704073e744fcb2777ac3e8d7a2f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_1f09169e8dde4a9db3cf0afe7543792b","placeholder":"​","style":"IPY_MODEL_d0db33fadcf1494b976a13cb382b0610","tabbable":null,"tooltip":null,"value":"Downloading builder script: "}},"e127272439614b07988bebdd9358f449":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3ff9f8522974d489a6602947050b1f5":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e489c3a4e6184a24b04e1fb646771f00":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5f6bd19bbb34b569bb667df055db4ae":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc47b1bb981d45e0b731240619bbe710":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_276b62defb65456b92ddf9b0470f142e","max":77,"min":0,"orientation":"horizontal","style":"IPY_MODEL_da06d7bfd43b40f5af5ad66daef05398","tabbable":null,"tooltip":null,"value":77}},"fde531abd1984d699ff0f100cd4e39ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"43512d74","cell_type":"markdown","source":"# C1. Imports & Configuration","metadata":{"papermill":{"duration":0.006753,"end_time":"2025-12-25T11:08:30.972947","exception":false,"start_time":"2025-12-25T11:08:30.966194","status":"completed"},"tags":[]}},{"id":"501361d2","cell_type":"code","source":"!pip install -q sacremoses","metadata":{"execution":{"iopub.status.busy":"2026-01-08T11:14:09.273663Z","iopub.execute_input":"2026-01-08T11:14:09.273975Z","iopub.status.idle":"2026-01-08T11:14:15.650297Z","shell.execute_reply.started":"2026-01-08T11:14:09.273949Z","shell.execute_reply":"2026-01-08T11:14:15.649246Z"},"papermill":{"duration":4.247404,"end_time":"2025-12-25T11:08:35.226225","exception":false,"start_time":"2025-12-25T11:08:30.978821","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"id":"0d3dbc9f","cell_type":"code","source":"!pip install -q evaluate sacrebleu","metadata":{"execution":{"iopub.status.busy":"2026-01-08T11:14:15.652491Z","iopub.execute_input":"2026-01-08T11:14:15.652780Z","iopub.status.idle":"2026-01-08T11:14:20.127239Z","shell.execute_reply.started":"2026-01-08T11:14:15.652752Z","shell.execute_reply":"2026-01-08T11:14:20.126514Z"},"papermill":{"duration":3.868853,"end_time":"2025-12-25T11:08:39.101210","exception":false,"start_time":"2025-12-25T11:08:35.232357","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"id":"bf97b0a1","cell_type":"code","source":"import os\nimport re\nimport gc\nimport pandas as pd\nimport torch\nimport evaluate\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer, \n    AutoModelForSeq2SeqLM, \n    DataCollatorForSeq2Seq, \n    Seq2SeqTrainer, \n    Seq2SeqTrainingArguments,\n    set_seed,\n)\n\n# Memory safety tweaks\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\ntry:\n    torch.backends.cuda.matmul.allow_tf32 = True\n    torch.backends.cudnn.benchmark = False\n    torch.set_float32_matmul_precision(\"medium\")\nexcept Exception:\n    pass\n\n# --- Configuration ---\nMODEL_PATH = \"/kaggle/input/models-for-dpc/pretrained_models/opus-mt-mul-en\"\nDATA_DIR = \"/kaggle/input/deep-past-initiative-machine-translation\"\nOUTPUT_DIR = \"/kaggle/working/marian-mt-saved\"\n\nMAX_LENGTH = 160 \nPREFIX = \">>eng<< \"  # CRITICAL: MarianMT requires target language prefix\n\nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2026-01-08T11:14:20.128466Z","iopub.execute_input":"2026-01-08T11:14:20.128755Z","iopub.status.idle":"2026-01-08T11:15:06.676169Z","shell.execute_reply.started":"2026-01-08T11:14:20.128716Z","shell.execute_reply":"2026-01-08T11:15:06.675534Z"},"papermill":{"duration":30.839785,"end_time":"2025-12-25T11:09:09.947308","exception":false,"start_time":"2025-12-25T11:08:39.107523","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"2026-01-08 11:14:41.317325: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767870881.746312      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767870881.898369      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767870882.934256      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767870882.934298      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767870882.934301      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767870882.934304      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":3},{"id":"6d54d7d3","cell_type":"markdown","source":"# C2.Data Loading & Alignment","metadata":{"papermill":{"duration":0.005995,"end_time":"2025-12-25T11:09:09.959629","exception":false,"start_time":"2025-12-25T11:09:09.953634","status":"completed"},"tags":[]}},{"id":"13cc0bf5","cell_type":"code","source":"SUBSCRIPT_TRANS = str.maketrans({\"₀\": \"0\", \"₁\": \"1\", \"₂\": \"2\", \"₃\": \"3\", \"₄\": \"4\", \"₅\": \"5\", \"₆\": \"6\", \"₇\": \"7\", \"₈\": \"8\", \"₉\": \"9\", \"ₓ\": \"x\"})\n\n\ndef normalize_subscripts(text: str) -> str:\n\n    return text.translate(SUBSCRIPT_TRANS)\n\n\n\ndef replace_gaps(text):\n\n    \"\"\"Replace various gap notations with standardized tokens\"\"\"\n\n    if pd.isna(text): \n\n        return text\n\n    \n\n    # Complex gap patterns (order matters)\n\n    text = re.sub(r'\\.3(?:\\s+\\.3)+\\.{3}(?:\\s+\\.{3})+\\s+\\.{3}(?:\\s+\\.{3})+', '<big_gap>', text)\n\n    text = re.sub(r'\\.3(?:\\s+\\.3)+\\.{3}(?:\\s+\\.{3})+', '<big_gap>', text)\n\n    text = re.sub(r'\\.{3}(?:\\s+\\.{3})+', '<big_gap>', text)\n\n\n\n    # Simple gap patterns\n\n    text = re.sub(r'xx', '<gap>', text)\n\n    text = re.sub(r' x ', ' <gap> ', text)\n\n    text = re.sub(r'……', '<big_gap>', text)\n\n    text = re.sub(r'\\.\\.\\.\\.\\.\\.', '<big_gap>', text)\n\n    text = re.sub(r'…', '<big_gap>', text)\n\n    text = re.sub(r'\\.\\.\\.', '<big_gap>', text)\n\n\n\n    return text\n\n\n\ndef replace_gaps_back(text):\n\n    \"\"\"Convert standardized gap tokens back to original format\"\"\"\n\n    if pd.isna(text):  \n\n        return text\n\n    \n\n    text = re.sub(r'<gap>', 'x', text)\n\n    text = re.sub(r'<big_gap>', '...', text)\n\n\n\n    return text\n\n\n\ndef clean_translit(text):\n\n    \"\"\"Normalize transliteration by stripping scribal marks and gaps.\"\"\"\n\n    if not isinstance(text, str):\n\n        return \"\"\n\n    text = normalize_subscripts(text)\n\n    # Apply gap replacement first\n\n    text = replace_gaps(text)\n\n    text = re.sub(r\"\\[[^\\]]*\\]\", \" \", text)\n\n    text = re.sub(r\"<<[^>]*>>\", \" \", text)\n\n    text = re.sub(r\"[˹˺]\", \" \", text)\n\n    text = re.sub(r\"\\([^)]*\\)\", \" \", text)\n\n    text = re.sub(r\"\\{([^}]*)\\}\", r\"\\1\", text)\n\n    text = re.sub(r\"<([^>]*)>\", r\"\\1\", text)\n\n    text = re.sub(r\"[!?/:·]\", \" \", text)\n\n    text = re.sub(r\"\\s+\", \" \", text)\n\n    return text.strip()\n\n\n\ndef clean_translation(text):\n\n    if not isinstance(text, str):\n\n        return \"\"\n\n    text = text.replace(\"…\", \" \")\n\n    text = re.sub(r\"\\s+\", \" \", text)\n\n    return text.strip()\n\n\n\ndef filter_quality(df):\n\n    df[\"src_len\"] = df[\"src\"].str.split().str.len()\n\n    df[\"tgt_len\"] = df[\"tgt\"].str.split().str.len()\n\n    df = df[(df[\"src_len\"] >= 3) & (df[\"tgt_len\"] >= 3)]\n\n    ratio = (df[\"src_len\"] / df[\"tgt_len\"]).clip(upper=6)\n\n    df = df[(ratio >= 0.2) & (ratio <= 5)]\n\n    df = df.drop_duplicates(subset=[\"src\", \"tgt\"])\n\n    return df.drop(columns=[\"src_len\", \"tgt_len\"])\n\n\n\ndef load_and_align_data(filepath):\n\n    \"\"\"\n\n    Aligns Akkadian transliterations to English translations.\n\n    \"\"\"\n\n    df = pd.read_csv(filepath)\n\n    aligned_rows = []\n\n\n\n    print(f\"Raw documents: {len(df)}\")\n\n\n\n    for _, row in df.iterrows():\n\n        src = clean_translit(row.get(\"transliteration\", \"\"))\n\n        tgt = clean_translation(row.get(\"translation\", \"\"))\n\n\n\n        src_lines = [s.strip() for s in src.split(\"\\n\") if len(s.strip()) > 1]\n\n        tgt_sents = [t.strip() for t in re.split(r'(?<=[.!?])\\s+', tgt) if len(t.strip()) > 1]\n\n\n\n        if len(src_lines) == len(tgt_sents) and len(src_lines) > 1:\n\n            for s, t in zip(src_lines, tgt_sents):\n\n                aligned_rows.append({\"src\": s, \"tgt\": t})\n\n        else:\n\n            merged_src = src.replace(\"\\n\", \" \")\n\n            if len(merged_src) > 3 and len(tgt) > 3:\n\n                aligned_rows.append({\"src\": merged_src, \"tgt\": tgt})\n\n\n\n    print(f\"Aligned training examples (pre-filter): {len(aligned_rows)}\")\n\n    out_df = filter_quality(pd.DataFrame(aligned_rows))\n\n    print(f\"Aligned training examples (post-filter): {len(out_df)}\")\n\n    return out_df","metadata":{"execution":{"iopub.status.busy":"2026-01-08T11:15:06.677037Z","iopub.execute_input":"2026-01-08T11:15:06.677683Z","iopub.status.idle":"2026-01-08T11:15:06.692871Z","shell.execute_reply.started":"2026-01-08T11:15:06.677655Z","shell.execute_reply":"2026-01-08T11:15:06.692227Z"},"papermill":{"duration":0.450376,"end_time":"2025-12-25T11:09:10.416010","exception":false,"start_time":"2025-12-25T11:09:09.965634","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":4},{"id":"8aa72bcb","cell_type":"code","source":"# Broad Search miner and main dataset assembly\n\nfrom tqdm.auto import tqdm\n\n\n\ndef mine_publications_data():\n\n    print(\"\\n\" + \"=\"*60)\n\n    print(\"MINING PUBLICATIONS FOR ADDITIONAL DATA (BROAD MODE)\")\n\n    print(\"=\"*60)\n\n\n\n    pub_path = f\"{DATA_DIR}/publications.csv\"\n\n    pub_texts_path = f\"{DATA_DIR}/published_texts.csv\"\n\n\n\n    print(f\"Looking for: {pub_path}\")\n\n    if not os.path.exists(pub_path):\n\n        print(f\"❌ Error: File not found at {pub_path}\")\n\n        return pd.DataFrame(columns=[\"src\", \"tgt\"])\n\n\n\n    pubs = pd.read_csv(pub_path)\n\n    pub_texts = pd.read_csv(pub_texts_path)\n\n\n\n    akkadian_mask = pubs['has_akkadian'].astype(str).str.lower() == 'true'\n    eng_mask = pubs['page_text'].astype(str).str.contains(r'\\b(the|and|that|with)\\b', case=False)\n\n    pubs = pubs[eng_mask].copy()\n\n    print(f\"Searching {len(pubs)} relevant publication pages...\")\n\n\n\n    augmented_rows = []\n\n    candidates = pub_texts.dropna(subset=['cdli_id']).head(3000)\n\n\n\n    for _, row in tqdm(candidates.iterrows(), total=len(candidates)):\n\n        cdli_ids = str(row['cdli_id']).split('|')\n\n        translit = clean_translit(str(row.get('transliteration', '')))\n\n        if len(translit.split()) < 3:\n\n            continue\n\n        for pid in cdli_ids:\n\n            pid = pid.strip()\n\n            if len(pid) < 4:\n\n                continue\n\n            matches = pubs[pubs['page_text'].astype(str).str.contains(pid, regex=False)]\n\n            if matches.empty:\n\n                continue\n\n            content = str(matches.iloc[0]['page_text'])\n\n            idx = content.find(pid)\n\n            snippet = content[idx:idx+1000] if idx != -1 else content[:1000]\n\n            potential_trans = re.findall(r'([A-Z][a-z\\s\\-,;]{20,300}[\\.\\!\\?])', snippet)\n\n            for sent in potential_trans:\n\n                if len(sent.split()) > 5 and \"Assyrian\" not in sent:\n\n                    augmented_rows.append({\"src\": translit, \"tgt\": sent.strip()})\n\n                    break\n\n\n\n    if not augmented_rows:\n\n        print(\"⚠️ Warning: Still found 0 pairs. Check regex or data.\")\n\n        return pd.DataFrame(columns=[\"src\", \"tgt\"])\n\n\n\n    result_df = pd.DataFrame(augmented_rows)\n\n    result_df = result_df.drop_duplicates(subset=['src'])\n\n    print(f\"✓ SUCCESS: Mined {len(result_df)} additional training pairs!\")\n\n    return filter_quality(result_df)\n\n\n\n# Main execution\n\ntrain_df = load_and_align_data(f\"{DATA_DIR}/train.csv\")\n\nmined_df = mine_publications_data()\n\n\n\nif len(mined_df) > 0:\n\n    print(f\"Merging {len(mined_df)} mined examples...\")\n\n    train_df = pd.concat([train_df, mined_df], ignore_index=True)\n\n\n\ndataset = Dataset.from_pandas(train_df)\n\ndataset = dataset.train_test_split(test_size=0.05, seed=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T11:15:06.693985Z","iopub.execute_input":"2026-01-08T11:15:06.694299Z","iopub.status.idle":"2026-01-08T11:26:59.051068Z","shell.execute_reply.started":"2026-01-08T11:15:06.694270Z","shell.execute_reply":"2026-01-08T11:26:59.050298Z"}},"outputs":[{"name":"stdout","text":"Raw documents: 1561\nAligned training examples (pre-filter): 1561\nAligned training examples (post-filter): 1529\n\n============================================================\nMINING PUBLICATIONS FOR ADDITIONAL DATA (BROAD MODE)\n============================================================\nLooking for: /kaggle/input/deep-past-initiative-machine-translation/publications.csv\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/4226911153.py:40: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n  eng_mask = pubs['page_text'].astype(str).str.contains(r'\\b(the|and|that|with)\\b', case=False)\n","output_type":"stream"},{"name":"stdout","text":"Searching 144614 relevant publication pages...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9810567a3acf4a9ca8fd3a0563e31c25"}},"metadata":{}},{"name":"stdout","text":"⚠️ Warning: Still found 0 pairs. Check regex or data.\n","output_type":"stream"}],"execution_count":5},{"id":"eaa89d87","cell_type":"code","source":"# Quick data stats after mining and merge\n\nsup_count_est = len(train_df) - (len(mined_df) if isinstance(mined_df, pd.DataFrame) else 0)\n\nprint(\"\\n=== DATASET COUNTS ===\")\n\nprint(f\"Supervised pairs (est.): {sup_count_est}\")\n\nprint(f\"Mined pairs: {len(mined_df) if isinstance(mined_df, pd.DataFrame) else 0}\")\n\nprint(f\"Total pairs: {len(train_df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-08T11:26:59.053313Z","iopub.execute_input":"2026-01-08T11:26:59.053619Z","iopub.status.idle":"2026-01-08T11:26:59.058804Z","shell.execute_reply.started":"2026-01-08T11:26:59.053594Z","shell.execute_reply":"2026-01-08T11:26:59.058072Z"}},"outputs":[{"name":"stdout","text":"\n=== DATASET COUNTS ===\nSupervised pairs (est.): 1529\nMined pairs: 0\nTotal pairs: 1529\n","output_type":"stream"}],"execution_count":6},{"id":"8f241efd","cell_type":"markdown","source":"# C3. Tokenization","metadata":{"papermill":{"duration":0.006088,"end_time":"2025-12-25T11:09:10.429386","exception":false,"start_time":"2025-12-25T11:09:10.423298","status":"completed"},"tags":[]}},{"id":"e0472a9c","cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n\ndef preprocess_function(examples):\n    # Add prefix for MarianMT to specify target language\n    inputs = [PREFIX + ex for ex in examples[\"src\"]]\n    targets = examples[\"tgt\"]\n\n    model_inputs = tokenizer(\n        inputs, \n        max_length=MAX_LENGTH, \n        truncation=True, \n        padding=\"max_length\"\n    )\n\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            targets, \n            max_length=MAX_LENGTH, \n            truncation=True, \n            padding=\"max_length\"\n        )\n\n    # Replace padding token id with -100\n    model_inputs[\"labels\"] = [\n        [(l if l != tokenizer.pad_token_id else -100) for l in label]\n        for label in labels[\"input_ids\"]\n    ]\n    return model_inputs\n\n# Apply processing\ntokenized_train = dataset[\"train\"].map(preprocess_function, batched=True)\ntokenized_val = dataset[\"test\"].map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2026-01-08T11:26:59.059807Z","iopub.execute_input":"2026-01-08T11:26:59.060060Z","iopub.status.idle":"2026-01-08T11:27:04.649945Z","shell.execute_reply.started":"2026-01-08T11:26:59.060037Z","shell.execute_reply":"2026-01-08T11:27:04.649222Z"},"papermill":{"duration":4.781496,"end_time":"2025-12-25T11:09:15.216921","exception":false,"start_time":"2025-12-25T11:09:10.435425","status":"completed"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1452 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40ae2d8942df42a2a82b8df695516660"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/77 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62c0038624034c5eb092d6727784a34f"}},"metadata":{}}],"execution_count":7},{"id":"5d778719","cell_type":"markdown","source":"# C4. Model Setup","metadata":{"papermill":{"duration":0.006361,"end_time":"2025-12-25T11:09:15.230236","exception":false,"start_time":"2025-12-25T11:09:15.223875","status":"completed"},"tags":[]}},{"id":"790a566c","cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH)\n\ndata_collator = DataCollatorForSeq2Seq(\n    tokenizer=tokenizer, \n    model=model,\n    label_pad_token_id=-100\n)","metadata":{"execution":{"iopub.status.busy":"2026-01-08T11:27:04.650940Z","iopub.execute_input":"2026-01-08T11:27:04.651518Z","iopub.status.idle":"2026-01-08T11:27:06.512547Z","shell.execute_reply.started":"2026-01-08T11:27:04.651493Z","shell.execute_reply":"2026-01-08T11:27:06.511735Z"},"papermill":{"duration":1.69115,"end_time":"2025-12-25T11:09:16.927804","exception":false,"start_time":"2025-12-25T11:09:15.236654","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":8},{"id":"2ad0c636","cell_type":"markdown","source":"# C5. Training Configuration","metadata":{"papermill":{"duration":0.006336,"end_time":"2025-12-25T11:09:16.940750","exception":false,"start_time":"2025-12-25T11:09:16.934414","status":"completed"},"tags":[]}},{"id":"2f89b711","cell_type":"code","source":"# --- C5. Training Configuration (Optimized for 31+ Score) ---\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=OUTPUT_DIR,\n    \n    # --- DISK SPACE & SPEED ---\n    save_strategy=\"no\",           # No checkpoints to save disk space\n    eval_strategy=\"no\",           # Skip eval for faster training\n    load_best_model_at_end=False,\n    \n    learning_rate=3e-5,           # Slightly higher for better convergence\n    \n    per_device_train_batch_size=8, \n    per_device_eval_batch_size=8,\n    gradient_accumulation_steps=2,  # Effective batch = 16\n    gradient_checkpointing=False,    # MarianMT is memory efficient\n    \n    num_train_epochs=18,            # More epochs for this fast model\n    weight_decay=0.01,\n    predict_with_generate=False,    # Faster training\n    \n    fp16=True,                      # Mixed precision\n    report_to=\"none\",\n    logging_steps=50,\n    \n    # Quality optimizations\n    label_smoothing_factor=0.1,\n    lr_scheduler_type=\"cosine\",\n    warmup_ratio=0.05,\n    generation_max_length=180,\n    generation_num_beams=6\n)","metadata":{"execution":{"iopub.status.busy":"2026-01-08T11:27:06.513519Z","iopub.execute_input":"2026-01-08T11:27:06.513850Z","iopub.status.idle":"2026-01-08T11:27:06.775132Z","shell.execute_reply.started":"2026-01-08T11:27:06.513814Z","shell.execute_reply":"2026-01-08T11:27:06.774504Z"},"papermill":{"duration":0.195392,"end_time":"2025-12-25T11:09:17.142332","exception":false,"start_time":"2025-12-25T11:09:16.946940","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":9},{"id":"50d3825b","cell_type":"markdown","source":"# C6. Execution","metadata":{"papermill":{"duration":0.006249,"end_time":"2025-12-25T11:09:17.155125","exception":false,"start_time":"2025-12-25T11:09:17.148876","status":"completed"},"tags":[]}},{"id":"bab0091b","cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)\n\nprint(\"Starting MarianMT Training...\")\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2026-01-08T11:27:06.776054Z","iopub.execute_input":"2026-01-08T11:27:06.776362Z","iopub.status.idle":"2026-01-08T11:36:51.032893Z","shell.execute_reply.started":"2026-01-08T11:27:06.776337Z","shell.execute_reply":"2026-01-08T11:36:51.032215Z"},"papermill":{"duration":525.408425,"end_time":"2025-12-25T11:18:02.569642","exception":false,"start_time":"2025-12-25T11:09:17.161217","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/148008205.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\nThe tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n","output_type":"stream"},{"name":"stdout","text":"Starting MarianMT Training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='828' max='828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [828/828 09:36, Epoch 18/18]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>10.801700</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>4.179200</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>3.655500</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>3.442100</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>3.298300</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>3.171300</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>3.138300</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>3.023500</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>2.976900</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>2.941200</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>2.913300</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>2.882100</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>2.859500</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>2.846600</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>2.855100</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>2.841200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=828, training_loss=3.5873839981889954, metrics={'train_runtime': 579.834, 'train_samples_per_second': 45.075, 'train_steps_per_second': 1.428, 'total_flos': 1107459582197760.0, 'train_loss': 3.5873839981889954, 'epoch': 18.0})"},"metadata":{}}],"execution_count":10},{"id":"66c6d40a","cell_type":"code","source":"# POST-TRAINING VALIDATION - Load fresh data and evaluate\nprint(\"\\n=== POST-TRAINING VALIDATION ===\")\n\n# Reload validation data fresh\nval_df = pd.read_csv(f\"{DATA_DIR}/train.csv\")\nval_texts = []\nval_refs_list = []\n\nfor _, row in val_df.iterrows():\n    src = clean_translit(row.get(\"transliteration\", \"\"))\n    tgt = clean_translation(row.get(\"translation\", \"\"))\n    if len(src) > 5 and len(tgt) > 5:\n        val_texts.append(src)\n        val_refs_list.append(tgt)\n\n# Use ~200 samples for quick validation\nval_texts = val_texts[:200]\nval_refs_list = val_refs_list[:200]\nval_refs = [[t] for t in val_refs_list]\n\nprint(f\"Validating on {len(val_texts)} samples...\")\n\nmetric_bleu = evaluate.load(\"sacrebleu\")\nmetric_chrf = evaluate.load(\"chrf\")\n\ndef dedup_repeats(text: str) -> str:\n    toks = text.split()\n    out = []\n    for t in toks:\n        if len(out) >= 2 and t == out[-1] == out[-2]:\n            continue\n        out.append(t)\n    return \" \".join(out)\n\ndef postprocess_text(preds):\n    out = []\n    for p in preds:\n        p = p.strip()\n        p = re.sub(r\"\\s+([.,!?;:])\", r\"\\1\", p)\n        p = re.sub(r\"([.,!?;:])([A-Za-z])\", r\"\\1 \\2\", p)\n        p = dedup_repeats(p)\n        if p and p[0].islower():\n            p = p[0].upper() + p[1:]\n        if p and p[-1] not in \".!?\":\n            p += \".\"\n        p = re.sub(r\"([.!?]){2,}\", \".\", p)\n        out.append(p.strip())\n    return out\n\ndef generate_batch(texts):\n    batch_inputs = [\">>eng<< \" + doc for doc in texts]\n    enc = tokenizer(batch_inputs, max_length=160, truncation=True, padding=True, return_tensors=\"pt\").to(model.device)\n    gen = model.generate(\n        **enc,\n        max_length=180,\n        min_length=6,\n        num_beams=6,\n        no_repeat_ngram_size=3,\n        length_penalty=1.05,\n        early_stopping=True,\n    )\n    return tokenizer.batch_decode(gen, skip_special_tokens=True)\n\npreds = []\nfor i in range(0, len(val_texts), 8):\n    preds.extend(generate_batch(val_texts[i:i+8]))\n\npreds = postprocess_text(preds)\nbleu = metric_bleu.compute(predictions=preds, references=val_refs)\nchrf = metric_chrf.compute(predictions=preds, references=val_refs)\nprint(f\"Validation BLEU: {bleu['score']:.2f}, chrF: {chrf['score']:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2026-01-08T11:36:51.033942Z","iopub.execute_input":"2026-01-08T11:36:51.034209Z","iopub.status.idle":"2026-01-08T11:38:16.364263Z","shell.execute_reply.started":"2026-01-08T11:36:51.034184Z","shell.execute_reply":"2026-01-08T11:38:16.363386Z"},"papermill":{"duration":71.647827,"end_time":"2025-12-25T11:19:14.224317","exception":false,"start_time":"2025-12-25T11:18:02.576490","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\n=== POST-TRAINING VALIDATION ===\nValidating on 200 samples...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0eff5152cf13498bbe18cb8ad3be7d63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0f69a2e1f324b57984357b1a7f89165"}},"metadata":{}},{"name":"stdout","text":"Validation BLEU: 6.22, chrF: 26.33\n","output_type":"stream"}],"execution_count":11},{"id":"69683d09","cell_type":"markdown","source":"# C7. Save Model","metadata":{"papermill":{"duration":0.006699,"end_time":"2025-12-25T11:19:14.237745","exception":false,"start_time":"2025-12-25T11:19:14.231046","status":"completed"},"tags":[]}},{"id":"ed53aaf2","cell_type":"code","source":"print(f\"Saving model to {OUTPUT_DIR}...\")\ntrainer.save_model(OUTPUT_DIR)\ntokenizer.save_pretrained(OUTPUT_DIR)\nprint(\"Notebook C (MarianMT) Complete.\")","metadata":{"execution":{"iopub.status.busy":"2026-01-08T11:38:16.365381Z","iopub.execute_input":"2026-01-08T11:38:16.365954Z","iopub.status.idle":"2026-01-08T11:38:17.141556Z","shell.execute_reply.started":"2026-01-08T11:38:16.365925Z","shell.execute_reply":"2026-01-08T11:38:17.140942Z"},"papermill":{"duration":0.71791,"end_time":"2025-12-25T11:19:14.962238","exception":false,"start_time":"2025-12-25T11:19:14.244328","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Saving model to /kaggle/working/marian-mt-saved...\nNotebook C (MarianMT) Complete.\n","output_type":"stream"}],"execution_count":12},{"id":"4de81446","cell_type":"code","source":"# C8. Optional Self-Training Augmentation (Fast, Quality-Filtered)\nENABLE_SELF_TRAIN = False\nMAX_PSEUDO = int(os.getenv(\"MARIAN_MAX_PSEUDO\", \"1500\"))\n\nif ENABLE_SELF_TRAIN:\n    print(\"\\n=== SELF-TRAINING AUGMENTATION (MarianMT) ===\")\n    pub_path = f\"{DATA_DIR}/published_texts.csv\"\n    if os.path.exists(pub_path):\n        pub_df = pd.read_csv(pub_path)\n        translits = pub_df.get(\"transliteration\", pd.Series([])).dropna().astype(str).tolist()\n        translits = [clean_translit(t) for t in translits]\n        translits = [t for t in translits if 5 <= len(t.split()) <= 140]\n        translits = translits[:MAX_PSEUDO]\n        print(f\"Generating pseudo translations for {len(translits)} extra transliterations...\")\n\n        def generate_batch(texts):\n            batch_inputs = [PREFIX + doc for doc in texts]\n            enc = tokenizer(batch_inputs, max_length=MAX_LENGTH, truncation=True, padding=True, return_tensors=\"pt\").to(model.device)\n            gen = model.generate(\n                **enc,\n                max_length=180,\n                min_length=6,\n                num_beams=6,\n                no_repeat_ngram_size=3,\n                length_penalty=1.05,\n                early_stopping=True,\n            )\n            return tokenizer.batch_decode(gen, skip_special_tokens=True)\n\n        pseudo_trans = []\n        for i in range(0, len(translits), 16):\n            batch_preds = generate_batch(translits[i:i+16])\n            pseudo_trans.extend(batch_preds)\n\n        # Postprocess & quality filter\n        def dedup_repeats(text: str) -> str:\n            toks = text.split()\n            out = []\n            for t in toks:\n                if len(out) >= 2 and t == out[-1] == out[-2]:\n                    continue\n                out.append(t)\n            return \" \".join(out)\n        def postprocess_text(preds):\n            out = []\n            for p in preds:\n                p = p.strip()\n                p = re.sub(r\"\\s+([.,!?;:])\", r\"\\1\", p)\n                p = re.sub(r\"([.,!?;:])([A-Za-z])\", r\"\\1 \\2\", p)\n                p = dedup_repeats(p)\n                if p and p[0].islower():\n                    p = p[0].upper() + p[1:]\n                if p and p[-1] not in \".!?\":\n                    p += \".\"\n                p = re.sub(r\"([.!?]){2,}\", \".\", p)\n                out.append(p.strip())\n            return out\n\n        pseudo_trans = postprocess_text(pseudo_trans)\n        aug_df = pd.DataFrame({\"transliteration\": translits, \"translation\": pseudo_trans})\n        aug_df[\"src_len\"] = aug_df[\"transliteration\"].str.split().str.len()\n        aug_df[\"tgt_len\"] = aug_df[\"translation\"].str.split().str.len()\n        ratio = (aug_df[\"tgt_len\"] / aug_df[\"src_len\"]).clip(upper=6)\n        aug_df = aug_df[(aug_df[\"tgt_len\"] >= 4) & (ratio >= 0.5) & (ratio <= 6)]\n        aug_df = aug_df.drop(columns=[\"src_len\", \"tgt_len\"])\n        print(f\"Pseudo pairs retained after filtering: {len(aug_df)}\")\n\n        base_train = pd.read_csv(f\"{DATA_DIR}/train.csv\")\n        base_train = base_train.dropna(subset=[\"transliteration\", \"translation\"]).astype(str)\n        base_train[\"transliteration\"] = base_train[\"transliteration\"].map(clean_translit)\n        base_train[\"translation\"] = base_train[\"translation\"].map(clean_translation)\n        combined = pd.concat([\n            base_train[[\"transliteration\", \"translation\"]],\n            aug_df[[\"transliteration\", \"translation\"]]\n        ], axis=0).drop_duplicates().reset_index(drop=True)\n        print(f\"Total combined training pairs: {len(combined)}\")\n\n        def preprocess_function_aug(examples):\n            inputs = [PREFIX + ex for ex in examples[\"transliteration\"]]\n            targets = examples[\"translation\"]\n            model_inputs = tokenizer(\n                inputs,\n                max_length=MAX_LENGTH,\n                truncation=True,\n                padding=\"max_length\"\n            )\n            with tokenizer.as_target_tokenizer():\n                labels = tokenizer(\n                    targets,\n                    max_length=MAX_LENGTH,\n                    truncation=True,\n                    padding=\"max_length\"\n                )\n            model_inputs[\"labels\"] = [\n                [(l if l != tokenizer.pad_token_id else -100) for l in label]\n                for label in labels[\"input_ids\"]\n            ]\n            return model_inputs\n\n        ds_combined = Dataset.from_pandas(combined)\n        tokenized_combined = ds_combined.map(preprocess_function_aug, batched=True)\n\n        training_args_aug = Seq2SeqTrainingArguments(\n            output_dir=OUTPUT_DIR,\n            save_strategy=\"no\",\n            eval_strategy=\"no\",\n            load_best_model_at_end=False,\n            learning_rate=2e-5,\n            per_device_train_batch_size=8,\n            gradient_accumulation_steps=2,\n            num_train_epochs=2,\n            fp16=True,\n            report_to=\"none\"\n        )\n        trainer_aug = Seq2SeqTrainer(\n            model=model,\n            args=training_args_aug,\n            train_dataset=tokenized_combined,\n            tokenizer=tokenizer,\n            data_collator=data_collator,\n        )\n        print(\"Starting second-stage training with augmented data...\")\n        trainer_aug.train()\n        print(\"Augmentation stage complete.\")\n        \n        print(f\"Saving augmented model to {OUTPUT_DIR}...\")\n        trainer_aug.save_model(OUTPUT_DIR)\n        tokenizer.save_pretrained(OUTPUT_DIR)\n    else:\n        print(\"published_texts.csv not found; skipping self-training.\")","metadata":{"execution":{"iopub.status.busy":"2026-01-08T11:38:17.142433Z","iopub.execute_input":"2026-01-08T11:38:17.143034Z","iopub.status.idle":"2026-01-08T11:38:17.159497Z","shell.execute_reply.started":"2026-01-08T11:38:17.143009Z","shell.execute_reply":"2026-01-08T11:38:17.158656Z"},"trusted":true},"outputs":[],"execution_count":13}]}